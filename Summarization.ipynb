{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "57838783",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features: ['article', 'highlights', 'id']\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"cnn_dailymail\", \"3.0.0\")\n",
    "print(f\"Features: {dataset['train'].column_names}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "76b6c7bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'article': ['LONDON, England (Reuters) -- Harry Potter star Daniel Radcliffe gains access to a reported £20 million ($41.1 million) fortune as he turns 18 on Monday, but he insists the money won\\'t cast a spell on him. Daniel Radcliffe as Harry Potter in \"Harry Potter and the Order of the Phoenix\" To the disappointment of gossip columnists around the world, the young actor says he has no plans to fritter his cash away on fast cars, drink and celebrity parties. \"I don\\'t plan to be one of those people who, as soon as they turn 18, suddenly buy themselves a massive sports car collection or something similar,\" he told an Australian interviewer earlier this month. \"I don\\'t think I\\'ll be particularly extravagant. \"The things I like buying are things that cost about 10 pounds -- books and CDs and DVDs.\" At 18, Radcliffe will be able to gamble in a casino, buy a drink in a pub or see the horror film \"Hostel: Part II,\" currently six places below his number one movie on the UK box office chart. Details of how he\\'ll mark his landmark birthday are under wraps. His agent and publicist had no comment on his plans. \"I\\'ll definitely have some sort of party,\" he said in an interview. \"Hopefully none of you will be reading about it.\" Radcliffe\\'s earnings from the first five Potter films have been held in a trust fund which he has not been able to touch. Despite his growing fame and riches, the actor says he is keeping his feet firmly on the ground. \"People are always looking to say \\'kid star goes off the rails,\\'\" he told reporters last month. \"But I try very hard not to go that way because it would be too easy for them.\" His latest outing as the boy wizard in \"Harry Potter and the Order of the Phoenix\" is breaking records on both sides of the Atlantic and he will reprise the role in the last two films.  Watch I-Reporter give her review of Potter\\'s latest » . There is life beyond Potter, however. The Londoner has filmed a TV movie called \"My Boy Jack,\" about author Rudyard Kipling and his son, due for release later this year. He will also appear in \"December Boys,\" an Australian film about four boys who escape an orphanage. Earlier this year, he made his stage debut playing a tortured teenager in Peter Shaffer\\'s \"Equus.\" Meanwhile, he is braced for even closer media scrutiny now that he\\'s legally an adult: \"I just think I\\'m going to be more sort of fair game,\" he told Reuters. E-mail to a friend . Copyright 2007 Reuters. All rights reserved.This material may not be published, broadcast, rewritten, or redistributed.',\n",
       "  'Editor\\'s note: In our Behind the Scenes series, CNN correspondents share their experiences in covering news and analyze the stories behind the events. Here, Soledad O\\'Brien takes users inside a jail where many of the inmates are mentally ill. An inmate housed on the \"forgotten floor,\" where many mentally ill inmates are housed in Miami before trial. MIAMI, Florida (CNN) -- The ninth floor of the Miami-Dade pretrial detention facility is dubbed the \"forgotten floor.\" Here, inmates with the most severe mental illnesses are incarcerated until they\\'re ready to appear in court. Most often, they face drug charges or charges of assaulting an officer --charges that Judge Steven Leifman says are usually \"avoidable felonies.\" He says the arrests often result from confrontations with police. Mentally ill people often won\\'t do what they\\'re told when police arrive on the scene -- confrontation seems to exacerbate their illness and they become more paranoid, delusional, and less likely to follow directions, according to Leifman. So, they end up on the ninth floor severely mentally disturbed, but not getting any real help because they\\'re in jail. We toured the jail with Leifman. He is well known in Miami as an advocate for justice and the mentally ill. Even though we were not exactly welcomed with open arms by the guards, we were given permission to shoot videotape and tour the floor.  Go inside the \\'forgotten floor\\' » . At first, it\\'s hard to determine where the people are. The prisoners are wearing sleeveless robes. Imagine cutting holes for arms and feet in a heavy wool sleeping bag -- that\\'s kind of what they look like. They\\'re designed to keep the mentally ill patients from injuring themselves. That\\'s also why they have no shoes, laces or mattresses. Leifman says about one-third of all people in Miami-Dade county jails are mentally ill. So, he says, the sheer volume is overwhelming the system, and the result is what we see on the ninth floor. Of course, it is a jail, so it\\'s not supposed to be warm and comforting, but the lights glare, the cells are tiny and it\\'s loud. We see two, sometimes three men -- sometimes in the robes, sometimes naked, lying or sitting in their cells. \"I am the son of the president. You need to get me out of here!\" one man shouts at me. He is absolutely serious, convinced that help is on the way -- if only he could reach the White House. Leifman tells me that these prisoner-patients will often circulate through the system, occasionally stabilizing in a mental hospital, only to return to jail to face their charges. It\\'s brutally unjust, in his mind, and he has become a strong advocate for changing things in Miami. Over a meal later, we talk about how things got this way for mental patients. Leifman says 200 years ago people were considered \"lunatics\" and they were locked up in jails even if they had no charges against them. They were just considered unfit to be in society. Over the years, he says, there was some public outcry, and the mentally ill were moved out of jails and into hospitals. But Leifman says many of these mental hospitals were so horrible they were shut down. Where did the patients go? Nowhere. The streets. They became, in many cases, the homeless, he says. They never got treatment. Leifman says in 1955 there were more than half a million people in state mental hospitals, and today that number has been reduced 90 percent, and 40,000 to 50,000 people are in mental hospitals. The judge says he\\'s working to change this. Starting in 2008, many inmates who would otherwise have been brought to the \"forgotten floor\"  will instead be sent to a new mental health facility -- the first step on a journey toward long-term treatment, not just punishment. Leifman says it\\'s not the complete answer, but it\\'s a start. Leifman says the best part is that it\\'s a win-win solution. The patients win, the families are relieved, and the state saves money by simply not cycling these prisoners through again and again. And, for Leifman, justice is served. E-mail to a friend .',\n",
       "  'MINNEAPOLIS, Minnesota (CNN) -- Drivers who were on the Minneapolis bridge when it collapsed told harrowing tales of survival. \"The whole bridge from one side of the Mississippi to the other just completely gave way, fell all the way down,\" survivor Gary Babineau told CNN. \"I probably had a 30-, 35-foot free fall. And there\\'s cars in the water, there\\'s cars on fire. The whole bridge is down.\" He said his back was injured but he determined he could move around. \"I realized there was a school bus right next to me, and me and a couple of other guys went over and started lifting the kids off the bridge. They were yelling, screaming, bleeding. I think there were some broken bones.\"  Watch a driver describe his narrow escape » . At home when he heard about the disaster, Dr. John Hink, an emergency room physician, jumped into his car and rushed to the scene in 15 minutes. He arrived at the south side of the bridge, stood on the riverbank and saw dozens of people lying dazed on an expansive deck. They were in the middle of the Mississippi River, which was churning fast, and he had no way of getting to them. He went to the north side, where there was easier access to people. Ambulances were also having a hard time driving down to the river to get closer to the scene. Working feverishly, volunteers, EMTs and other officials managed to get 55 people into ambulances in less than two hours. Occasionally, a pickup truck with a medic inside would drive to get an injured person and bring him back up even ground, Hink told CNN. The rescue effort was controlled and organized, he said; the opposite of the lightning-quick collapse. \"I could see the whole bridge as it was going down, as it was falling,\" Babineau said. \"It just gave a rumble real quick, and it all just gave way, and it just fell completely, all the way to the ground. And there was dust everywhere and it was just like everyone has been saying: It was just like out of the movies.\" Babineau said the rear of his pickup truck was dangling over the edge of a broken-off section of the bridge. He said several vehicles slid past him into the water. \"I stayed in my car for one or two seconds. I saw a couple cars fall,\" he said. \"So I stayed in my car until the cars quit falling for a second, then I got out real quick, ran in front of my truck -- because behind my truck was just a hole -- and I helped a woman off of the bridge with me. \"I just wanted off the bridge, and then I ran over to the school bus. I started grabbing kids and handing them down. It was just complete chaos.\" He said most of the children were crying or screaming. He and other rescuers set them on the ground and told them to run to the river bank, but a few needed to be carried because of their injuries.  See rescuers clamber over rubble » . Babineau said he had no rescue training. \"I just knew what I had to do at the moment.\" Melissa Hughes, 32, of Minneapolis, told The Associated Press that she was driving home when the western edge of the bridge collapsed under her. \"You know that free-fall feeling? I felt that twice,\" Hughes said. A pickup landed on top of her car, but she was not hurt. \"I had no idea there was a vehicle on my car,\" she told AP. \"It\\'s really very surreal.\" Babineau told the Minneapolis Star-Tribune: \"On the way down, I thought I was dead. I literally thought I was dead. \"My truck was completely face down, pointed toward the ground, and my truck got ripped in half. It was folded in half, and I can\\'t believe I\\'m alive.\"  See and hear eyewitness accounts » . Bernie Toivonen told CNN\\'s \"American Morning\" that his vehicle was on a part of the bridge that ended up tilted at a 45-degree angle. \"I knew the deck was going down, there was no question about it, and I thought I was going to die,\" he said. After the bridge settled and his car remained upright, \"I just put in park, turned the key off and said, \\'Oh, I\\'m alive,\\' \" he said. E-mail to a friend .',\n",
       "  'WASHINGTON (CNN) -- Doctors removed five small polyps from President Bush\\'s colon on Saturday, and \"none appeared worrisome,\" a White House spokesman said. The polyps were removed and sent to the National Naval Medical Center in Bethesda, Maryland, for routine microscopic examination, spokesman Scott Stanzel said. Results are expected in two to three days. All were small, less than a centimeter [half an inch] in diameter, he said. Bush is in good humor, Stanzel said, and will resume his activities at Camp David. During the procedure Vice President Dick Cheney assumed presidential power. Bush reclaimed presidential power at 9:21 a.m. after about two hours. Doctors used \"monitored anesthesia care,\" Stanzel said, so the president was asleep, but not as deeply unconscious as with a true general anesthetic. He spoke to first lady Laura Bush -- who is in Midland, Texas, celebrating her mother\\'s birthday -- before and after the procedure, Stanzel said. Afterward, the president played with his Scottish terriers, Barney and Miss Beazley, Stanzel said. He planned to have lunch at Camp David and have briefings with National Security Adviser Stephen Hadley and White House Chief of Staff Josh Bolten, and planned to take a bicycle ride Saturday afternoon. Cheney, meanwhile, spent the morning at his home on Maryland\\'s eastern shore, reading and playing with his dogs, Stanzel said. Nothing occurred that required him to take official action as president before Bush reclaimed presidential power. The procedure was supervised by Dr. Richard Tubb, Bush\\'s physician, and conducted by a multidisciplinary team from the National Naval Medical Center in Bethesda, Maryland, the White House said. Bush\\'s last colonoscopy was in June 2002, and no abnormalities were found, White House spokesman Tony Snow said. The president\\'s doctor had recommended a repeat procedure in about five years. A colonoscopy is the most sensitive test for colon cancer, rectal cancer and polyps, small clumps of cells that can become cancerous, according to the Mayo Clinic. Small polyps may be removed during the procedure. Snow said on Friday that Bush had polyps removed during colonoscopies before becoming president. Snow himself is undergoing chemotherapy for cancer that began in his colon and spread to his liver.  Watch Snow talk about Bush\\'s procedure and his own colon cancer » . \"The president wants to encourage everybody to use surveillance,\" Snow said. The American Cancer Society recommends that people without high risk factors or symptoms begin getting screened for signs of colorectal cancer at age 50. E-mail to a friend .',\n",
       "  '(CNN)  -- The National Football League has indefinitely suspended Atlanta Falcons quarterback Michael Vick without pay, officials with the league said Friday. NFL star Michael Vick is set to appear in court Monday. A judge will have the final say on a plea deal. Earlier, Vick admitted to participating in a dogfighting ring as part of a plea agreement with federal prosecutors in Virginia. \"Your admitted conduct was not only illegal, but also cruel and reprehensible. Your team, the NFL, and NFL fans have all been hurt by your actions,\" NFL Commissioner Roger Goodell said in a letter to Vick. Goodell said he would review the status of the suspension after the legal proceedings are over. In papers filed Friday with a federal court in Virginia, Vick also admitted that he and two co-conspirators killed dogs that did not fight well. Falcons owner Arthur Blank said Vick\\'s admissions describe actions that are \"incomprehensible and unacceptable.\" The suspension makes \"a strong statement that conduct which tarnishes the good reputation of the NFL will not be tolerated,\" he said in a statement.  Watch what led to Vick\\'s suspension » . Goodell said the Falcons could \"assert any claims or remedies\" to recover $22 million of Vick\\'s signing bonus from the 10-year, $130 million contract he signed in 2004, according to The Associated Press. Vick said he would plead guilty to one count of \"Conspiracy to Travel in Interstate Commerce in Aid of Unlawful Activities and to Sponsor a Dog in an Animal Fighting Venture\" in a plea agreement filed at U.S. District Court in Richmond, Virginia. The charge is punishable by up to five years in prison, a $250,000 fine, \"full restitution, a special assessment and 3 years of supervised release,\" the plea deal said. Federal prosecutors agreed to ask for the low end of the sentencing guidelines. \"The defendant will plead guilty because the defendant is in fact guilty of the charged offense,\" the plea agreement said. In an additional summary of facts, signed by Vick and filed with the agreement, Vick admitted buying pit bulls and the property used for training and fighting the dogs, but the statement said he did not bet on the fights or receive any of the money won. \"Most of the \\'Bad Newz Kennels\\' operations and gambling monies were provided by Vick,\" the official summary of facts said. Gambling wins were generally split among co-conspirators Tony Taylor, Quanis Phillips and sometimes Purnell Peace, it continued. \"Vick did not gamble by placing side bets on any of the fights. Vick did not receive any of the proceeds from the purses that were won by \\'Bad Newz Kennels.\\' \" Vick also agreed that \"collective efforts\" by him and two others caused the deaths of at least six dogs. Around April, Vick, Peace and Phillips tested some dogs in fighting sessions at Vick\\'s property in Virginia, the statement said. \"Peace, Phillips and Vick agreed to the killing of approximately 6-8 dogs that did not perform well in \\'testing\\' sessions at 1915 Moonlight Road and all of those dogs were killed by various methods, including hanging and drowning. \"Vick agrees and stipulates that these dogs all died as a result of the collective efforts of Peace, Phillips and Vick,\" the summary said. Peace, 35, of Virginia Beach, Virginia; Phillips, 28, of Atlanta, Georgia; and Taylor, 34, of Hampton, Virginia, already have accepted agreements to plead guilty in exchange for reduced sentences. Vick, 27, is scheduled to appear Monday in court, where he is expected to plead guilty before a judge.  See a timeline of the case against Vick » . The judge in the case will have the final say over the plea agreement. The federal case against Vick focused on the interstate conspiracy, but Vick\\'s admission that he was involved in the killing of dogs could lead to local charges, according to CNN legal analyst Jeffrey Toobin. \"It sometimes happens -- not often -- that the state will follow a federal prosecution by charging its own crimes for exactly the same behavior,\" Toobin said Friday. \"The risk for Vick is, if he makes admissions in his federal guilty plea, the state of Virginia could say, \\'Hey, look, you admitted violating Virginia state law as well. We\\'re going to introduce that against you and charge you in our court.\\' \" In the plea deal, Vick agreed to cooperate with investigators and provide all information he may have on any criminal activity and to testify if necessary. Vick also agreed to turn over any documents he has and to submit to polygraph tests. Vick agreed to \"make restitution for the full amount of the costs associated\" with the dogs that are being held by the government. \"Such costs may include, but are not limited to, all costs associated with the care of the dogs involved in that case, including if necessary, the long-term care and/or the humane euthanasia of some or all of those animals.\" Prosecutors, with the support of animal rights activists, have asked for permission to euthanize the dogs. But the dogs could serve as important evidence in the cases against Vick and his admitted co-conspirators. Judge Henry E. Hudson issued an order Thursday telling the U.S. Marshals Service to \"arrest and seize the defendant property, and use discretion and whatever means appropriate to protect and maintain said defendant property.\" Both the judge\\'s order and Vick\\'s filing refer to \"approximately\" 53 pit bull dogs. After Vick\\'s indictment last month, Goodell ordered the quarterback not to report to the Falcons training camp, and the league is reviewing the case. Blank told the NFL Network on Monday he could not speculate on Vick\\'s future as a Falcon, at least not until he had seen \"a statement of facts\" in the case.  E-mail to a friend . CNN\\'s Mike Phelan contributed to this report.',\n",
       "  'BAGHDAD, Iraq (CNN) -- Dressed in a Superman shirt, 5-year-old Youssif held his sister\\'s hand Friday, seemingly unaware that millions of people across the world have been touched by his story. Nearby, his parents talked about the new future and hope they have for their boy -- and the potential for recovery from his severe burns. Youssif holds his sister\\'s hand Friday. He\\'s wearing a facial mask often used to help burn victims. It\\'s the best birthday present the Iraqi family could ever have imagined for their boy: Youssif turns 6 next Friday. \"I was so happy I didn\\'t know what to do with myself,\" his mother, Zainab, told CNN, a broad smile across her face. \"I didn\\'t think the reaction would be this big.\" His father said he was on the roof of his house when CNN called him with the news about the outpouring of support for his son. \"We just want to thank everyone who has come forward,\" he said. \"We knew there was kindness out there.\" Like his wife, he couldn\\'t stop smiling. He talked about how he tried in vain to get help for his son in Baghdad, leaving \"no stone unturned\" on a mission to help his boy. There were many trips to the Ministry of Health. He says he even put in a request to Iraq\\'s parliament for help. The family eventually told CNN their story -- that Youssif was grabbed by masked men outside their home on January 15, doused in gasoline and set on fire. Simply by coming forward, his parents put themselves in incredible danger. No one has been arrested or held accountable in Youssif\\'s case.  Watch CNN\\'s Arwa Damon describe \\'truly phenomenal\\' outpouring » . Shortly after Youssif\\'s story aired Wednesday, the Children\\'s Burn Foundation -- a nonprofit organization based in Sherman Oaks, California, that provides support for burn victims locally, nationally and internationally -- agreed to pay for the transportation for Youssif and his family to come to the United States and to set up a fund for donations. You can make a donation at the foundation\\'s site by clicking here. There\\'s a drop-down menu under the \"general donation\" area that is marked \"Youssif\\'s fund.\" The foundation says it will cover all medical costs -- from surgeries for Youssif to housing costs to any social rehabilitation that might be needed for him. Surgeries will be performed by Dr. Peter Grossman, a plastic surgeon with the affiliated Grossman Burn Center who is donating his services for Youssif\\'s cause. Officials are still trying to get the appropriate visas for the family\\'s travels. \"We are prepared to have them come here, set them up in a housing situation, provide support for them and begin treatment,\" said Barbara Friedman, executive director of the Children\\'s Burn Foundation. \"We expect that the treatment will be from between six months to a year with many surgeries.\" She added, \"He will be getting the absolute best care that\\'s available.\" Youssif\\'s parents said they know it\\'s going to be a lengthy and difficult process and that adjusting to their stay in America may not be easy. But none of that matters -- getting help for their boy is first and foremost. \"I will do anything for Youssif,\" his father said, pulling his son closer to him. \"Our child is everything.\" His mother tried to coax Youssif to talk to us on this day. But he didn\\'t want to; his mother says he\\'s shy outside of their home. The biggest obstacle now is getting the visas to leave, and the serious security risks they face every day and hour they remain in Iraq. But this family -- which saw the very worst in humanity on that January day -- has new hope in the world. That is partly due to the tens of thousands of CNN.com users who were so moved by the story and wanted to act. CNN Iraqi staff central to bringing this story together were also overwhelmed with the generosity coming from people outside of their border. In a nation that largely feels abandoned by the rest of the world, it was a refreshing realization. E-mail to a friend . CNN.com senior producer Wayne Drash contributed to this report in Atlanta.',\n",
       "  'BAGHDAD, Iraq (CNN) -- The women are too afraid and ashamed to show their faces or have their real names used. They have been driven to sell their bodies to put food on the table for their children -- for as little as $8 a day. Suha, 37, is a mother of three. She says her husband thinks she is cleaning houses when she leaves home. \"People shouldn\\'t criticize women, or talk badly about them,\" says 37-year-old Suha as she adjusts the light colored scarf she wears these days to avoid extremists who insist women cover themselves. \"They all say we have lost our way, but they never ask why we had to take this path.\" A mother of three, she wears light makeup, a gold pendant of Iraq around her neck, and an unexpected air of elegance about her. \"I don\\'t have money to take my kid to the doctor. I have to do anything that I can to preserve my child, because I am a mother,\" she says, explaining why she prostitutes herself. Anger and frustration rise in her voice as she speaks. \"No matter what else I may be, no matter how off the path I may be, I am a mother!\"  Watch a woman describe turning to prostitution to \"save my child\" » . Her clasped hands clench and unclench nervously. Suha\\'s husband thinks that she is cleaning houses when she goes away. So does Karima\\'s family. \"At the start I was cleaning homes, but I wasn\\'t making much. No matter how hard I worked it just wasn\\'t enough,\" she says. Karima, clad in all black, adds, \"My husband died of lung cancer nine months ago and left me with nothing.\" She has five children, ages 8 to 17. Her eldest son could work, but she\\'s too afraid for his life to let him go into the streets, preferring to sacrifice herself than risk her child. She was solicited the first time when she was cleaning an office. \"They took advantage of me,\" she says softly. \"At first I rejected it, but then I realized I have to do it.\" Both Suha and Karima have clients that call them a couple times a week. Other women resort to trips to the market to find potential clients. Or they flag down vehicles. Prostitution is a choice more and more Iraqi women are making just to survive. \"It\\'s increasing,\" Suha says. \"I found this \\'thing\\' through my friend, and I have another friend in the same predicament as mine. Because of the circumstance, she is forced to do such things.\" Violence, increased cost of living, and lack of any sort of government aid leave women like these with few other options, according to humanitarian workers. \"At this point there is a population of women who have to sell their bodies in order to keep their children alive,\" says Yanar Mohammed, head and founder of the Organization for Women\\'s Freedom in Iraq. \"It\\'s a taboo that no one is speaking about.\" She adds, \"There is a huge population of women who were the victims of war who had to sell their bodies, their souls and they lost it all. It crushes us to see them, but we have to work on it and that\\'s why we started our team of women activists.\" Her team pounds the streets of Baghdad looking for these victims often too humiliated to come forward. \"Most of the women that we find at hospitals [who] have tried to commit suicide\" have been involved in prostitution, said Basma Rahim, a member of Mohammed\\'s team. The team\\'s aim is to compile information on specific cases and present it to Iraq\\'s political parties -- to have them, as Mohammed puts it, \"come tell us what [they] are ... going to do about this.\" Rahim tells the heartbreaking story of one woman they found who lives in a room with three of her children: \"She has sex while her three children are in the room, but she makes them stand in separate corners.\" According to Rahim and Mohammed, most of the women they encounter say they are driven to prostitution by a desperate desire for survival in the dangerously violent and unforgiving circumstances in Iraq. \"They took this path but they are not pleased,\" Rahim says. Karima says when she sees her children with food on the table, she is able to convince herself that it\\'s worth it. \"Everything is for the children. They are the beauty in life and, without them, we cannot live.\" But she says, \"I would never allow my daughter to do this. I would rather marry her off at 13 than have her go through this.\" Karima\\'s last happy memory is of her late husband, when they were a family and able to shoulder the hardships of life in today\\'s Iraq together. Suha says as a young girl she dreamed of being a doctor, with her mom boasting about her potential in that career. Life couldn\\'t have taken her further from that dream. \"It\\'s not like we were born into this, nor was it ever in my blood,\" she says. What she does for her family to survive now eats away at her. \"I lay on my pillow and my brain is spinning, and it all comes back to me as if I am watching a movie.\" E-mail to a friend .',\n",
       "  'BOGOTA, Colombia (CNN) -- A key rebel commander and fugitive from a U.S. drug trafficking indictment was killed over the weekend in an air attack on a guerrilla encampment, the Colombian military said Monday. Alleged cocaine trafficker and FARC rebel Tomas Medina Caracas in an Interpol photo. Tomas Medina Caracas, known popularly as \"El Negro Acacio,\" was a member of the high command of the Fuerzas Armadas Revolucionarias de Colombia and, according to Colombian and U.S. officials, helped manage the group\\'s extensive cocaine trafficking network. He had been in the cross-hairs of the U.S. Justice Department since 2002. He was charged with conspiracy to import cocaine into the United States and manufacturing and distributing cocaine within Colombia to fund the FARC\\'s 42-year insurgency against the government. U.S. officials alleged Medina Caracas managed the rebel group\\'s sales of cocaine to international drug traffickers, who in turn smuggled it into the United States. He was also indicted in the United States along with two other FARC commanders in November 2002 on charges of conspiring to kidnap two U.S. oil workers from neighboring Venezuela in 1997 and holding one of them for nine months until a $1 million ransom was paid. Officials said the army\\'s Rapid Response Force, backed by elements of the Colombian Air Force, tracked Medina Caracas down at a FARC camp in the jungle in the south of the country. \"After a bombardment, the troops occupied the camp, and they\\'ve found 14 dead rebels so far, along with rifles, pistols, communications equipment and ... four GPS systems,\" Defense Minister Juan Manuel Santos said at a news conference. \"The death of \\'El Negro Acacio\\' was confirmed by various sources, including members of FARC itself.\" Medina Caracas commanded FARC\\'s 16th Front in the southern departments of Vichada and Guainia. Established in 1964 as the military wing of the Colombian Communist Party, FARC is Colombia\\'s oldest, largest, most capable and best-equipped Marxist rebel group, according to the U.S. Department of State. E-mail to a friend . Journalist Fernando Ramos contributed to this report.',\n",
       "  'WASHINGTON (CNN) -- White House press secretary Tony Snow, who is undergoing treatment for cancer, will step down from his post September 14 and be replaced by deputy press secretary Dana Perino, the White House announced Friday. White House press secretary Tony Snow will step down from his post on September 14. President Bush told reporters Friday that he will \"sadly accept\" Snow\\'s resignation. Flanked by Snow and Perino in the White House press room, the president spoke warmly of his departing press secretary. \"It\\'s been a joy to watch him spar with you,\" Bush told reporters.  Watch the announcement about Snow leaving » . Bush said he was certain of two things in regard to Snow. \"He\\'ll battle cancer and win,\" Bush said, \"and he\\'ll be a solid contributor to society.\" Turning to Snow, the president then said: \"I love you, and I wish you all the best.\" Snow, speaking after Bush at the start of the daily White House news conference, said he was leaving to earn more money. He took a big pay cut, he said, when he left his previous jobs as anchor and political analyst for Fox News. According to The Washington Post, Snow makes $168,000 as the White House spokesman. His family took out a loan when he started the job, \"and that loan is now gone.\" \"This job has really been a dream for me, a blast. I\\'ve had an enormous amount of fun and satisfaction,\" Snow said. He said he would continue to speak out on issues, and would do \"some radio, some TV, but I don\\'t anticipate full-time anchor duties.\" Snow said he\\'s received great satisfaction from talking to people about his illness. Snow\\'s cancer was diagnosed for the first time in February 2005. His colon was removed, and after six months of treatment, doctors said the cancer was in remission. Perino announced March 27 that Snow\\'s cancer had recurred, and that doctors had removed a growth from his abdomen the day before. Sources told CNN two weeks ago that Snow was planning to leave his job, possibly as early as September. Bush tapped Snow to replace Scott McClellan in April 2006. Snow had been an anchor for \"Fox News Sunday\" and a political analyst for the Fox News Channel, which he joined in 1996. He also hosted \"The Tony Snow Show\" on Fox News Radio. On Thursday, Snow told CNN his health is improving, citing two medical tests this month that found the cancer has not spread. \"The tumors are stable -- they are not growing,\" Snow said of the results from an MRI and a CAT scan. \"And there are no new growths. The health is good.\" The press secretary, whose hair has turned gray during chemotherapy treatment, said his black hair is expected to grow back in about a month. \"I\\'m also putting on weight again,\" he said after returning from a 10-day vacation. \"I actually feel very good about\" the health situation. Snow said on Friday he was to see his oncologist, and they will decide on some minor forms of chemotherapy to start as maintenance treatment. E-mail to a friend .',\n",
       "  '(CNN) -- Police and FBI agents are investigating the discovery of an empty rocket launcher tube on the front lawn of a Jersey City, New Jersey, home, FBI spokesman Sean Quinn said. Niranjan Desai discovered the 20-year-old AT4 anti-tank rocket launcher tube, a one-time-use device, lying on her lawn Friday morning, police said. The launcher has been turned over to U.S. Army officials at the 754th Ordnance Company, an explosive ordnance disposal unit, at Fort Monmouth, New Jersey, Army officials said. The launcher \"is no longer operable and not considered to be a hazard to public safety,\" police said, adding there was no indication the launcher had been fired recently. Army officials said they could not determine if the launcher had been fired, but indicated they should know once they find out where it came from. The nearest military base, Fort Dix, is more than 70 miles from Jersey City. The Joint Terrorism Task Force division of the FBI and Jersey City police are investigating the origin of the rocket launcher and the circumstance that led to its appearance on residential property. \"Al Qaeda doesn\\'t leave a rocket launcher on the lawn of middle-aged ladies,\" said Paul Cruickshank of New York University Law School\\'s Center on Law and Security. A neighbor, Joe Quinn, said the object lying on Desai\\'s lawn looked military, was brown, had a handle and strap, and \"both ends were open, like you could shoot something with it.\" Quinn also said the device had a picture of a soldier on it and was 3 to 4 feet long. An Army official said the device is basically a shoulder-fired, direct-fire weapon used against ground targets -- a modern-day bazooka -- and it is not wire-guided. According to the Web site Globalsecurity.org, a loaded M136 AT4 anti-tank weapon has a 40-inch-long fiberglass-wrapped tube and weighs just 4 pounds. Its 84 millimeter shaped-charge missile can penetrate 14 inches of armor from a maximum of 985 feet. It is used once and discarded. E-mail to a friend . CNN\\'s Carol Cratty, Dugald McConnell, and Mike Mount contributed to this report.'],\n",
       " 'highlights': [\"Harry Potter star Daniel Radcliffe gets £20M fortune as he turns 18 Monday .\\nYoung actor says he has no plans to fritter his cash away .\\nRadcliffe's earnings from first five Potter films have been held in trust fund .\",\n",
       "  'Mentally ill inmates in Miami are housed on the \"forgotten floor\"\\nJudge Steven Leifman says most are there as a result of \"avoidable felonies\"\\nWhile CNN tours facility, patient shouts: \"I am the son of the president\"\\nLeifman says the system is unjust and he\\'s fighting for change .',\n",
       "  'NEW: \"I thought I was going to die,\" driver says .\\nMan says pickup truck was folded in half; he just has cut on face .\\nDriver: \"I probably had a 30-, 35-foot free fall\"\\nMinnesota bridge collapsed during rush hour Wednesday .',\n",
       "  'Five small polyps found during procedure; \"none worrisome,\" spokesman says .\\nPresident reclaims powers transferred to vice president .\\nBush undergoes routine colonoscopy at Camp David .',\n",
       "  \"NEW: NFL chief, Atlanta Falcons owner critical of Michael Vick's conduct .\\nNFL suspends Falcons quarterback indefinitely without pay .\\nVick admits funding dogfighting operation but says he did not gamble .\\nVick due in federal court Monday; future in NFL remains uncertain .\",\n",
       "  'Parents beam with pride, can\\'t stop from smiling from outpouring of support .\\nMom: \"I was so happy I didn\\'t know what to do\"\\nBurn center in U.S. has offered to provide treatment for reconstructive surgeries .\\nDad says, \"Anything for Youssif\"',\n",
       "  'Aid workers: Violence, increased cost of living drive women to prostitution .\\nGroup is working to raise awareness of the problem with Iraq\\'s political leaders .\\nTwo Iraqi mothers tell CNN they turned to prostitution to help feed their children .\\n\"Everything is for the children,\" one woman says .',\n",
       "  'Tomas Medina Caracas was a fugitive from a U.S. drug trafficking indictment .\\n\"El Negro Acacio\" allegedly helped manage extensive cocaine network .\\nU.S. Justice Department indicted him in 2002 .\\nColombian military: He was killed in an attack on a guerrilla encampment .',\n",
       "  'President Bush says Tony Snow \"will battle cancer and win\"  Job of press secretary \"has been a dream for me,\" Snow says  Snow leaving on September 14, will be succeeded by Dana Perino .',\n",
       "  'Empty anti-tank weapon turns up in front of New Jersey home .\\nDevice handed over to Army ordnance disposal unit .\\nWeapon not capable of being reloaded, experts say .'],\n",
       " 'id': ['42c027e4ff9730fbb3de84c1af0d2c506e41c3e4',\n",
       "  'ee8871b15c50d0db17b0179a6d2beab35065f1e9',\n",
       "  '06352019a19ae31e527f37f7571c6dd7f0c5da37',\n",
       "  '24521a2abb2e1f5e34e6824e0f9e56904a2b0e88',\n",
       "  '7fe70cc8b12fab2d0a258fababf7d9c6b5e1262a',\n",
       "  'a1ebb8bb4d370a1fdf28769206d572be60642d70',\n",
       "  '7c0e61ac829a3b3b653e2e3e7536cc4881d1f264',\n",
       "  'f0d73bdab711763e745cdc75850861c9018f235d',\n",
       "  '5e22bbfc7232418b8d2dd646b952e404df5bd048',\n",
       "  '613d6311ec2c1985bd44707d1796d275452fe156']}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = dataset[\"train\"][:10]\n",
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1fa6a1ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'article': ['LONDON, England (Reuters) -- Harry Potter star Daniel Radcliffe gains access to a reported £20 million ($41.1 million) fortune as he turns 18 on Monday, but he insists the money won\\'t cast a spell on him. Daniel Radcliffe as Harry Potter in \"Harry Potter and the Order of the Phoenix\" To the disappointment of gossip columnists around the world, the young actor says he has no plans to fritter his cash away on fast cars, drink and celebrity parties. \"I don\\'t plan to be one of those people who, as soon as they turn 18, suddenly buy themselves a massive sports car collection or something similar,\" he told an Australian interviewer earlier this month. \"I don\\'t think I\\'ll be particularly extravagant. \"The things I like buying are things that cost about 10 pounds -- books and CDs and DVDs.\" At 18, Radcliffe will be able to gamble in a casino, buy a drink in a pub or see the horror film \"Hostel: Part II,\" currently six places below his number one movie on the UK box office chart. Details of how he\\'ll mark his landmark birthday are under wraps. His agent and publicist had no comment on his plans. \"I\\'ll definitely have some sort of party,\" he said in an interview. \"Hopefully none of you will be reading about it.\" Radcliffe\\'s earnings from the first five Potter films have been held in a trust fund which he has not been able to touch. Despite his growing fame and riches, the actor says he is keeping his feet firmly on the ground. \"People are always looking to say \\'kid star goes off the rails,\\'\" he told reporters last month. \"But I try very hard not to go that way because it would be too easy for them.\" His latest outing as the boy wizard in \"Harry Potter and the Order of the Phoenix\" is breaking records on both sides of the Atlantic and he will reprise the role in the last two films.  Watch I-Reporter give her review of Potter\\'s latest » . There is life beyond Potter, however. The Londoner has filmed a TV movie called \"My Boy Jack,\" about author Rudyard Kipling and his son, due for release later this year. He will also appear in \"December Boys,\" an Australian film about four boys who escape an orphanage. Earlier this year, he made his stage debut playing a tortured teenager in Peter Shaffer\\'s \"Equus.\" Meanwhile, he is braced for even closer media scrutiny now that he\\'s legally an adult: \"I just think I\\'m going to be more sort of fair game,\" he told Reuters. E-mail to a friend . Copyright 2007 Reuters. All rights reserved.This material may not be published, broadcast, rewritten, or redistributed.',\n",
       "  'Editor\\'s note: In our Behind the Scenes series, CNN correspondents share their experiences in covering news and analyze the stories behind the events. Here, Soledad O\\'Brien takes users inside a jail where many of the inmates are mentally ill. An inmate housed on the \"forgotten floor,\" where many mentally ill inmates are housed in Miami before trial. MIAMI, Florida (CNN) -- The ninth floor of the Miami-Dade pretrial detention facility is dubbed the \"forgotten floor.\" Here, inmates with the most severe mental illnesses are incarcerated until they\\'re ready to appear in court. Most often, they face drug charges or charges of assaulting an officer --charges that Judge Steven Leifman says are usually \"avoidable felonies.\" He says the arrests often result from confrontations with police. Mentally ill people often won\\'t do what they\\'re told when police arrive on the scene -- confrontation seems to exacerbate their illness and they become more paranoid, delusional, and less likely to follow directions, according to Leifman. So, they end up on the ninth floor severely mentally disturbed, but not getting any real help because they\\'re in jail. We toured the jail with Leifman. He is well known in Miami as an advocate for justice and the mentally ill. Even though we were not exactly welcomed with open arms by the guards, we were given permission to shoot videotape and tour the floor.  Go inside the \\'forgotten floor\\' » . At first, it\\'s hard to determine where the people are. The prisoners are wearing sleeveless robes. Imagine cutting holes for arms and feet in a heavy wool sleeping bag -- that\\'s kind of what they look like. They\\'re designed to keep the mentally ill patients from injuring themselves. That\\'s also why they have no shoes, laces or mattresses. Leifman says about one-third of all people in Miami-Dade county jails are mentally ill. So, he says, the sheer volume is overwhelming the system, and the result is what we see on the ninth floor. Of course, it is a jail, so it\\'s not supposed to be warm and comforting, but the lights glare, the cells are tiny and it\\'s loud. We see two, sometimes three men -- sometimes in the robes, sometimes naked, lying or sitting in their cells. \"I am the son of the president. You need to get me out of here!\" one man shouts at me. He is absolutely serious, convinced that help is on the way -- if only he could reach the White House. Leifman tells me that these prisoner-patients will often circulate through the system, occasionally stabilizing in a mental hospital, only to return to jail to face their charges. It\\'s brutally unjust, in his mind, and he has become a strong advocate for changing things in Miami. Over a meal later, we talk about how things got this way for mental patients. Leifman says 200 years ago people were considered \"lunatics\" and they were locked up in jails even if they had no charges against them. They were just considered unfit to be in society. Over the years, he says, there was some public outcry, and the mentally ill were moved out of jails and into hospitals. But Leifman says many of these mental hospitals were so horrible they were shut down. Where did the patients go? Nowhere. The streets. They became, in many cases, the homeless, he says. They never got treatment. Leifman says in 1955 there were more than half a million people in state mental hospitals, and today that number has been reduced 90 percent, and 40,000 to 50,000 people are in mental hospitals. The judge says he\\'s working to change this. Starting in 2008, many inmates who would otherwise have been brought to the \"forgotten floor\"  will instead be sent to a new mental health facility -- the first step on a journey toward long-term treatment, not just punishment. Leifman says it\\'s not the complete answer, but it\\'s a start. Leifman says the best part is that it\\'s a win-win solution. The patients win, the families are relieved, and the state saves money by simply not cycling these prisoners through again and again. And, for Leifman, justice is served. E-mail to a friend .',\n",
       "  'MINNEAPOLIS, Minnesota (CNN) -- Drivers who were on the Minneapolis bridge when it collapsed told harrowing tales of survival. \"The whole bridge from one side of the Mississippi to the other just completely gave way, fell all the way down,\" survivor Gary Babineau told CNN. \"I probably had a 30-, 35-foot free fall. And there\\'s cars in the water, there\\'s cars on fire. The whole bridge is down.\" He said his back was injured but he determined he could move around. \"I realized there was a school bus right next to me, and me and a couple of other guys went over and started lifting the kids off the bridge. They were yelling, screaming, bleeding. I think there were some broken bones.\"  Watch a driver describe his narrow escape » . At home when he heard about the disaster, Dr. John Hink, an emergency room physician, jumped into his car and rushed to the scene in 15 minutes. He arrived at the south side of the bridge, stood on the riverbank and saw dozens of people lying dazed on an expansive deck. They were in the middle of the Mississippi River, which was churning fast, and he had no way of getting to them. He went to the north side, where there was easier access to people. Ambulances were also having a hard time driving down to the river to get closer to the scene. Working feverishly, volunteers, EMTs and other officials managed to get 55 people into ambulances in less than two hours. Occasionally, a pickup truck with a medic inside would drive to get an injured person and bring him back up even ground, Hink told CNN. The rescue effort was controlled and organized, he said; the opposite of the lightning-quick collapse. \"I could see the whole bridge as it was going down, as it was falling,\" Babineau said. \"It just gave a rumble real quick, and it all just gave way, and it just fell completely, all the way to the ground. And there was dust everywhere and it was just like everyone has been saying: It was just like out of the movies.\" Babineau said the rear of his pickup truck was dangling over the edge of a broken-off section of the bridge. He said several vehicles slid past him into the water. \"I stayed in my car for one or two seconds. I saw a couple cars fall,\" he said. \"So I stayed in my car until the cars quit falling for a second, then I got out real quick, ran in front of my truck -- because behind my truck was just a hole -- and I helped a woman off of the bridge with me. \"I just wanted off the bridge, and then I ran over to the school bus. I started grabbing kids and handing them down. It was just complete chaos.\" He said most of the children were crying or screaming. He and other rescuers set them on the ground and told them to run to the river bank, but a few needed to be carried because of their injuries.  See rescuers clamber over rubble » . Babineau said he had no rescue training. \"I just knew what I had to do at the moment.\" Melissa Hughes, 32, of Minneapolis, told The Associated Press that she was driving home when the western edge of the bridge collapsed under her. \"You know that free-fall feeling? I felt that twice,\" Hughes said. A pickup landed on top of her car, but she was not hurt. \"I had no idea there was a vehicle on my car,\" she told AP. \"It\\'s really very surreal.\" Babineau told the Minneapolis Star-Tribune: \"On the way down, I thought I was dead. I literally thought I was dead. \"My truck was completely face down, pointed toward the ground, and my truck got ripped in half. It was folded in half, and I can\\'t believe I\\'m alive.\"  See and hear eyewitness accounts » . Bernie Toivonen told CNN\\'s \"American Morning\" that his vehicle was on a part of the bridge that ended up tilted at a 45-degree angle. \"I knew the deck was going down, there was no question about it, and I thought I was going to die,\" he said. After the bridge settled and his car remained upright, \"I just put in park, turned the key off and said, \\'Oh, I\\'m alive,\\' \" he said. E-mail to a friend .',\n",
       "  'WASHINGTON (CNN) -- Doctors removed five small polyps from President Bush\\'s colon on Saturday, and \"none appeared worrisome,\" a White House spokesman said. The polyps were removed and sent to the National Naval Medical Center in Bethesda, Maryland, for routine microscopic examination, spokesman Scott Stanzel said. Results are expected in two to three days. All were small, less than a centimeter [half an inch] in diameter, he said. Bush is in good humor, Stanzel said, and will resume his activities at Camp David. During the procedure Vice President Dick Cheney assumed presidential power. Bush reclaimed presidential power at 9:21 a.m. after about two hours. Doctors used \"monitored anesthesia care,\" Stanzel said, so the president was asleep, but not as deeply unconscious as with a true general anesthetic. He spoke to first lady Laura Bush -- who is in Midland, Texas, celebrating her mother\\'s birthday -- before and after the procedure, Stanzel said. Afterward, the president played with his Scottish terriers, Barney and Miss Beazley, Stanzel said. He planned to have lunch at Camp David and have briefings with National Security Adviser Stephen Hadley and White House Chief of Staff Josh Bolten, and planned to take a bicycle ride Saturday afternoon. Cheney, meanwhile, spent the morning at his home on Maryland\\'s eastern shore, reading and playing with his dogs, Stanzel said. Nothing occurred that required him to take official action as president before Bush reclaimed presidential power. The procedure was supervised by Dr. Richard Tubb, Bush\\'s physician, and conducted by a multidisciplinary team from the National Naval Medical Center in Bethesda, Maryland, the White House said. Bush\\'s last colonoscopy was in June 2002, and no abnormalities were found, White House spokesman Tony Snow said. The president\\'s doctor had recommended a repeat procedure in about five years. A colonoscopy is the most sensitive test for colon cancer, rectal cancer and polyps, small clumps of cells that can become cancerous, according to the Mayo Clinic. Small polyps may be removed during the procedure. Snow said on Friday that Bush had polyps removed during colonoscopies before becoming president. Snow himself is undergoing chemotherapy for cancer that began in his colon and spread to his liver.  Watch Snow talk about Bush\\'s procedure and his own colon cancer » . \"The president wants to encourage everybody to use surveillance,\" Snow said. The American Cancer Society recommends that people without high risk factors or symptoms begin getting screened for signs of colorectal cancer at age 50. E-mail to a friend .',\n",
       "  '(CNN)  -- The National Football League has indefinitely suspended Atlanta Falcons quarterback Michael Vick without pay, officials with the league said Friday. NFL star Michael Vick is set to appear in court Monday. A judge will have the final say on a plea deal. Earlier, Vick admitted to participating in a dogfighting ring as part of a plea agreement with federal prosecutors in Virginia. \"Your admitted conduct was not only illegal, but also cruel and reprehensible. Your team, the NFL, and NFL fans have all been hurt by your actions,\" NFL Commissioner Roger Goodell said in a letter to Vick. Goodell said he would review the status of the suspension after the legal proceedings are over. In papers filed Friday with a federal court in Virginia, Vick also admitted that he and two co-conspirators killed dogs that did not fight well. Falcons owner Arthur Blank said Vick\\'s admissions describe actions that are \"incomprehensible and unacceptable.\" The suspension makes \"a strong statement that conduct which tarnishes the good reputation of the NFL will not be tolerated,\" he said in a statement.  Watch what led to Vick\\'s suspension » . Goodell said the Falcons could \"assert any claims or remedies\" to recover $22 million of Vick\\'s signing bonus from the 10-year, $130 million contract he signed in 2004, according to The Associated Press. Vick said he would plead guilty to one count of \"Conspiracy to Travel in Interstate Commerce in Aid of Unlawful Activities and to Sponsor a Dog in an Animal Fighting Venture\" in a plea agreement filed at U.S. District Court in Richmond, Virginia. The charge is punishable by up to five years in prison, a $250,000 fine, \"full restitution, a special assessment and 3 years of supervised release,\" the plea deal said. Federal prosecutors agreed to ask for the low end of the sentencing guidelines. \"The defendant will plead guilty because the defendant is in fact guilty of the charged offense,\" the plea agreement said. In an additional summary of facts, signed by Vick and filed with the agreement, Vick admitted buying pit bulls and the property used for training and fighting the dogs, but the statement said he did not bet on the fights or receive any of the money won. \"Most of the \\'Bad Newz Kennels\\' operations and gambling monies were provided by Vick,\" the official summary of facts said. Gambling wins were generally split among co-conspirators Tony Taylor, Quanis Phillips and sometimes Purnell Peace, it continued. \"Vick did not gamble by placing side bets on any of the fights. Vick did not receive any of the proceeds from the purses that were won by \\'Bad Newz Kennels.\\' \" Vick also agreed that \"collective efforts\" by him and two others caused the deaths of at least six dogs. Around April, Vick, Peace and Phillips tested some dogs in fighting sessions at Vick\\'s property in Virginia, the statement said. \"Peace, Phillips and Vick agreed to the killing of approximately 6-8 dogs that did not perform well in \\'testing\\' sessions at 1915 Moonlight Road and all of those dogs were killed by various methods, including hanging and drowning. \"Vick agrees and stipulates that these dogs all died as a result of the collective efforts of Peace, Phillips and Vick,\" the summary said. Peace, 35, of Virginia Beach, Virginia; Phillips, 28, of Atlanta, Georgia; and Taylor, 34, of Hampton, Virginia, already have accepted agreements to plead guilty in exchange for reduced sentences. Vick, 27, is scheduled to appear Monday in court, where he is expected to plead guilty before a judge.  See a timeline of the case against Vick » . The judge in the case will have the final say over the plea agreement. The federal case against Vick focused on the interstate conspiracy, but Vick\\'s admission that he was involved in the killing of dogs could lead to local charges, according to CNN legal analyst Jeffrey Toobin. \"It sometimes happens -- not often -- that the state will follow a federal prosecution by charging its own crimes for exactly the same behavior,\" Toobin said Friday. \"The risk for Vick is, if he makes admissions in his federal guilty plea, the state of Virginia could say, \\'Hey, look, you admitted violating Virginia state law as well. We\\'re going to introduce that against you and charge you in our court.\\' \" In the plea deal, Vick agreed to cooperate with investigators and provide all information he may have on any criminal activity and to testify if necessary. Vick also agreed to turn over any documents he has and to submit to polygraph tests. Vick agreed to \"make restitution for the full amount of the costs associated\" with the dogs that are being held by the government. \"Such costs may include, but are not limited to, all costs associated with the care of the dogs involved in that case, including if necessary, the long-term care and/or the humane euthanasia of some or all of those animals.\" Prosecutors, with the support of animal rights activists, have asked for permission to euthanize the dogs. But the dogs could serve as important evidence in the cases against Vick and his admitted co-conspirators. Judge Henry E. Hudson issued an order Thursday telling the U.S. Marshals Service to \"arrest and seize the defendant property, and use discretion and whatever means appropriate to protect and maintain said defendant property.\" Both the judge\\'s order and Vick\\'s filing refer to \"approximately\" 53 pit bull dogs. After Vick\\'s indictment last month, Goodell ordered the quarterback not to report to the Falcons training camp, and the league is reviewing the case. Blank told the NFL Network on Monday he could not speculate on Vick\\'s future as a Falcon, at least not until he had seen \"a statement of facts\" in the case.  E-mail to a friend . CNN\\'s Mike Phelan contributed to this report.',\n",
       "  'BAGHDAD, Iraq (CNN) -- Dressed in a Superman shirt, 5-year-old Youssif held his sister\\'s hand Friday, seemingly unaware that millions of people across the world have been touched by his story. Nearby, his parents talked about the new future and hope they have for their boy -- and the potential for recovery from his severe burns. Youssif holds his sister\\'s hand Friday. He\\'s wearing a facial mask often used to help burn victims. It\\'s the best birthday present the Iraqi family could ever have imagined for their boy: Youssif turns 6 next Friday. \"I was so happy I didn\\'t know what to do with myself,\" his mother, Zainab, told CNN, a broad smile across her face. \"I didn\\'t think the reaction would be this big.\" His father said he was on the roof of his house when CNN called him with the news about the outpouring of support for his son. \"We just want to thank everyone who has come forward,\" he said. \"We knew there was kindness out there.\" Like his wife, he couldn\\'t stop smiling. He talked about how he tried in vain to get help for his son in Baghdad, leaving \"no stone unturned\" on a mission to help his boy. There were many trips to the Ministry of Health. He says he even put in a request to Iraq\\'s parliament for help. The family eventually told CNN their story -- that Youssif was grabbed by masked men outside their home on January 15, doused in gasoline and set on fire. Simply by coming forward, his parents put themselves in incredible danger. No one has been arrested or held accountable in Youssif\\'s case.  Watch CNN\\'s Arwa Damon describe \\'truly phenomenal\\' outpouring » . Shortly after Youssif\\'s story aired Wednesday, the Children\\'s Burn Foundation -- a nonprofit organization based in Sherman Oaks, California, that provides support for burn victims locally, nationally and internationally -- agreed to pay for the transportation for Youssif and his family to come to the United States and to set up a fund for donations. You can make a donation at the foundation\\'s site by clicking here. There\\'s a drop-down menu under the \"general donation\" area that is marked \"Youssif\\'s fund.\" The foundation says it will cover all medical costs -- from surgeries for Youssif to housing costs to any social rehabilitation that might be needed for him. Surgeries will be performed by Dr. Peter Grossman, a plastic surgeon with the affiliated Grossman Burn Center who is donating his services for Youssif\\'s cause. Officials are still trying to get the appropriate visas for the family\\'s travels. \"We are prepared to have them come here, set them up in a housing situation, provide support for them and begin treatment,\" said Barbara Friedman, executive director of the Children\\'s Burn Foundation. \"We expect that the treatment will be from between six months to a year with many surgeries.\" She added, \"He will be getting the absolute best care that\\'s available.\" Youssif\\'s parents said they know it\\'s going to be a lengthy and difficult process and that adjusting to their stay in America may not be easy. But none of that matters -- getting help for their boy is first and foremost. \"I will do anything for Youssif,\" his father said, pulling his son closer to him. \"Our child is everything.\" His mother tried to coax Youssif to talk to us on this day. But he didn\\'t want to; his mother says he\\'s shy outside of their home. The biggest obstacle now is getting the visas to leave, and the serious security risks they face every day and hour they remain in Iraq. But this family -- which saw the very worst in humanity on that January day -- has new hope in the world. That is partly due to the tens of thousands of CNN.com users who were so moved by the story and wanted to act. CNN Iraqi staff central to bringing this story together were also overwhelmed with the generosity coming from people outside of their border. In a nation that largely feels abandoned by the rest of the world, it was a refreshing realization. E-mail to a friend . CNN.com senior producer Wayne Drash contributed to this report in Atlanta.',\n",
       "  'BAGHDAD, Iraq (CNN) -- The women are too afraid and ashamed to show their faces or have their real names used. They have been driven to sell their bodies to put food on the table for their children -- for as little as $8 a day. Suha, 37, is a mother of three. She says her husband thinks she is cleaning houses when she leaves home. \"People shouldn\\'t criticize women, or talk badly about them,\" says 37-year-old Suha as she adjusts the light colored scarf she wears these days to avoid extremists who insist women cover themselves. \"They all say we have lost our way, but they never ask why we had to take this path.\" A mother of three, she wears light makeup, a gold pendant of Iraq around her neck, and an unexpected air of elegance about her. \"I don\\'t have money to take my kid to the doctor. I have to do anything that I can to preserve my child, because I am a mother,\" she says, explaining why she prostitutes herself. Anger and frustration rise in her voice as she speaks. \"No matter what else I may be, no matter how off the path I may be, I am a mother!\"  Watch a woman describe turning to prostitution to \"save my child\" » . Her clasped hands clench and unclench nervously. Suha\\'s husband thinks that she is cleaning houses when she goes away. So does Karima\\'s family. \"At the start I was cleaning homes, but I wasn\\'t making much. No matter how hard I worked it just wasn\\'t enough,\" she says. Karima, clad in all black, adds, \"My husband died of lung cancer nine months ago and left me with nothing.\" She has five children, ages 8 to 17. Her eldest son could work, but she\\'s too afraid for his life to let him go into the streets, preferring to sacrifice herself than risk her child. She was solicited the first time when she was cleaning an office. \"They took advantage of me,\" she says softly. \"At first I rejected it, but then I realized I have to do it.\" Both Suha and Karima have clients that call them a couple times a week. Other women resort to trips to the market to find potential clients. Or they flag down vehicles. Prostitution is a choice more and more Iraqi women are making just to survive. \"It\\'s increasing,\" Suha says. \"I found this \\'thing\\' through my friend, and I have another friend in the same predicament as mine. Because of the circumstance, she is forced to do such things.\" Violence, increased cost of living, and lack of any sort of government aid leave women like these with few other options, according to humanitarian workers. \"At this point there is a population of women who have to sell their bodies in order to keep their children alive,\" says Yanar Mohammed, head and founder of the Organization for Women\\'s Freedom in Iraq. \"It\\'s a taboo that no one is speaking about.\" She adds, \"There is a huge population of women who were the victims of war who had to sell their bodies, their souls and they lost it all. It crushes us to see them, but we have to work on it and that\\'s why we started our team of women activists.\" Her team pounds the streets of Baghdad looking for these victims often too humiliated to come forward. \"Most of the women that we find at hospitals [who] have tried to commit suicide\" have been involved in prostitution, said Basma Rahim, a member of Mohammed\\'s team. The team\\'s aim is to compile information on specific cases and present it to Iraq\\'s political parties -- to have them, as Mohammed puts it, \"come tell us what [they] are ... going to do about this.\" Rahim tells the heartbreaking story of one woman they found who lives in a room with three of her children: \"She has sex while her three children are in the room, but she makes them stand in separate corners.\" According to Rahim and Mohammed, most of the women they encounter say they are driven to prostitution by a desperate desire for survival in the dangerously violent and unforgiving circumstances in Iraq. \"They took this path but they are not pleased,\" Rahim says. Karima says when she sees her children with food on the table, she is able to convince herself that it\\'s worth it. \"Everything is for the children. They are the beauty in life and, without them, we cannot live.\" But she says, \"I would never allow my daughter to do this. I would rather marry her off at 13 than have her go through this.\" Karima\\'s last happy memory is of her late husband, when they were a family and able to shoulder the hardships of life in today\\'s Iraq together. Suha says as a young girl she dreamed of being a doctor, with her mom boasting about her potential in that career. Life couldn\\'t have taken her further from that dream. \"It\\'s not like we were born into this, nor was it ever in my blood,\" she says. What she does for her family to survive now eats away at her. \"I lay on my pillow and my brain is spinning, and it all comes back to me as if I am watching a movie.\" E-mail to a friend .',\n",
       "  'BOGOTA, Colombia (CNN) -- A key rebel commander and fugitive from a U.S. drug trafficking indictment was killed over the weekend in an air attack on a guerrilla encampment, the Colombian military said Monday. Alleged cocaine trafficker and FARC rebel Tomas Medina Caracas in an Interpol photo. Tomas Medina Caracas, known popularly as \"El Negro Acacio,\" was a member of the high command of the Fuerzas Armadas Revolucionarias de Colombia and, according to Colombian and U.S. officials, helped manage the group\\'s extensive cocaine trafficking network. He had been in the cross-hairs of the U.S. Justice Department since 2002. He was charged with conspiracy to import cocaine into the United States and manufacturing and distributing cocaine within Colombia to fund the FARC\\'s 42-year insurgency against the government. U.S. officials alleged Medina Caracas managed the rebel group\\'s sales of cocaine to international drug traffickers, who in turn smuggled it into the United States. He was also indicted in the United States along with two other FARC commanders in November 2002 on charges of conspiring to kidnap two U.S. oil workers from neighboring Venezuela in 1997 and holding one of them for nine months until a $1 million ransom was paid. Officials said the army\\'s Rapid Response Force, backed by elements of the Colombian Air Force, tracked Medina Caracas down at a FARC camp in the jungle in the south of the country. \"After a bombardment, the troops occupied the camp, and they\\'ve found 14 dead rebels so far, along with rifles, pistols, communications equipment and ... four GPS systems,\" Defense Minister Juan Manuel Santos said at a news conference. \"The death of \\'El Negro Acacio\\' was confirmed by various sources, including members of FARC itself.\" Medina Caracas commanded FARC\\'s 16th Front in the southern departments of Vichada and Guainia. Established in 1964 as the military wing of the Colombian Communist Party, FARC is Colombia\\'s oldest, largest, most capable and best-equipped Marxist rebel group, according to the U.S. Department of State. E-mail to a friend . Journalist Fernando Ramos contributed to this report.',\n",
       "  'WASHINGTON (CNN) -- White House press secretary Tony Snow, who is undergoing treatment for cancer, will step down from his post September 14 and be replaced by deputy press secretary Dana Perino, the White House announced Friday. White House press secretary Tony Snow will step down from his post on September 14. President Bush told reporters Friday that he will \"sadly accept\" Snow\\'s resignation. Flanked by Snow and Perino in the White House press room, the president spoke warmly of his departing press secretary. \"It\\'s been a joy to watch him spar with you,\" Bush told reporters.  Watch the announcement about Snow leaving » . Bush said he was certain of two things in regard to Snow. \"He\\'ll battle cancer and win,\" Bush said, \"and he\\'ll be a solid contributor to society.\" Turning to Snow, the president then said: \"I love you, and I wish you all the best.\" Snow, speaking after Bush at the start of the daily White House news conference, said he was leaving to earn more money. He took a big pay cut, he said, when he left his previous jobs as anchor and political analyst for Fox News. According to The Washington Post, Snow makes $168,000 as the White House spokesman. His family took out a loan when he started the job, \"and that loan is now gone.\" \"This job has really been a dream for me, a blast. I\\'ve had an enormous amount of fun and satisfaction,\" Snow said. He said he would continue to speak out on issues, and would do \"some radio, some TV, but I don\\'t anticipate full-time anchor duties.\" Snow said he\\'s received great satisfaction from talking to people about his illness. Snow\\'s cancer was diagnosed for the first time in February 2005. His colon was removed, and after six months of treatment, doctors said the cancer was in remission. Perino announced March 27 that Snow\\'s cancer had recurred, and that doctors had removed a growth from his abdomen the day before. Sources told CNN two weeks ago that Snow was planning to leave his job, possibly as early as September. Bush tapped Snow to replace Scott McClellan in April 2006. Snow had been an anchor for \"Fox News Sunday\" and a political analyst for the Fox News Channel, which he joined in 1996. He also hosted \"The Tony Snow Show\" on Fox News Radio. On Thursday, Snow told CNN his health is improving, citing two medical tests this month that found the cancer has not spread. \"The tumors are stable -- they are not growing,\" Snow said of the results from an MRI and a CAT scan. \"And there are no new growths. The health is good.\" The press secretary, whose hair has turned gray during chemotherapy treatment, said his black hair is expected to grow back in about a month. \"I\\'m also putting on weight again,\" he said after returning from a 10-day vacation. \"I actually feel very good about\" the health situation. Snow said on Friday he was to see his oncologist, and they will decide on some minor forms of chemotherapy to start as maintenance treatment. E-mail to a friend .',\n",
       "  '(CNN) -- Police and FBI agents are investigating the discovery of an empty rocket launcher tube on the front lawn of a Jersey City, New Jersey, home, FBI spokesman Sean Quinn said. Niranjan Desai discovered the 20-year-old AT4 anti-tank rocket launcher tube, a one-time-use device, lying on her lawn Friday morning, police said. The launcher has been turned over to U.S. Army officials at the 754th Ordnance Company, an explosive ordnance disposal unit, at Fort Monmouth, New Jersey, Army officials said. The launcher \"is no longer operable and not considered to be a hazard to public safety,\" police said, adding there was no indication the launcher had been fired recently. Army officials said they could not determine if the launcher had been fired, but indicated they should know once they find out where it came from. The nearest military base, Fort Dix, is more than 70 miles from Jersey City. The Joint Terrorism Task Force division of the FBI and Jersey City police are investigating the origin of the rocket launcher and the circumstance that led to its appearance on residential property. \"Al Qaeda doesn\\'t leave a rocket launcher on the lawn of middle-aged ladies,\" said Paul Cruickshank of New York University Law School\\'s Center on Law and Security. A neighbor, Joe Quinn, said the object lying on Desai\\'s lawn looked military, was brown, had a handle and strap, and \"both ends were open, like you could shoot something with it.\" Quinn also said the device had a picture of a soldier on it and was 3 to 4 feet long. An Army official said the device is basically a shoulder-fired, direct-fire weapon used against ground targets -- a modern-day bazooka -- and it is not wire-guided. According to the Web site Globalsecurity.org, a loaded M136 AT4 anti-tank weapon has a 40-inch-long fiberglass-wrapped tube and weighs just 4 pounds. Its 84 millimeter shaped-charge missile can penetrate 14 inches of armor from a maximum of 985 feet. It is used once and discarded. E-mail to a friend . CNN\\'s Carol Cratty, Dugald McConnell, and Mike Mount contributed to this report.'],\n",
       " 'highlights': [\"Harry Potter star Daniel Radcliffe gets £20M fortune as he turns 18 Monday .\\nYoung actor says he has no plans to fritter his cash away .\\nRadcliffe's earnings from first five Potter films have been held in trust fund .\",\n",
       "  'Mentally ill inmates in Miami are housed on the \"forgotten floor\"\\nJudge Steven Leifman says most are there as a result of \"avoidable felonies\"\\nWhile CNN tours facility, patient shouts: \"I am the son of the president\"\\nLeifman says the system is unjust and he\\'s fighting for change .',\n",
       "  'NEW: \"I thought I was going to die,\" driver says .\\nMan says pickup truck was folded in half; he just has cut on face .\\nDriver: \"I probably had a 30-, 35-foot free fall\"\\nMinnesota bridge collapsed during rush hour Wednesday .',\n",
       "  'Five small polyps found during procedure; \"none worrisome,\" spokesman says .\\nPresident reclaims powers transferred to vice president .\\nBush undergoes routine colonoscopy at Camp David .',\n",
       "  \"NEW: NFL chief, Atlanta Falcons owner critical of Michael Vick's conduct .\\nNFL suspends Falcons quarterback indefinitely without pay .\\nVick admits funding dogfighting operation but says he did not gamble .\\nVick due in federal court Monday; future in NFL remains uncertain .\",\n",
       "  'Parents beam with pride, can\\'t stop from smiling from outpouring of support .\\nMom: \"I was so happy I didn\\'t know what to do\"\\nBurn center in U.S. has offered to provide treatment for reconstructive surgeries .\\nDad says, \"Anything for Youssif\"',\n",
       "  'Aid workers: Violence, increased cost of living drive women to prostitution .\\nGroup is working to raise awareness of the problem with Iraq\\'s political leaders .\\nTwo Iraqi mothers tell CNN they turned to prostitution to help feed their children .\\n\"Everything is for the children,\" one woman says .',\n",
       "  'Tomas Medina Caracas was a fugitive from a U.S. drug trafficking indictment .\\n\"El Negro Acacio\" allegedly helped manage extensive cocaine network .\\nU.S. Justice Department indicted him in 2002 .\\nColombian military: He was killed in an attack on a guerrilla encampment .',\n",
       "  'President Bush says Tony Snow \"will battle cancer and win\"  Job of press secretary \"has been a dream for me,\" Snow says  Snow leaving on September 14, will be succeeded by Dana Perino .',\n",
       "  'Empty anti-tank weapon turns up in front of New Jersey home .\\nDevice handed over to Army ordnance disposal unit .\\nWeapon not capable of being reloaded, experts say .'],\n",
       " 'id': ['42c027e4ff9730fbb3de84c1af0d2c506e41c3e4',\n",
       "  'ee8871b15c50d0db17b0179a6d2beab35065f1e9',\n",
       "  '06352019a19ae31e527f37f7571c6dd7f0c5da37',\n",
       "  '24521a2abb2e1f5e34e6824e0f9e56904a2b0e88',\n",
       "  '7fe70cc8b12fab2d0a258fababf7d9c6b5e1262a',\n",
       "  'a1ebb8bb4d370a1fdf28769206d572be60642d70',\n",
       "  '7c0e61ac829a3b3b653e2e3e7536cc4881d1f264',\n",
       "  'f0d73bdab711763e745cdc75850861c9018f235d',\n",
       "  '5e22bbfc7232418b8d2dd646b952e404df5bd048',\n",
       "  '613d6311ec2c1985bd44707d1796d275452fe156']}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "978733d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Article (excerpt of 500 characters, total length: 4051):\n",
      "\n",
      "Editor's note: In our Behind the Scenes series, CNN correspondents share their experiences in covering news and analyze the stories behind the events. Here, Soledad O'Brien takes users inside a jail where many of the inmates are mentally ill. An inmate housed on the \"forgotten floor,\" where many mentally ill inmates are housed in Miami before trial. MIAMI, Florida (CNN) -- The ninth floor of the Miami-Dade pretrial detention facility is dubbed the \"forgotten floor.\" Here, inmates with the most s\n",
      "\n",
      "Summary (length: 281):\n",
      "Mentally ill inmates in Miami are housed on the \"forgotten floor\"\n",
      "Judge Steven Leifman says most are there as a result of \"avoidable felonies\"\n",
      "While CNN tours facility, patient shouts: \"I am the son of the president\"\n",
      "Leifman says the system is unjust and he's fighting for change .\n"
     ]
    }
   ],
   "source": [
    "\n",
    "sample = dataset[\"train\"][1]\n",
    "print(f\"\"\"\n",
    "Article (excerpt of 500 characters, total length: {len(sample[\"article\"])}):\n",
    "\"\"\")\n",
    "print(sample[\"article\"][:500])\n",
    "print(f'\\nSummary (length: {len(sample[\"highlights\"])}):')\n",
    "print(sample[\"highlights\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9c6575e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_text = dataset[\"train\"][1][\"article\"][:2000]\n",
    "# We'll collect the generated summaries of each model in a dictionary\n",
    "summaries = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e245f379",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Editor\\'s note: In our Behind the Scenes series, CNN correspondents share their experiences in covering news and analyze the stories behind the events. Here, Soledad O\\'Brien takes users inside a jail where many of the inmates are mentally ill. An inmate housed on the \"forgotten floor,\" where many mentally ill inmates are housed in Miami before trial. MIAMI, Florida (CNN) -- The ninth floor of the Miami-Dade pretrial detention facility is dubbed the \"forgotten floor.\" Here, inmates with the most severe mental illnesses are incarcerated until they\\'re ready to appear in court. Most often, they face drug charges or charges of assaulting an officer --charges that Judge Steven Leifman says are usually \"avoidable felonies.\" He says the arrests often result from confrontations with police. Mentally ill people often won\\'t do what they\\'re told when police arrive on the scene -- confrontation seems to exacerbate their illness and they become more paranoid, delusional, and less likely to follow directions, according to Leifman. So, they end up on the ninth floor severely mentally disturbed, but not getting any real help because they\\'re in jail. We toured the jail with Leifman. He is well known in Miami as an advocate for justice and the mentally ill. Even though we were not exactly welcomed with open arms by the guards, we were given permission to shoot videotape and tour the floor.  Go inside the \\'forgotten floor\\' » . At first, it\\'s hard to determine where the people are. The prisoners are wearing sleeveless robes. Imagine cutting holes for arms and feet in a heavy wool sleeping bag -- that\\'s kind of what they look like. They\\'re designed to keep the mentally ill patients from injuring themselves. That\\'s also why they have no shoes, laces or mattresses. Leifman says about one-third of all people in Miami-Dade county jails are mentally ill. So, he says, the sheer volume is overwhelming the system, and the result is what we see on the ninth floor. Of course, it is a jail, so it\\'s '"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8cfd2053",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\sshuser\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "nltk.download(\"punkt_tab\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "acb6c462",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The U.S. are a country.', 'The U.N. is an organization.']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string = \"The U.S. are a country. The U.N. is an organization.\"\n",
    "sent_tokenize(string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eb18141e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def three_sentence_summary(text):\n",
    "    return \"\\n\".join(sent_tokenize(text)[:3])\n",
    "     \n",
    "\n",
    "summaries[\"baseline\"] = three_sentence_summary(sample_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "36a99c5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Editor's note: In our Behind the Scenes series, CNN correspondents share their experiences in covering news and analyze the stories behind the events.\n",
      "Here, Soledad O'Brien takes users inside a jail where many of the inmates are mentally ill. An inmate housed on the \"forgotten floor,\" where many mentally ill inmates are housed in Miami before trial.\n",
      "MIAMI, Florida (CNN) -- The ninth floor of the Miami-Dade pretrial detention facility is dubbed the \"forgotten floor.\"\n"
     ]
    }
   ],
   "source": [
    "print(summaries[\"baseline\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5b4050a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Editor's note: In our Behind the Scenes series, CNN correspondents share their experiences in covering news and analyze the stories behind the events.\",\n",
       " 'Here, Soledad O\\'Brien takes users inside a jail where many of the inmates are mentally ill. An inmate housed on the \"forgotten floor,\" where many mentally ill inmates are housed in Miami before trial.',\n",
       " 'MIAMI, Florida (CNN) -- The ninth floor of the Miami-Dade pretrial detention facility is dubbed the \"forgotten floor.\"',\n",
       " \"Here, inmates with the most severe mental illnesses are incarcerated until they're ready to appear in court.\",\n",
       " 'Most often, they face drug charges or charges of assaulting an officer --charges that Judge Steven Leifman says are usually \"avoidable felonies.\"',\n",
       " 'He says the arrests often result from confrontations with police.',\n",
       " \"Mentally ill people often won't do what they're told when police arrive on the scene -- confrontation seems to exacerbate their illness and they become more paranoid, delusional, and less likely to follow directions, according to Leifman.\",\n",
       " \"So, they end up on the ninth floor severely mentally disturbed, but not getting any real help because they're in jail.\",\n",
       " 'We toured the jail with Leifman.',\n",
       " 'He is well known in Miami as an advocate for justice and the mentally ill.',\n",
       " 'Even though we were not exactly welcomed with open arms by the guards, we were given permission to shoot videotape and tour the floor.',\n",
       " \"Go inside the 'forgotten floor' » .\",\n",
       " \"At first, it's hard to determine where the people are.\",\n",
       " 'The prisoners are wearing sleeveless robes.',\n",
       " \"Imagine cutting holes for arms and feet in a heavy wool sleeping bag -- that's kind of what they look like.\",\n",
       " \"They're designed to keep the mentally ill patients from injuring themselves.\",\n",
       " \"That's also why they have no shoes, laces or mattresses.\",\n",
       " 'Leifman says about one-third of all people in Miami-Dade county jails are mentally ill.',\n",
       " 'So, he says, the sheer volume is overwhelming the system, and the result is what we see on the ninth floor.',\n",
       " \"Of course, it is a jail, so it's\"]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_tokenize(sample_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e5ed1995",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=512) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mentally ill aren't being treated properly and are being housed in an environment that is not conducive to their care.\n",
      "The inmates are living on the ninth floor of the jail, a place where there are no beds and no proper ventilation.\n",
      "The mentally ill inmates are not getting any help and are instead getting worse.\n",
      "The mentally ill inmates are often violent at times, but it could be for a variety of reasons.\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline, set_seed\n",
    "\n",
    "set_seed(42)\n",
    "pipe = pipeline(\"text-generation\", model=\"gpt2-xl\")\n",
    "gpt2_query = sample_text + \"\\nTL;DR:\\n\"\n",
    "pipe_out = pipe(gpt2_query, max_length=512, clean_up_tokenization_spaces=True)\n",
    "summaries[\"gpt2\"] = \"\\n\".join(\n",
    "    sent_tokenize(pipe_out[0][\"generated_text\"][len(gpt2_query) :])\n",
    ")\n",
    "print(summaries[\"gpt2\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "53984ceb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"The mentally ill aren't being treated properly and are being housed in an environment that is not conducive to their care.\\nThe inmates are living on the ninth floor of the jail, a place where there are no beds and no proper ventilation.\\nThe mentally ill inmates are not getting any help and are instead getting worse.\\nThe mentally ill inmates are often violent at times, but it could be for a variety of reasons.\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summaries[\"gpt2\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c50cfd23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Editor\\'s note: In our Behind the Scenes series, CNN correspondents share their experiences in covering news and analyze the stories behind the events. Here, Soledad O\\'Brien takes users inside a jail where many of the inmates are mentally ill. An inmate housed on the \"forgotten floor,\" where many mentally ill inmates are housed in Miami before trial. MIAMI, Florida (CNN) -- The ninth floor of the Miami-Dade pretrial detention facility is dubbed the \"forgotten floor.\" Here, inmates with the most severe mental illnesses are incarcerated until they\\'re ready to appear in court. Most often, they face drug charges or charges of assaulting an officer --charges that Judge Steven Leifman says are usually \"avoidable felonies.\" He says the arrests often result from confrontations with police. Mentally ill people often won\\'t do what they\\'re told when police arrive on the scene -- confrontation seems to exacerbate their illness and they become more paranoid, delusional, and less likely to follow directions, according to Leifman. So, they end up on the ninth floor severely mentally disturbed, but not getting any real help because they\\'re in jail. We toured the jail with Leifman. He is well known in Miami as an advocate for justice and the mentally ill. Even though we were not exactly welcomed with open arms by the guards, we were given permission to shoot videotape and tour the floor.  Go inside the \\'forgotten floor\\' » . At first, it\\'s hard to determine where the people are. The prisoners are wearing sleeveless robes. Imagine cutting holes for arms and feet in a heavy wool sleeping bag -- that\\'s kind of what they look like. They\\'re designed to keep the mentally ill patients from injuring themselves. That\\'s also why they have no shoes, laces or mattresses. Leifman says about one-third of all people in Miami-Dade county jails are mentally ill. So, he says, the sheer volume is overwhelming the system, and the result is what we see on the ninth floor. Of course, it is a jail, so it\\'s \\nTL;DR:\\n'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpt2_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8cf11b85",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "pipe = pipeline(\"summarization\", model=\"t5-small\")\n",
    "pipe_out = pipe(sample_text)\n",
    "summaries[\"t5\"] = \"\\n\".join(sent_tokenize(pipe_out[0][\"summary_text\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "12668196",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inmates with most severe mental illnesses are incarcerated until they're ready to appear in court .\n",
      "most often, they face drug charges or charges of assaulting an officer .\n",
      "they end up on the ninth floor severely mentally disturbed, but not getting real help .\n"
     ]
    }
   ],
   "source": [
    "print(summaries[\"t5\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d8541cb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "#hide_output\n",
    "pipe = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\")\n",
    "pipe_out = pipe(sample_text)\n",
    "summaries[\"bart\"] = \"\\n\".join(sent_tokenize(pipe_out[0][\"summary_text\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "22f07ad4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mentally ill inmates are housed on the \"forgotten floor\" of Miami-Dade jail.\n",
      "Most often, they face drug charges or charges of assaulting an officer.\n",
      "Judge Steven Leifman says the arrests often result from confrontations with police.\n",
      "He says about one-third of all people in the county jails are mentally ill.\n"
     ]
    }
   ],
   "source": [
    "print(summaries[\"bart\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "24d60b9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of PegasusForConditionalGeneration were not initialized from the model checkpoint at google/pegasus-cnn_dailymail and are newly initialized: ['model.decoder.embed_positions.weight', 'model.encoder.embed_positions.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "pipe = pipeline(\"summarization\", model=\"google/pegasus-cnn_dailymail\")\n",
    "pipe_out = pipe(sample_text)\n",
    "summaries[\"pegasus\"] = pipe_out[0][\"summary_text\"].replace(\" .\", \".\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e0c14a4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mentally ill inmates are housed on the \"forgotten floor\" of a Miami jail.\n",
      "<n>Judge Steven Leifman says most are charged with \"avoidable felonies\"<n>Leifman says confrontations with police exacerbate mental illness.\n",
      "<n>Prisoners have no shoes, laces or mattresses.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(summaries[\"pegasus\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2af485c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GROUND TRUTH\n",
      "Mentally ill inmates in Miami are housed on the \"forgotten floor\"\n",
      "Judge Steven Leifman says most are there as a result of \"avoidable felonies\"\n",
      "While CNN tours facility, patient shouts: \"I am the son of the president\"\n",
      "Leifman says the system is unjust and he's fighting for change .\n",
      "\n",
      "BASELINE\n",
      "Editor's note: In our Behind the Scenes series, CNN correspondents share their experiences in covering news and analyze the stories behind the events.\n",
      "Here, Soledad O'Brien takes users inside a jail where many of the inmates are mentally ill. An inmate housed on the \"forgotten floor,\" where many mentally ill inmates are housed in Miami before trial.\n",
      "MIAMI, Florida (CNN) -- The ninth floor of the Miami-Dade pretrial detention facility is dubbed the \"forgotten floor.\"\n",
      "\n",
      "GPT2\n",
      "The mentally ill aren't being treated properly and are being housed in an environment that is not conducive to their care.\n",
      "The inmates are living on the ninth floor of the jail, a place where there are no beds and no proper ventilation.\n",
      "The mentally ill inmates are not getting any help and are instead getting worse.\n",
      "The mentally ill inmates are often violent at times, but it could be for a variety of reasons.\n",
      "\n",
      "T5\n",
      "inmates with most severe mental illnesses are incarcerated until they're ready to appear in court .\n",
      "most often, they face drug charges or charges of assaulting an officer .\n",
      "they end up on the ninth floor severely mentally disturbed, but not getting real help .\n",
      "\n",
      "BART\n",
      "Mentally ill inmates are housed on the \"forgotten floor\" of Miami-Dade jail.\n",
      "Most often, they face drug charges or charges of assaulting an officer.\n",
      "Judge Steven Leifman says the arrests often result from confrontations with police.\n",
      "He says about one-third of all people in the county jails are mentally ill.\n",
      "\n",
      "PEGASUS\n",
      "Mentally ill inmates are housed on the \"forgotten floor\" of a Miami jail.\n",
      "<n>Judge Steven Leifman says most are charged with \"avoidable felonies\"<n>Leifman says confrontations with police exacerbate mental illness.\n",
      "<n>Prisoners have no shoes, laces or mattresses.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"GROUND TRUTH\")\n",
    "print(dataset[\"train\"][1][\"highlights\"])\n",
    "print(\"\")\n",
    "\n",
    "for model_name in summaries:\n",
    "    print(model_name.upper())\n",
    "    print(summaries[model_name])\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b651677e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "\n",
    "bleu_metric = evaluate.load(\"sacrebleu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "884e0a23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>score</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>counts</th>\n",
       "      <td>[2, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>totals</th>\n",
       "      <td>[6, 5, 4, 3]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precisions</th>\n",
       "      <td>[33.33, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bp</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sys_len</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ref_len</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Value\n",
       "score                          0.0\n",
       "counts                [2, 0, 0, 0]\n",
       "totals                [6, 5, 4, 3]\n",
       "precisions  [33.33, 0.0, 0.0, 0.0]\n",
       "bp                             1.0\n",
       "sys_len                          6\n",
       "ref_len                          6"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "bleu_metric.add(\n",
    "    prediction=\"the the the the the the\", reference=[\"the cat is on the mat\"])\n",
    "\n",
    "results = bleu_metric.compute(smooth_method=\"floor\", smooth_value=0)\n",
    "results[\"precisions\"] = [np.round(p, 2) for p in results[\"precisions\"]]\n",
    "pd.DataFrame.from_dict(results, orient=\"index\", columns=[\"Value\"])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "97aa4a6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>score</th>\n",
       "      <td>57.893007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>counts</th>\n",
       "      <td>[5, 3, 2, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>totals</th>\n",
       "      <td>[5, 4, 3, 2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precisions</th>\n",
       "      <td>[100.0, 75.0, 66.67, 50.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bp</th>\n",
       "      <td>0.818731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sys_len</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ref_len</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Value\n",
       "score                        57.893007\n",
       "counts                    [5, 3, 2, 1]\n",
       "totals                    [5, 4, 3, 2]\n",
       "precisions  [100.0, 75.0, 66.67, 50.0]\n",
       "bp                            0.818731\n",
       "sys_len                              5\n",
       "ref_len                              6"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bleu_metric.add(\n",
    "    prediction=\"the cat is on mat\", reference=[\"the cat is on the mat\"])\n",
    "\n",
    "results = bleu_metric.compute(smooth_method=\"floor\", smooth_value=0)\n",
    "results[\"precisions\"] = [np.round(p, 2) for p in results[\"precisions\"]]\n",
    "pd.DataFrame.from_dict(results, orient=\"index\", columns=[\"Value\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4583be13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rouge1</th>\n",
       "      <th>rouge2</th>\n",
       "      <th>rougeL</th>\n",
       "      <th>rougeLsum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>baseline</th>\n",
       "      <td>0.365079</td>\n",
       "      <td>0.145161</td>\n",
       "      <td>0.206349</td>\n",
       "      <td>0.285714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt2</th>\n",
       "      <td>0.320000</td>\n",
       "      <td>0.065041</td>\n",
       "      <td>0.192000</td>\n",
       "      <td>0.304000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t5</th>\n",
       "      <td>0.195652</td>\n",
       "      <td>0.022222</td>\n",
       "      <td>0.108696</td>\n",
       "      <td>0.173913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bart</th>\n",
       "      <td>0.475248</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.316832</td>\n",
       "      <td>0.415842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pegasus</th>\n",
       "      <td>0.488889</td>\n",
       "      <td>0.318182</td>\n",
       "      <td>0.422222</td>\n",
       "      <td>0.466667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            rouge1    rouge2    rougeL  rougeLsum\n",
       "baseline  0.365079  0.145161  0.206349   0.285714\n",
       "gpt2      0.320000  0.065041  0.192000   0.304000\n",
       "t5        0.195652  0.022222  0.108696   0.173913\n",
       "bart      0.475248  0.222222  0.316832   0.415842\n",
       "pegasus   0.488889  0.318182  0.422222   0.466667"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "rouge_metric = evaluate.load(\"rouge\")\n",
    "     \n",
    "\n",
    "reference = dataset[\"train\"][1][\"highlights\"]\n",
    "records = []\n",
    "rouge_names = [\"rouge1\", \"rouge2\", \"rougeL\", \"rougeLsum\"]\n",
    "\n",
    "for model_name in summaries:\n",
    "    rouge_metric.add(prediction=summaries[model_name], reference=reference)\n",
    "    score = rouge_metric.compute()\n",
    "    rouge_dict = {rn: score[rn] for rn in rouge_names}\n",
    "    records.append(rouge_dict)\n",
    "pd.DataFrame.from_records(records, index=summaries.keys())\n",
    "     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0352cb3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_summaries_baseline(dataset, metric,\n",
    "                                column_text=\"article\", \n",
    "                                column_summary=\"highlights\"):\n",
    "    summaries = [three_sentence_summary(text) for text in dataset[column_text]]\n",
    "    metric.add_batch(predictions=summaries,\n",
    "                     references=dataset[column_summary])    \n",
    "    score = metric.compute()\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "82c1928c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rouge1</th>\n",
       "      <th>rouge2</th>\n",
       "      <th>rougeL</th>\n",
       "      <th>rougeLsum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>baseline</th>\n",
       "      <td>0.389276</td>\n",
       "      <td>0.171296</td>\n",
       "      <td>0.245061</td>\n",
       "      <td>0.354239</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            rouge1    rouge2    rougeL  rougeLsum\n",
       "baseline  0.389276  0.171296  0.245061   0.354239"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sampled = dataset[\"test\"].shuffle(seed=42).select(range(1000))\n",
    "\n",
    "score = evaluate_summaries_baseline(test_sampled, rouge_metric)\n",
    "rouge_dict = dict((rn, score[rn]) for rn in rouge_names)\n",
    "pd.DataFrame.from_dict(rouge_dict, orient=\"index\", columns=[\"baseline\"]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "32396242",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rouge1': np.float64(0.38927595912508084),\n",
       " 'rouge2': np.float64(0.17129582477214172),\n",
       " 'rougeL': np.float64(0.24506081279840572),\n",
       " 'rougeLsum': np.float64(0.35423930222104383)}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5e5aa8bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EvaluationModule(name: \"rouge\", module_type: \"metric\", features: [{'predictions': Value('string'), 'references': List(Value('string'))}, {'predictions': Value('string'), 'references': Value('string')}], usage: \"\"\"\n",
       "Calculates average rouge scores for a list of hypotheses and references\n",
       "Args:\n",
       "    predictions: list of predictions to score. Each prediction\n",
       "        should be a string with tokens separated by spaces.\n",
       "    references: list of reference for each prediction. Each\n",
       "        reference should be a string with tokens separated by spaces.\n",
       "    rouge_types: A list of rouge types to calculate.\n",
       "        Valid names:\n",
       "        `\"rouge{n}\"` (e.g. `\"rouge1\"`, `\"rouge2\"`) where: {n} is the n-gram based scoring,\n",
       "        `\"rougeL\"`: Longest common subsequence based scoring.\n",
       "        `\"rougeLsum\"`: rougeLsum splits text using `\"\n",
       "\"`.\n",
       "        See details in https://github.com/huggingface/datasets/issues/617\n",
       "    use_stemmer: Bool indicating whether Porter stemmer should be used to strip word suffixes.\n",
       "    use_aggregator: Return aggregates if this is set to True\n",
       "Returns:\n",
       "    rouge1: rouge_1 (f1),\n",
       "    rouge2: rouge_2 (f1),\n",
       "    rougeL: rouge_l (f1),\n",
       "    rougeLsum: rouge_lsum (f1)\n",
       "Examples:\n",
       "\n",
       "    >>> rouge = evaluate.load('rouge')\n",
       "    >>> predictions = [\"hello there\", \"general kenobi\"]\n",
       "    >>> references = [\"hello there\", \"general kenobi\"]\n",
       "    >>> results = rouge.compute(predictions=predictions, references=references)\n",
       "    >>> print(results)\n",
       "    {'rouge1': 1.0, 'rouge2': 1.0, 'rougeL': 1.0, 'rougeLsum': 1.0}\n",
       "\"\"\", stored examples: 0)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rouge_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d09709cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import torch\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "def chunks(list_of_elements, batch_size):\n",
    "    \"\"\"Yield successive batch-sized chunks from list_of_elements.\"\"\"\n",
    "    for i in range(0, len(list_of_elements), batch_size):\n",
    "        yield list_of_elements[i : i + batch_size]\n",
    "\n",
    "def evaluate_summaries_pegasus(dataset, metric, model, tokenizer, \n",
    "                               batch_size=16, device=device, \n",
    "                               column_text=\"article\", \n",
    "                               column_summary=\"highlights\"):\n",
    "    article_batches = list(chunks(dataset[column_text], batch_size))\n",
    "    target_batches = list(chunks(dataset[column_summary], batch_size))\n",
    "\n",
    "    for article_batch, target_batch in tqdm(\n",
    "        zip(article_batches, target_batches), total=len(article_batches)):\n",
    "        \n",
    "        inputs = tokenizer(article_batch, max_length=1024,  truncation=True, \n",
    "                        padding=\"max_length\", return_tensors=\"pt\")\n",
    "        \n",
    "        summaries = model.generate(input_ids=inputs[\"input_ids\"].to(device),\n",
    "                         attention_mask=inputs[\"attention_mask\"].to(device), \n",
    "                         length_penalty=0.8, num_beams=8, max_length=128)\n",
    "        \n",
    "        decoded_summaries = [tokenizer.decode(s, skip_special_tokens=True, \n",
    "                                clean_up_tokenization_spaces=True) \n",
    "               for s in summaries]\n",
    "        decoded_summaries = [d.replace(\"\", \" \") for d in decoded_summaries]\n",
    "        metric.add_batch(predictions=decoded_summaries, references=target_batch)\n",
    "        \n",
    "    score = metric.compute()\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8b8fa337",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11d969ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of PegasusForConditionalGeneration were not initialized from the model checkpoint at google/pegasus-cnn_dailymail and are newly initialized: ['model.decoder.embed_positions.weight', 'model.encoder.embed_positions.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "  1%|          | 1/125 [05:20<11:03:12, 320.91s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[35]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      4\u001b[39m tokenizer = AutoTokenizer.from_pretrained(model_ckpt)\n\u001b[32m      5\u001b[39m model = AutoModelForSeq2SeqLM.from_pretrained(model_ckpt).to(device)\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m score = \u001b[43mevaluate_summaries_pegasus\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_sampled\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrouge_metric\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m                                   \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m8\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      8\u001b[39m rouge_dict = \u001b[38;5;28mdict\u001b[39m((rn, score[rn].mid.fmeasure) \u001b[38;5;28;01mfor\u001b[39;00m rn \u001b[38;5;129;01min\u001b[39;00m rouge_names)\n\u001b[32m      9\u001b[39m pd.DataFrame(rouge_dict, index=[\u001b[33m\"\u001b[39m\u001b[33mpegasus\u001b[39m\u001b[33m\"\u001b[39m])\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[33]\u001b[39m\u001b[32m, line 24\u001b[39m, in \u001b[36mevaluate_summaries_pegasus\u001b[39m\u001b[34m(dataset, metric, model, tokenizer, batch_size, device, column_text, column_summary)\u001b[39m\n\u001b[32m     18\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m article_batch, target_batch \u001b[38;5;129;01min\u001b[39;00m tqdm(\n\u001b[32m     19\u001b[39m     \u001b[38;5;28mzip\u001b[39m(article_batches, target_batches), total=\u001b[38;5;28mlen\u001b[39m(article_batches)):\n\u001b[32m     21\u001b[39m     inputs = tokenizer(article_batch, max_length=\u001b[32m1024\u001b[39m,  truncation=\u001b[38;5;28;01mTrue\u001b[39;00m, \n\u001b[32m     22\u001b[39m                     padding=\u001b[33m\"\u001b[39m\u001b[33mmax_length\u001b[39m\u001b[33m\"\u001b[39m, return_tensors=\u001b[33m\"\u001b[39m\u001b[33mpt\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m24\u001b[39m     summaries = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43minput_ids\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     25\u001b[39m \u001b[43m                     \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mattention_mask\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m     26\u001b[39m \u001b[43m                     \u001b[49m\u001b[43mlength_penalty\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.8\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_beams\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m8\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m128\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     28\u001b[39m     decoded_summaries = [tokenizer.decode(s, skip_special_tokens=\u001b[38;5;28;01mTrue\u001b[39;00m, \n\u001b[32m     29\u001b[39m                             clean_up_tokenization_spaces=\u001b[38;5;28;01mTrue\u001b[39;00m) \n\u001b[32m     30\u001b[39m            \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m summaries]\n\u001b[32m     31\u001b[39m     decoded_summaries = [d.replace(\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m \u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m decoded_summaries]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\sshuser\\NLP_for_transformers\\.venv\\Lib\\site-packages\\torch\\utils\\_contextlib.py:120\u001b[39m, in \u001b[36mcontext_decorator.<locals>.decorate_context\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    117\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecorate_context\u001b[39m(*args, **kwargs):\n\u001b[32m    119\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[32m--> \u001b[39m\u001b[32m120\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\sshuser\\NLP_for_transformers\\.venv\\Lib\\site-packages\\transformers\\generation\\utils.py:2564\u001b[39m, in \u001b[36mGenerationMixin.generate\u001b[39m\u001b[34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, use_model_defaults, custom_generate, **kwargs)\u001b[39m\n\u001b[32m   2561\u001b[39m model_kwargs[\u001b[33m\"\u001b[39m\u001b[33muse_cache\u001b[39m\u001b[33m\"\u001b[39m] = generation_config.use_cache\n\u001b[32m   2563\u001b[39m \u001b[38;5;66;03m# 9. Call generation mode\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2564\u001b[39m result = \u001b[43mdecoding_method\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2565\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   2566\u001b[39m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2567\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlogits_processor\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprepared_logits_processor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2568\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprepared_stopping_criteria\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2569\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2570\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mgeneration_mode_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2571\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2572\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2574\u001b[39m \u001b[38;5;66;03m# Convert to legacy cache format if requested\u001b[39;00m\n\u001b[32m   2575\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m   2576\u001b[39m     generation_config.return_legacy_cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m   2577\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(result, \u001b[33m\"\u001b[39m\u001b[33mpast_key_values\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   2578\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(result.past_key_values, \u001b[33m\"\u001b[39m\u001b[33mto_legacy_cache\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   2579\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\sshuser\\NLP_for_transformers\\.venv\\Lib\\site-packages\\transformers\\generation\\utils.py:3260\u001b[39m, in \u001b[36mGenerationMixin._beam_search\u001b[39m\u001b[34m(self, input_ids, logits_processor, stopping_criteria, generation_config, synced_gpus, **model_kwargs)\u001b[39m\n\u001b[32m   3257\u001b[39m beam_indices = running_beam_indices.detach().clone()\n\u001b[32m   3259\u001b[39m \u001b[38;5;66;03m# 4. run the generation loop\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m3260\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_has_unfinished_sequences\u001b[49m\u001b[43m(\u001b[49m\u001b[43mthis_peer_finished\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msynced_gpus\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[32m   3261\u001b[39m     \u001b[38;5;66;03m# a. Forward current tokens, obtain the logits\u001b[39;00m\n\u001b[32m   3262\u001b[39m     flat_running_sequences = \u001b[38;5;28mself\u001b[39m._flatten_beam_dim(running_sequences[:, :, :cur_len])\n\u001b[32m   3263\u001b[39m     model_inputs = \u001b[38;5;28mself\u001b[39m.prepare_inputs_for_generation(flat_running_sequences, **model_kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\sshuser\\NLP_for_transformers\\.venv\\Lib\\site-packages\\transformers\\generation\\utils.py:2583\u001b[39m, in \u001b[36mGenerationMixin._has_unfinished_sequences\u001b[39m\u001b[34m(self, this_peer_finished, synced_gpus, device)\u001b[39m\n\u001b[32m   2580\u001b[39m         result.past_key_values = result.past_key_values.to_legacy_cache()\n\u001b[32m   2581\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[32m-> \u001b[39m\u001b[32m2583\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_has_unfinished_sequences\u001b[39m(\u001b[38;5;28mself\u001b[39m, this_peer_finished: \u001b[38;5;28mbool\u001b[39m, synced_gpus: \u001b[38;5;28mbool\u001b[39m, device: torch.device) -> \u001b[38;5;28mbool\u001b[39m:\n\u001b[32m   2584\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   2585\u001b[39m \u001b[33;03m    Returns whether there are still unfinished sequences in the device. The existence of unfinished sequences is\u001b[39;00m\n\u001b[32m   2586\u001b[39m \u001b[33;03m    fed through `this_peer_finished`. ZeRO stage 3-friendly.\u001b[39;00m\n\u001b[32m   2587\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m   2588\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m synced_gpus:\n\u001b[32m   2589\u001b[39m         \u001b[38;5;66;03m# Under synced_gpus the `forward` call must continue until all gpus complete their sequence.\u001b[39;00m\n\u001b[32m   2590\u001b[39m         \u001b[38;5;66;03m# The following logic allows an early break if all peers finished generating their sequence\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "\n",
    "model_ckpt = \"google/pegasus-cnn_dailymail\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_ckpt)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_ckpt).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1c40a0d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/125 [00:14<?, ?it/s]\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 12.00 GiB of which 0 bytes is free. Of the allocated memory 15.46 GiB is allocated by PyTorch, and 246.32 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mOutOfMemoryError\u001b[39m                          Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[36]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m score = \u001b[43mevaluate_summaries_pegasus\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_sampled\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrouge_metric\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m      2\u001b[39m \u001b[43m                                   \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m8\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      3\u001b[39m rouge_dict = \u001b[38;5;28mdict\u001b[39m((rn, score[rn].mid.fmeasure) \u001b[38;5;28;01mfor\u001b[39;00m rn \u001b[38;5;129;01min\u001b[39;00m rouge_names)\n\u001b[32m      4\u001b[39m pd.DataFrame(rouge_dict, index=[\u001b[33m\"\u001b[39m\u001b[33mpegasus\u001b[39m\u001b[33m\"\u001b[39m])\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[33]\u001b[39m\u001b[32m, line 24\u001b[39m, in \u001b[36mevaluate_summaries_pegasus\u001b[39m\u001b[34m(dataset, metric, model, tokenizer, batch_size, device, column_text, column_summary)\u001b[39m\n\u001b[32m     18\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m article_batch, target_batch \u001b[38;5;129;01min\u001b[39;00m tqdm(\n\u001b[32m     19\u001b[39m     \u001b[38;5;28mzip\u001b[39m(article_batches, target_batches), total=\u001b[38;5;28mlen\u001b[39m(article_batches)):\n\u001b[32m     21\u001b[39m     inputs = tokenizer(article_batch, max_length=\u001b[32m1024\u001b[39m,  truncation=\u001b[38;5;28;01mTrue\u001b[39;00m, \n\u001b[32m     22\u001b[39m                     padding=\u001b[33m\"\u001b[39m\u001b[33mmax_length\u001b[39m\u001b[33m\"\u001b[39m, return_tensors=\u001b[33m\"\u001b[39m\u001b[33mpt\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m24\u001b[39m     summaries = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43minput_ids\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     25\u001b[39m \u001b[43m                     \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mattention_mask\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m     26\u001b[39m \u001b[43m                     \u001b[49m\u001b[43mlength_penalty\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.8\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_beams\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m8\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m128\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     28\u001b[39m     decoded_summaries = [tokenizer.decode(s, skip_special_tokens=\u001b[38;5;28;01mTrue\u001b[39;00m, \n\u001b[32m     29\u001b[39m                             clean_up_tokenization_spaces=\u001b[38;5;28;01mTrue\u001b[39;00m) \n\u001b[32m     30\u001b[39m            \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m summaries]\n\u001b[32m     31\u001b[39m     decoded_summaries = [d.replace(\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m \u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m decoded_summaries]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\sshuser\\NLP_for_transformers\\.venv\\Lib\\site-packages\\torch\\utils\\_contextlib.py:120\u001b[39m, in \u001b[36mcontext_decorator.<locals>.decorate_context\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    117\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecorate_context\u001b[39m(*args, **kwargs):\n\u001b[32m    119\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[32m--> \u001b[39m\u001b[32m120\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\sshuser\\NLP_for_transformers\\.venv\\Lib\\site-packages\\transformers\\generation\\utils.py:2564\u001b[39m, in \u001b[36mGenerationMixin.generate\u001b[39m\u001b[34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, use_model_defaults, custom_generate, **kwargs)\u001b[39m\n\u001b[32m   2561\u001b[39m model_kwargs[\u001b[33m\"\u001b[39m\u001b[33muse_cache\u001b[39m\u001b[33m\"\u001b[39m] = generation_config.use_cache\n\u001b[32m   2563\u001b[39m \u001b[38;5;66;03m# 9. Call generation mode\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2564\u001b[39m result = \u001b[43mdecoding_method\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2565\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   2566\u001b[39m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2567\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlogits_processor\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprepared_logits_processor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2568\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprepared_stopping_criteria\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2569\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2570\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mgeneration_mode_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2571\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2572\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2574\u001b[39m \u001b[38;5;66;03m# Convert to legacy cache format if requested\u001b[39;00m\n\u001b[32m   2575\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m   2576\u001b[39m     generation_config.return_legacy_cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m   2577\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(result, \u001b[33m\"\u001b[39m\u001b[33mpast_key_values\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   2578\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(result.past_key_values, \u001b[33m\"\u001b[39m\u001b[33mto_legacy_cache\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   2579\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\sshuser\\NLP_for_transformers\\.venv\\Lib\\site-packages\\transformers\\generation\\utils.py:3265\u001b[39m, in \u001b[36mGenerationMixin._beam_search\u001b[39m\u001b[34m(self, input_ids, logits_processor, stopping_criteria, generation_config, synced_gpus, **model_kwargs)\u001b[39m\n\u001b[32m   3262\u001b[39m flat_running_sequences = \u001b[38;5;28mself\u001b[39m._flatten_beam_dim(running_sequences[:, :, :cur_len])\n\u001b[32m   3263\u001b[39m model_inputs = \u001b[38;5;28mself\u001b[39m.prepare_inputs_for_generation(flat_running_sequences, **model_kwargs)\n\u001b[32m-> \u001b[39m\u001b[32m3265\u001b[39m model_outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m   3267\u001b[39m \u001b[38;5;66;03m# synced_gpus: don't waste resources running the code we don't need; kwargs must be updated before skipping\u001b[39;00m\n\u001b[32m   3268\u001b[39m model_kwargs = \u001b[38;5;28mself\u001b[39m._update_model_kwargs_for_generation(\n\u001b[32m   3269\u001b[39m     model_outputs,\n\u001b[32m   3270\u001b[39m     model_kwargs,\n\u001b[32m   3271\u001b[39m     is_encoder_decoder=\u001b[38;5;28mself\u001b[39m.config.is_encoder_decoder,\n\u001b[32m   3272\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\sshuser\\NLP_for_transformers\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\sshuser\\NLP_for_transformers\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\sshuser\\NLP_for_transformers\\.venv\\Lib\\site-packages\\transformers\\models\\pegasus\\modeling_pegasus.py:1470\u001b[39m, in \u001b[36mPegasusForConditionalGeneration.forward\u001b[39m\u001b[34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, past_key_values, inputs_embeds, decoder_inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001b[39m\n\u001b[32m   1465\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m decoder_input_ids \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m decoder_inputs_embeds \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1466\u001b[39m         decoder_input_ids = shift_tokens_right(\n\u001b[32m   1467\u001b[39m             labels, \u001b[38;5;28mself\u001b[39m.config.pad_token_id, \u001b[38;5;28mself\u001b[39m.config.decoder_start_token_id\n\u001b[32m   1468\u001b[39m         )\n\u001b[32m-> \u001b[39m\u001b[32m1470\u001b[39m outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1471\u001b[39m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1472\u001b[39m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1473\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdecoder_input_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecoder_input_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1474\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoder_outputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoder_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1475\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdecoder_attention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1476\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1477\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdecoder_head_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecoder_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1478\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcross_attn_head_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcross_attn_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1479\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1480\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1481\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdecoder_inputs_embeds\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecoder_inputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1482\u001b[39m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1483\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1484\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1485\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1486\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1487\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1488\u001b[39m lm_logits = \u001b[38;5;28mself\u001b[39m.lm_head(outputs[\u001b[32m0\u001b[39m]) + \u001b[38;5;28mself\u001b[39m.final_logits_bias\n\u001b[32m   1490\u001b[39m masked_lm_loss = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\sshuser\\NLP_for_transformers\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\sshuser\\NLP_for_transformers\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\sshuser\\NLP_for_transformers\\.venv\\Lib\\site-packages\\transformers\\models\\pegasus\\modeling_pegasus.py:1296\u001b[39m, in \u001b[36mPegasusModel.forward\u001b[39m\u001b[34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, past_key_values, inputs_embeds, decoder_inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001b[39m\n\u001b[32m   1289\u001b[39m     encoder_outputs = BaseModelOutput(\n\u001b[32m   1290\u001b[39m         last_hidden_state=encoder_outputs[\u001b[32m0\u001b[39m],\n\u001b[32m   1291\u001b[39m         hidden_states=encoder_outputs[\u001b[32m1\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(encoder_outputs) > \u001b[32m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1292\u001b[39m         attentions=encoder_outputs[\u001b[32m2\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(encoder_outputs) > \u001b[32m2\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1293\u001b[39m     )\n\u001b[32m   1295\u001b[39m \u001b[38;5;66;03m# decoder outputs consists of (dec_features, past_key_values, dec_hidden, dec_attn)\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1296\u001b[39m decoder_outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdecoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1297\u001b[39m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecoder_input_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1298\u001b[39m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1299\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoder_outputs\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1300\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1301\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecoder_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1302\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcross_attn_head_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcross_attn_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1303\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1304\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecoder_inputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1305\u001b[39m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1306\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1307\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1308\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1309\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1310\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1312\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m return_dict:\n\u001b[32m   1313\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m decoder_outputs + encoder_outputs\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\sshuser\\NLP_for_transformers\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\sshuser\\NLP_for_transformers\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\sshuser\\NLP_for_transformers\\.venv\\Lib\\site-packages\\transformers\\models\\pegasus\\modeling_pegasus.py:1120\u001b[39m, in \u001b[36mPegasusDecoder.forward\u001b[39m\u001b[34m(self, input_ids, attention_mask, encoder_hidden_states, encoder_attention_mask, head_mask, cross_attn_head_mask, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001b[39m\n\u001b[32m   1117\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m dropout_probability < \u001b[38;5;28mself\u001b[39m.layerdrop:\n\u001b[32m   1118\u001b[39m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1120\u001b[39m layer_outputs = \u001b[43mdecoder_layer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1121\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1122\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcausal_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1123\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# as a positional argument for gradient checkpointing\u001b[39;49;00m\n\u001b[32m   1124\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1125\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1126\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcross_attn_layer_head_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcross_attn_head_mask\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcross_attn_head_mask\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1127\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1128\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1129\u001b[39m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1130\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1131\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1132\u001b[39m hidden_states = layer_outputs[\u001b[32m0\u001b[39m]\n\u001b[32m   1134\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m output_attentions:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\sshuser\\NLP_for_transformers\\.venv\\Lib\\site-packages\\transformers\\modeling_layers.py:94\u001b[39m, in \u001b[36mGradientCheckpointingLayer.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     91\u001b[39m         logger.warning_once(message)\n\u001b[32m     93\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._gradient_checkpointing_func(partial(\u001b[38;5;28msuper\u001b[39m().\u001b[34m__call__\u001b[39m, **kwargs), *args)\n\u001b[32m---> \u001b[39m\u001b[32m94\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\sshuser\\NLP_for_transformers\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\sshuser\\NLP_for_transformers\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\sshuser\\NLP_for_transformers\\.venv\\Lib\\site-packages\\transformers\\utils\\deprecation.py:172\u001b[39m, in \u001b[36mdeprecate_kwarg.<locals>.wrapper.<locals>.wrapped_func\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    168\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m minimum_action \u001b[38;5;129;01min\u001b[39;00m (Action.NOTIFY, Action.NOTIFY_ALWAYS) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torchdynamo_compiling():\n\u001b[32m    169\u001b[39m     \u001b[38;5;66;03m# DeprecationWarning is ignored by default, so we use FutureWarning instead\u001b[39;00m\n\u001b[32m    170\u001b[39m     warnings.warn(message, \u001b[38;5;167;01mFutureWarning\u001b[39;00m, stacklevel=\u001b[32m2\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m172\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\sshuser\\NLP_for_transformers\\.venv\\Lib\\site-packages\\transformers\\models\\pegasus\\modeling_pegasus.py:427\u001b[39m, in \u001b[36mPegasusDecoderLayer.forward\u001b[39m\u001b[34m(self, hidden_states, attention_mask, encoder_hidden_states, encoder_attention_mask, layer_head_mask, cross_attn_layer_head_mask, past_key_values, output_attentions, use_cache, cache_position)\u001b[39m\n\u001b[32m    424\u001b[39m residual = hidden_states\n\u001b[32m    425\u001b[39m hidden_states = \u001b[38;5;28mself\u001b[39m.encoder_attn_layer_norm(hidden_states)\n\u001b[32m--> \u001b[39m\u001b[32m427\u001b[39m hidden_states, cross_attn_weights = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mencoder_attn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    428\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    429\u001b[39m \u001b[43m    \u001b[49m\u001b[43mkey_value_states\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    430\u001b[39m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    431\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcross_attn_layer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    432\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    433\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    434\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    435\u001b[39m hidden_states = nn.functional.dropout(hidden_states, p=\u001b[38;5;28mself\u001b[39m.dropout, training=\u001b[38;5;28mself\u001b[39m.training)\n\u001b[32m    436\u001b[39m hidden_states = residual + hidden_states\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\sshuser\\NLP_for_transformers\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\sshuser\\NLP_for_transformers\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\sshuser\\NLP_for_transformers\\.venv\\Lib\\site-packages\\transformers\\utils\\deprecation.py:172\u001b[39m, in \u001b[36mdeprecate_kwarg.<locals>.wrapper.<locals>.wrapped_func\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    168\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m minimum_action \u001b[38;5;129;01min\u001b[39;00m (Action.NOTIFY, Action.NOTIFY_ALWAYS) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torchdynamo_compiling():\n\u001b[32m    169\u001b[39m     \u001b[38;5;66;03m# DeprecationWarning is ignored by default, so we use FutureWarning instead\u001b[39;00m\n\u001b[32m    170\u001b[39m     warnings.warn(message, \u001b[38;5;167;01mFutureWarning\u001b[39;00m, stacklevel=\u001b[32m2\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m172\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\sshuser\\NLP_for_transformers\\.venv\\Lib\\site-packages\\transformers\\models\\pegasus\\modeling_pegasus.py:244\u001b[39m, in \u001b[36mPegasusAttention.forward\u001b[39m\u001b[34m(self, hidden_states, key_value_states, past_key_values, attention_mask, layer_head_mask, output_attentions, cache_position, **kwargs)\u001b[39m\n\u001b[32m    241\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m past_key_values \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    242\u001b[39m     \u001b[38;5;66;03m# save all key/value_states to cache to be re-used for fast auto-regressive generation\u001b[39;00m\n\u001b[32m    243\u001b[39m     cache_position = cache_position \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_cross_attention \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m244\u001b[39m     key_states, value_states = \u001b[43mcurr_past_key_value\u001b[49m\u001b[43m.\u001b[49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    245\u001b[39m \u001b[43m        \u001b[49m\u001b[43mkey_states\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue_states\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlayer_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcache_position\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m}\u001b[49m\n\u001b[32m    246\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    247\u001b[39m     \u001b[38;5;66;03m# set flag that curr layer for cross-attn is already updated so we can re-use in subsequent calls\u001b[39;00m\n\u001b[32m    248\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m is_cross_attention \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(past_key_values, EncoderDecoderCache):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\sshuser\\NLP_for_transformers\\.venv\\Lib\\site-packages\\transformers\\cache_utils.py:776\u001b[39m, in \u001b[36mCache.update\u001b[39m\u001b[34m(self, key_states, value_states, layer_idx, cache_kwargs)\u001b[39m\n\u001b[32m    773\u001b[39m     torch.cuda.default_stream(key_states.device).wait_stream(\u001b[38;5;28mself\u001b[39m.prefetch_stream)\n\u001b[32m    774\u001b[39m     \u001b[38;5;28mself\u001b[39m.prefetch(layer_idx + \u001b[32m1\u001b[39m, \u001b[38;5;28mself\u001b[39m.only_non_sliding)\n\u001b[32m--> \u001b[39m\u001b[32m776\u001b[39m keys, values = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlayers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlayer_idx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey_states\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue_states\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    778\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.offloading:\n\u001b[32m    779\u001b[39m     \u001b[38;5;28mself\u001b[39m.offload(layer_idx, \u001b[38;5;28mself\u001b[39m.only_non_sliding)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\sshuser\\NLP_for_transformers\\.venv\\Lib\\site-packages\\transformers\\cache_utils.py:119\u001b[39m, in \u001b[36mDynamicLayer.update\u001b[39m\u001b[34m(self, key_states, value_states, cache_kwargs)\u001b[39m\n\u001b[32m    116\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.is_initialized:\n\u001b[32m    117\u001b[39m     \u001b[38;5;28mself\u001b[39m.lazy_initialization(key_states)\n\u001b[32m--> \u001b[39m\u001b[32m119\u001b[39m \u001b[38;5;28mself\u001b[39m.keys = \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey_states\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[43m=\u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    120\u001b[39m \u001b[38;5;28mself\u001b[39m.values = torch.cat([\u001b[38;5;28mself\u001b[39m.values, value_states], dim=-\u001b[32m2\u001b[39m)\n\u001b[32m    121\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.keys, \u001b[38;5;28mself\u001b[39m.values\n",
      "\u001b[31mOutOfMemoryError\u001b[39m: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 12.00 GiB of which 0 bytes is free. Of the allocated memory 15.46 GiB is allocated by PyTorch, and 246.32 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "score = evaluate_summaries_pegasus(test_sampled, rouge_metric, \n",
    "                                   model, tokenizer, batch_size=8)\n",
    "rouge_dict = dict((rn, score[rn].mid.fmeasure) for rn in rouge_names)\n",
    "pd.DataFrame(rouge_dict, index=[\"pegasus\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46426c43",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NLP_for_transformers (3.13.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

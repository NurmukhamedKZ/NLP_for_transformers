{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "87660dbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nurma/vscode_projects/NLP/.venv/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# hide_output\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model_name = \"gpt2-xl\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ee94dcaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [2782, 346, 47083, 22523, 379, 220], 'attention_mask': [1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"Adilbek sucks at \"\n",
    "text_tokenized = tokenizer(text)\n",
    "text_tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7460ed6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Ad', 'il', 'bek', 'Ġsucks', 'Ġat', 'Ġ']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.convert_ids_to_tokens(text_tokenized[\"input_ids\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "392ef96a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Adilbek sucks at '"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(text_tokenized[\"input_ids\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "655649be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "input_txt = \"Adilbek sucks at\"\n",
    "input_ids = tokenizer(input_txt, return_tensors=\"pt\")[\"input_ids\"].to(device)\n",
    "iterations = []\n",
    "n_steps = 3\n",
    "choices_per_step = 3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7b85677e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(input_ids[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c18d2e66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f619cd47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output.logits.shape=torch.Size([1, 5, 50257])\n",
      "next_token_logits.shape=torch.Size([50257])\n",
      "next_token_probs.shape=torch.Size([50257])\n",
      "sorted_ids.shape=torch.Size([50257])\n",
      "----------------------------------------\n",
      "token_id=tensor(10688)\n",
      "token_id=tensor(465)\n",
      "token_id=tensor(262)\n",
      "output.logits.shape=torch.Size([1, 6, 50257])\n",
      "next_token_logits.shape=torch.Size([50257])\n",
      "next_token_probs.shape=torch.Size([50257])\n",
      "sorted_ids.shape=torch.Size([50257])\n",
      "----------------------------------------\n",
      "token_id=tensor(13)\n",
      "token_id=tensor(11)\n",
      "token_id=tensor(290)\n",
      "output.logits.shape=torch.Size([1, 7, 50257])\n",
      "next_token_logits.shape=torch.Size([50257])\n",
      "next_token_probs.shape=torch.Size([50257])\n",
      "sorted_ids.shape=torch.Size([50257])\n",
      "----------------------------------------\n",
      "token_id=tensor(198)\n",
      "token_id=tensor(679)\n",
      "token_id=tensor(314)\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    for _ in range(n_steps):\n",
    "        iteration = dict()\n",
    "        iteration[\"Input\"] = tokenizer.decode(input_ids[0])\n",
    "        output = model(input_ids=input_ids) # (1, 5, 50257)\n",
    "        print(f\"{output.logits.shape=}\")\n",
    "        # Select logits of the first batch and the last token and apply softmax\n",
    "        next_token_logits = output.logits[0, -1, :] # (50257)\n",
    "        print(f\"{next_token_logits.shape=}\")\n",
    "        next_token_probs = torch.softmax(next_token_logits, dim=-1) # (50257)\n",
    "        print(f\"{next_token_probs.shape=}\")\n",
    "        sorted_ids = torch.argsort(next_token_probs, dim=-1, descending=True) # (50257)\n",
    "        \n",
    "        print(f\"{sorted_ids.shape=}\")\n",
    "        # Store tokens with highest probabilities\n",
    "        print(\"-\"*40)\n",
    "        for choice_idx in range(choices_per_step):\n",
    "            token_id = sorted_ids[choice_idx]\n",
    "            print(f\"{token_id=}\")\n",
    "            token_prob = next_token_probs[token_id].cpu().numpy()\n",
    "            token_choice = (\n",
    "                f\"{tokenizer.decode(token_id)} ({100 * token_prob:.2f}%)\"\n",
    "            )\n",
    "            iteration[f\"Choice {choice_idx+1}\"] = token_choice\n",
    "        # Append predicted next token to input\n",
    "        input_ids = torch.cat([input_ids, sorted_ids[None, 0, None]], dim=-1)\n",
    "        iterations.append(iteration)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ed6a2aea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.1078,  1.4739, -0.4956,  ..., -6.9666, -6.6467,  6.6501])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_token_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6f1e816a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.1343e-05, 4.4460e-05, 6.2035e-06,  ..., 9.6011e-09, 1.3220e-08,\n",
       "        7.8702e-03])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_token_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "edd659b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  198,   679,   314,  ..., 45544,   216,   182])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d57fcfba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.1821)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_token_probs[198]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5f5f3c81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.6364e-16)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_token_probs[182]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7f9e2dba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Input</th>\n",
       "      <th>Choice 1</th>\n",
       "      <th>Choice 2</th>\n",
       "      <th>Choice 3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Adilbek sucks at</td>\n",
       "      <td>math (3.49%)</td>\n",
       "      <td>his (3.46%)</td>\n",
       "      <td>the (3.36%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Adilbek sucks at math</td>\n",
       "      <td>. (34.40%)</td>\n",
       "      <td>, (23.77%)</td>\n",
       "      <td>and (10.39%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Adilbek sucks at math.</td>\n",
       "      <td>\\n (18.21%)</td>\n",
       "      <td>He (16.77%)</td>\n",
       "      <td>I (3.04%)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Input       Choice 1      Choice 2       Choice 3\n",
       "0        Adilbek sucks at   math (3.49%)   his (3.46%)    the (3.36%)\n",
       "1   Adilbek sucks at math     . (34.40%)    , (23.77%)   and (10.39%)\n",
       "2  Adilbek sucks at math.    \\n (18.21%)   He (16.77%)      I (3.04%)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(iterations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ca054159",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Ad', 'il', 'bek', 'Ġsucks', 'Ġat', 'Ġmath', '.', 'Ċ']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.convert_ids_to_tokens(input_ids[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "49132d34",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adilbek sucks at math.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "input_ids = tokenizer(input_txt, return_tensors=\"pt\")[\"input_ids\"].to(device)\n",
    "output = model.generate(input_ids, max_new_tokens=n_steps, do_sample=False)\n",
    "print(tokenizer.decode(output[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7ca18dc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adilbek sucks at math.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.decode(output[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "d016d76f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adilbek sucks at\n",
      "Adilbek sucks at math\n",
      "Adilbek sucks at math.\n",
      "Adilbek sucks at math.\n",
      "\n",
      "Adilbek sucks at math.\n",
      "\n",
      "\n",
      "Adilbek sucks at math.\n",
      "\n",
      "\"\n",
      "Adilbek sucks at math.\n",
      "\n",
      "\"I\n",
      "Adilbek sucks at math.\n",
      "\n",
      "\"I'm\n",
      "Adilbek sucks at math.\n",
      "\n",
      "\"I'm not\n",
      "Adilbek sucks at math.\n",
      "\n",
      "\"I'm not good\n",
      "Adilbek sucks at math.\n",
      "\n",
      "\"I'm not good at\n"
     ]
    }
   ],
   "source": [
    "\n",
    "input_txt = \"Adilbek sucks at\"\n",
    "input_ids = tokenizer(input_txt, return_tensors=\"pt\")[\"input_ids\"].to(device)\n",
    "iterations = []\n",
    "n_steps = 10\n",
    "choices_per_step = 3\n",
    "\n",
    "print(input_txt)\n",
    "with torch.no_grad():\n",
    "    for _ in range(n_steps):\n",
    "        output = model(input_ids=input_ids) # (1, 5, 50257)\n",
    "        # Select logits of the first batch and the last token and apply softmax\n",
    "        next_token_logits = output.logits[0, -1, :] # (50257)\n",
    "        next_token_probs = torch.softmax(next_token_logits, dim=-1) # (50257)\n",
    "        sorted_id = torch.argmax(next_token_probs, dim=-1).unsqueeze(-1).unsqueeze(-1) # (50257)\n",
    "        \n",
    "        input_ids = torch.cat([input_ids, sorted_id], dim=-1)\n",
    "        print(tokenizer.decode(input_ids[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "9a6f0011",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2.6458e-05, 2.3018e-05, 3.1340e-07,  ..., 4.1718e-07, 3.0811e-08,\n",
       "        1.8454e-05])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_token_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "052ed83d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(10688)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_id = torch.argmax(next_token_probs, dim=-1) # (50257)\n",
    "sorted_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "42181867",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([10688])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_id = sorted_id.unsqueeze(-1)  # Add dimension at the end\n",
    "sorted_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "2c98d6cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[10688]])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_id = sorted_id.unsqueeze(-1)  # Add dimension at the end\n",
    "sorted_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "e33903f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 2782,   346, 47083, 22523,   379]])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "e2f32bbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Adilbek sucks at math math'"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(torch.cat([input_ids, sorted_id], dim=-1)[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "d8734987",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 + 5 = ????\n",
      "\n",
      "The first thing to note is that\n"
     ]
    }
   ],
   "source": [
    "input_txt = \"5 + 5 = \"\n",
    "n_steps = 2\n",
    "input_ids = tokenizer(input_txt, return_tensors=\"pt\")[\"input_ids\"].to(device)\n",
    "output = model.generate(input_ids, max_new_tokens=n_steps, do_sample=False)\n",
    "print(tokenizer.decode(output[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "e6af4497",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "5 + 8 => 13 \n",
      " 7 + 2 => 9 \n",
      " 1 + 0 => 1 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "input_txt = \"5 + 8 => 13 \\n 7 + 2 => 9 \\n 1 + 0 =>\"\n",
    "\n",
    "n_steps = 3\n",
    "\n",
    "input_ids = tokenizer(input_txt, return_tensors=\"pt\")[\"input_ids\"].to(device)\n",
    "output = model.generate(input_ids, max_new_tokens=n_steps, do_sample=False)\n",
    "\n",
    "print('-'*40)\n",
    "print(tokenizer.decode(output[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "ac547290",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "def log_probs_from_logits(logits, labels):\n",
    "    logp = F.log_softmax(logits, dim=-1)\n",
    "    logp_label = torch.gather(logp, 2, labels.unsqueeze(2)).squeeze(-1)\n",
    "    return logp_label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6af50fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sequence_logprob(model, labels, input_len=0):\n",
    "    with torch.no_grad():\n",
    "        output = model(labels)\n",
    "        log_probs = log_probs_from_logits(\n",
    "            output.logits[:, :-1, :], labels[:, 1:]\n",
    "        )\n",
    "        seq_log_prob = torch.sum(log_probs[:, input_len:])\n",
    "    return seq_log_prob.cpu().numpy()\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "b4c501e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  20, 1343,  807, 5218, 1511,  220,  198,  767, 1343,  362, 5218,  860,\n",
       "          220,  198,  352, 1343,  657, 5218,  352,  220,  198]])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "f755e567",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 + 8 => 13 \n",
      " 7 + 2 => 9 \n",
      " 1 + 0 => 1 \n",
      "\n",
      "\n",
      "log-prob: -0.42\n"
     ]
    }
   ],
   "source": [
    "logp = sequence_logprob(model, output, input_len=len(input_ids[0]))\n",
    "print(tokenizer.decode(output[0]))\n",
    "print(f\"\\nlog-prob: {logp:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "1545b18a",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_txt = \"Guide to find a girlfriend\\n\"\n",
    "input_ids = tokenizer(input_txt, return_tensors=\"pt\")[\"input_ids\"].to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "73e5c73d",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_tokens = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "f3d1a3f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Guide to find a girlfriend\n",
      "\n",
      "How to find a girlfriend\n",
      "\n",
      "How to find a girlfriend\n",
      "\n",
      "How to find a girlfriend\n",
      "\n",
      "How to find a girlfriend\n",
      "\n",
      "How to find a girlfriend\n",
      "\n",
      "How to find a girlfriend\n",
      "\n",
      "How\n",
      "\n",
      "log-prob: -12.93\n"
     ]
    }
   ],
   "source": [
    "output_beam = model.generate(input_ids, max_length=max_tokens, num_beams=3, \n",
    "                             do_sample=False)\n",
    "logp = sequence_logprob(model, output_beam, input_len=len(input_ids[0]))\n",
    "print(tokenizer.decode(output_beam[0]))\n",
    "print(f\"\\nlog-prob: {logp:.2f}\")\n",
    "     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "541501c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Guide to find a girlfriend\n",
      "\n",
      "How to get a girl to like you\n",
      " the best way to make a woman fall in love with you<|endoftext|>\n",
      "Guide to find a girlfriend\n",
      "\n",
      "How to get a girl to like you\n",
      " the best way to make a woman fall in love with you<|endoftext|>\n",
      "\n",
      "log-prob: -38.28\n"
     ]
    }
   ],
   "source": [
    "from transformers import TextStreamer\n",
    "\n",
    "streamer = TextStreamer(tokenizer=tokenizer)\n",
    "\n",
    "output_beam = model.generate(input_ids, max_length=max_tokens, num_beams=1, \n",
    "                             do_sample=False, no_repeat_ngram_size=2, streamer=streamer)\n",
    "logp = sequence_logprob(model, output_beam, input_len=len(input_ids[0]))\n",
    "print(tokenizer.decode(output_beam[0]))\n",
    "print(f\"\\nlog-prob: {logp:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "c7c0941d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[47889,   284,  1064,   257, 11077,   198,   198,  2437,   284,  1064,\n",
       "           257, 11077,   198,   198,  2437,   284,  1064,   257, 11077,   198,\n",
       "           198,  2437,   284,  1064,   257, 11077,   198,   198,  2437,   284,\n",
       "          1064,   257, 11077,   198,   198,  2437,   284,  1064,   257, 11077,\n",
       "           198,   198,  2437,   284,  1064,   257, 11077,   198,   198,  2437]])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_beam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34e11b17",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp (3.13.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

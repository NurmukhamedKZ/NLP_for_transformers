{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "30fe2f02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(183,\n",
       " ['MLQA.ar.ar',\n",
       "  'MLQA.ar.de',\n",
       "  'MLQA.ar.en',\n",
       "  'MLQA.ar.es',\n",
       "  'MLQA.ar.hi',\n",
       "  'MLQA.ar.vi',\n",
       "  'MLQA.ar.zh',\n",
       "  'MLQA.de.ar',\n",
       "  'MLQA.de.de',\n",
       "  'MLQA.de.en',\n",
       "  'MLQA.de.es',\n",
       "  'MLQA.de.hi',\n",
       "  'MLQA.de.vi',\n",
       "  'MLQA.de.zh',\n",
       "  'MLQA.en.ar',\n",
       "  'MLQA.en.de',\n",
       "  'MLQA.en.en',\n",
       "  'MLQA.en.es',\n",
       "  'MLQA.en.hi',\n",
       "  'MLQA.en.vi',\n",
       "  'MLQA.en.zh',\n",
       "  'MLQA.es.ar',\n",
       "  'MLQA.es.de',\n",
       "  'MLQA.es.en',\n",
       "  'MLQA.es.es',\n",
       "  'MLQA.es.hi',\n",
       "  'MLQA.es.vi',\n",
       "  'MLQA.es.zh',\n",
       "  'MLQA.hi.ar',\n",
       "  'MLQA.hi.de',\n",
       "  'MLQA.hi.en',\n",
       "  'MLQA.hi.es',\n",
       "  'MLQA.hi.hi',\n",
       "  'MLQA.hi.vi',\n",
       "  'MLQA.hi.zh',\n",
       "  'MLQA.vi.ar',\n",
       "  'MLQA.vi.de',\n",
       "  'MLQA.vi.en',\n",
       "  'MLQA.vi.es',\n",
       "  'MLQA.vi.hi',\n",
       "  'MLQA.vi.vi',\n",
       "  'MLQA.vi.zh',\n",
       "  'MLQA.zh.ar',\n",
       "  'MLQA.zh.de',\n",
       "  'MLQA.zh.en',\n",
       "  'MLQA.zh.es',\n",
       "  'MLQA.zh.hi',\n",
       "  'MLQA.zh.vi',\n",
       "  'MLQA.zh.zh',\n",
       "  'PAN-X.af',\n",
       "  'PAN-X.ar',\n",
       "  'PAN-X.bg',\n",
       "  'PAN-X.bn',\n",
       "  'PAN-X.de',\n",
       "  'PAN-X.el',\n",
       "  'PAN-X.en',\n",
       "  'PAN-X.es',\n",
       "  'PAN-X.et',\n",
       "  'PAN-X.eu',\n",
       "  'PAN-X.fa',\n",
       "  'PAN-X.fi',\n",
       "  'PAN-X.fr',\n",
       "  'PAN-X.he',\n",
       "  'PAN-X.hi',\n",
       "  'PAN-X.hu',\n",
       "  'PAN-X.id',\n",
       "  'PAN-X.it',\n",
       "  'PAN-X.ja',\n",
       "  'PAN-X.jv',\n",
       "  'PAN-X.ka',\n",
       "  'PAN-X.kk',\n",
       "  'PAN-X.ko',\n",
       "  'PAN-X.ml',\n",
       "  'PAN-X.mr',\n",
       "  'PAN-X.ms',\n",
       "  'PAN-X.my',\n",
       "  'PAN-X.nl',\n",
       "  'PAN-X.pt',\n",
       "  'PAN-X.ru',\n",
       "  'PAN-X.sw',\n",
       "  'PAN-X.ta',\n",
       "  'PAN-X.te',\n",
       "  'PAN-X.th',\n",
       "  'PAN-X.tl',\n",
       "  'PAN-X.tr',\n",
       "  'PAN-X.ur',\n",
       "  'PAN-X.vi',\n",
       "  'PAN-X.yo',\n",
       "  'PAN-X.zh',\n",
       "  'PAWS-X.de',\n",
       "  'PAWS-X.en',\n",
       "  'PAWS-X.es',\n",
       "  'PAWS-X.fr',\n",
       "  'PAWS-X.ja',\n",
       "  'PAWS-X.ko',\n",
       "  'PAWS-X.zh',\n",
       "  'SQuAD',\n",
       "  'XNLI',\n",
       "  'XQuAD.ar',\n",
       "  'XQuAD.de',\n",
       "  'XQuAD.el',\n",
       "  'XQuAD.en',\n",
       "  'XQuAD.es',\n",
       "  'XQuAD.hi',\n",
       "  'XQuAD.ru',\n",
       "  'XQuAD.th',\n",
       "  'XQuAD.tr',\n",
       "  'XQuAD.vi',\n",
       "  'XQuAD.zh',\n",
       "  'bucc18.de',\n",
       "  'bucc18.fr',\n",
       "  'bucc18.ru',\n",
       "  'bucc18.zh',\n",
       "  'tatoeba.afr',\n",
       "  'tatoeba.ara',\n",
       "  'tatoeba.ben',\n",
       "  'tatoeba.bul',\n",
       "  'tatoeba.cmn',\n",
       "  'tatoeba.deu',\n",
       "  'tatoeba.ell',\n",
       "  'tatoeba.est',\n",
       "  'tatoeba.eus',\n",
       "  'tatoeba.fin',\n",
       "  'tatoeba.fra',\n",
       "  'tatoeba.heb',\n",
       "  'tatoeba.hin',\n",
       "  'tatoeba.hun',\n",
       "  'tatoeba.ind',\n",
       "  'tatoeba.ita',\n",
       "  'tatoeba.jav',\n",
       "  'tatoeba.jpn',\n",
       "  'tatoeba.kat',\n",
       "  'tatoeba.kaz',\n",
       "  'tatoeba.kor',\n",
       "  'tatoeba.mal',\n",
       "  'tatoeba.mar',\n",
       "  'tatoeba.nld',\n",
       "  'tatoeba.pes',\n",
       "  'tatoeba.por',\n",
       "  'tatoeba.rus',\n",
       "  'tatoeba.spa',\n",
       "  'tatoeba.swh',\n",
       "  'tatoeba.tam',\n",
       "  'tatoeba.tel',\n",
       "  'tatoeba.tgl',\n",
       "  'tatoeba.tha',\n",
       "  'tatoeba.tur',\n",
       "  'tatoeba.urd',\n",
       "  'tatoeba.vie',\n",
       "  'tydiqa',\n",
       "  'udpos.Afrikaans',\n",
       "  'udpos.Arabic',\n",
       "  'udpos.Basque',\n",
       "  'udpos.Bulgarian',\n",
       "  'udpos.Chinese',\n",
       "  'udpos.Dutch',\n",
       "  'udpos.English',\n",
       "  'udpos.Estonian',\n",
       "  'udpos.Finnish',\n",
       "  'udpos.French',\n",
       "  'udpos.German',\n",
       "  'udpos.Greek',\n",
       "  'udpos.Hebrew',\n",
       "  'udpos.Hindi',\n",
       "  'udpos.Hungarian',\n",
       "  'udpos.Indonesian',\n",
       "  'udpos.Italian',\n",
       "  'udpos.Japanese',\n",
       "  'udpos.Kazakh',\n",
       "  'udpos.Korean',\n",
       "  'udpos.Marathi',\n",
       "  'udpos.Persian',\n",
       "  'udpos.Portuguese',\n",
       "  'udpos.Russian',\n",
       "  'udpos.Spanish',\n",
       "  'udpos.Tagalog',\n",
       "  'udpos.Tamil',\n",
       "  'udpos.Telugu',\n",
       "  'udpos.Thai',\n",
       "  'udpos.Turkish',\n",
       "  'udpos.Urdu',\n",
       "  'udpos.Vietnamese',\n",
       "  'udpos.Yoruba'])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import get_dataset_config_names\n",
    "\n",
    "xtreme_subsets = get_dataset_config_names(\"xtreme\")\n",
    "len(xtreme_subsets), xtreme_subsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "627389d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['PAN-X.af',\n",
       " 'PAN-X.ar',\n",
       " 'PAN-X.bg',\n",
       " 'PAN-X.bn',\n",
       " 'PAN-X.de',\n",
       " 'PAN-X.el',\n",
       " 'PAN-X.en',\n",
       " 'PAN-X.es',\n",
       " 'PAN-X.et',\n",
       " 'PAN-X.eu',\n",
       " 'PAN-X.fa',\n",
       " 'PAN-X.fi',\n",
       " 'PAN-X.fr',\n",
       " 'PAN-X.he',\n",
       " 'PAN-X.hi',\n",
       " 'PAN-X.hu',\n",
       " 'PAN-X.id',\n",
       " 'PAN-X.it',\n",
       " 'PAN-X.ja',\n",
       " 'PAN-X.jv',\n",
       " 'PAN-X.ka',\n",
       " 'PAN-X.kk',\n",
       " 'PAN-X.ko',\n",
       " 'PAN-X.ml',\n",
       " 'PAN-X.mr',\n",
       " 'PAN-X.ms',\n",
       " 'PAN-X.my',\n",
       " 'PAN-X.nl',\n",
       " 'PAN-X.pt',\n",
       " 'PAN-X.ru',\n",
       " 'PAN-X.sw',\n",
       " 'PAN-X.ta',\n",
       " 'PAN-X.te',\n",
       " 'PAN-X.th',\n",
       " 'PAN-X.tl',\n",
       " 'PAN-X.tr',\n",
       " 'PAN-X.ur',\n",
       " 'PAN-X.vi',\n",
       " 'PAN-X.yo',\n",
       " 'PAN-X.zh']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "panx_subsets = [i for i in xtreme_subsets if i.startswith(\"PAN\") ]\n",
    "panx_subsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb80d8a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['PAN-X.kk']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[pan for pan in panx_subsets if pan[-2:] == \"kk\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "94a101e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "Generating train split: 100%|██████████| 1000/1000 [00:00<00:00, 8980.88 examples/s]\n",
      "Generating validation split: 100%|██████████| 1000/1000 [00:00<00:00, 288863.91 examples/s]\n",
      "Generating test split: 100%|██████████| 1000/1000 [00:00<00:00, 313311.72 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['tokens', 'ner_tags', 'langs'],\n",
       "        num_rows: 1000\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['tokens', 'ner_tags', 'langs'],\n",
       "        num_rows: 1000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['tokens', 'ner_tags', 'langs'],\n",
       "        num_rows: 1000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "panx_kk = load_dataset(\"xtreme\", name=\"PAN-X.kk\")\n",
    "panx_kk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "be45ca13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tokens': [['АЙДАУ', 'Ауыр', 'атлетикадан', 'әлем', 'чемпионаты', '2013'],\n",
       "  ['``', 'Қазақфильм', \"''\", 'киностудиясы', 'шығарған', '.'],\n",
       "  ['ҚР', 'Сыртқы', 'істер', 'министрлігі'],\n",
       "  [\"'\", \"''\", 'Ербаш', \"''\", \"'\", '—', 'Ресейдегі', 'өзен', '.'],\n",
       "  ['Даг', 'Хаммаршельд', '(', 'посмертно', ')']],\n",
       " 'ner_tags': [[0, 3, 4, 4, 4, 4],\n",
       "  [0, 3, 0, 0, 0, 0],\n",
       "  [3, 4, 4, 4],\n",
       "  [0, 0, 0, 0, 0, 0, 5, 0, 0],\n",
       "  [1, 2, 0, 0, 0]],\n",
       " 'langs': [['kk', 'kk', 'kk', 'kk', 'kk', 'kk'],\n",
       "  ['kk', 'kk', 'kk', 'kk', 'kk', 'kk'],\n",
       "  ['kk', 'kk', 'kk', 'kk'],\n",
       "  ['kk', 'kk', 'kk', 'kk', 'kk', 'kk', 'kk', 'kk', 'kk'],\n",
       "  ['kk', 'kk', 'kk', 'kk', 'kk']]}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "panx_kk[\"train\"][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "382e015d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "Generating train split: 100%|██████████| 20000/20000 [00:00<00:00, 1350257.22 examples/s]\n",
      "Generating validation split: 100%|██████████| 10000/10000 [00:00<00:00, 1168427.45 examples/s]\n",
      "Generating test split: 100%|██████████| 10000/10000 [00:00<00:00, 1197996.06 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'tokens': [['Илизаров', ',', 'Гавриил', 'Абрамович'],\n",
       "  [\"'\", \"''\", 'Рыбницкий', 'район', \"''\", \"'\"],\n",
       "  ['За',\n",
       "   'образцовое',\n",
       "   'выполнение',\n",
       "   'заданий',\n",
       "   'командования',\n",
       "   'в',\n",
       "   'боях',\n",
       "   'с',\n",
       "   'немецкими',\n",
       "   'захватчиками',\n",
       "   ',',\n",
       "   'за',\n",
       "   'овладение',\n",
       "   'городом',\n",
       "   'Демблин',\n",
       "   'и',\n",
       "   'проявленные',\n",
       "   'при',\n",
       "   'этом',\n",
       "   'доблесть',\n",
       "   'и',\n",
       "   'мужество',\n",
       "   '.'],\n",
       "  ['Стадион', 'имени', 'С.', 'Дарюса', 'и', 'С.', 'Гиренаса'],\n",
       "  ['Майкл', 'Томас', '(', '1987—1991', ')']],\n",
       " 'ner_tags': [[1, 2, 2, 2],\n",
       "  [0, 0, 5, 6, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [5, 6, 6, 6, 6, 6, 6],\n",
       "  [1, 2, 0, 0, 0]],\n",
       " 'langs': [['ru', 'ru', 'ru', 'ru'],\n",
       "  ['ru', 'ru', 'ru', 'ru', 'ru', 'ru'],\n",
       "  ['ru',\n",
       "   'ru',\n",
       "   'ru',\n",
       "   'ru',\n",
       "   'ru',\n",
       "   'ru',\n",
       "   'ru',\n",
       "   'ru',\n",
       "   'ru',\n",
       "   'ru',\n",
       "   'ru',\n",
       "   'ru',\n",
       "   'ru',\n",
       "   'ru',\n",
       "   'ru',\n",
       "   'ru',\n",
       "   'ru',\n",
       "   'ru',\n",
       "   'ru',\n",
       "   'ru',\n",
       "   'ru',\n",
       "   'ru',\n",
       "   'ru'],\n",
       "  ['ru', 'ru', 'ru', 'ru', 'ru', 'ru', 'ru'],\n",
       "  ['ru', 'ru', 'ru', 'ru', 'ru']]}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "panx_ru = load_dataset(\"xtreme\", name=\"PAN-X.ru\")\n",
    "panx_ru[\"train\"][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "064a7193",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tokens': ['Жак', 'Дерриданың', 'деконструкция', 'ілімі', ';'],\n",
       " 'ner_tags': [1, 2, 0, 0, 0],\n",
       " 'langs': ['kk', 'kk', 'kk', 'kk', 'kk']}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "panx_kk[\"train\"][12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "791af4f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from datasets import DatasetDict\n",
    "from datasets import load_dataset\n",
    "\n",
    "\n",
    "langs = [\"de\", \"fr\", \"it\", \"en\"]\n",
    "fracs = [0.629, 0.229, 0.084, 0.059]\n",
    "# Return a DatasetDict if a key doesn't exist\n",
    "panx_ch = defaultdict(DatasetDict)\n",
    "\n",
    "for lang, frac in zip(langs, fracs):\n",
    "    # Load monolingual corpus\n",
    "    ds = load_dataset(\"xtreme\", name=f\"PAN-X.{lang}\")\n",
    "    # Shuffle and downsample each split according to spoken proportion\n",
    "    for split in ds:\n",
    "        panx_ch[lang][split] = (\n",
    "            ds[split]\n",
    "            .shuffle(seed=0)\n",
    "            .select(range(int(frac * ds[split].num_rows))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2d6e34e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "validation\n",
      "test\n"
     ]
    }
   ],
   "source": [
    "for i in panx_kk:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3af2fb52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['de', 'fr', 'it', 'en']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "langs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5ff13801",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>de</th>\n",
       "      <th>fr</th>\n",
       "      <th>it</th>\n",
       "      <th>en</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Number of training examples</th>\n",
       "      <td>12580</td>\n",
       "      <td>4580</td>\n",
       "      <td>1680</td>\n",
       "      <td>1180</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                de    fr    it    en\n",
       "Number of training examples  12580  4580  1680  1180"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.DataFrame({lang: [panx_ch[lang][\"train\"].num_rows] for lang in langs}, index=[\"Number of training examples\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a91c0f0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['tokens', 'ner_tags', 'langs'],\n",
       "        num_rows: 1180\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['tokens', 'ner_tags', 'langs'],\n",
       "        num_rows: 590\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['tokens', 'ner_tags', 'langs'],\n",
       "        num_rows: 590\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "panx_ch[\"en\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "00816a41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokens: ['2.000', 'Einwohnern', 'an', 'der', 'Danziger', 'Bucht', 'in', 'der', 'polnischen', 'Woiwodschaft', 'Pommern', '.']\n",
      "ner_tags: [0, 0, 0, 0, 5, 6, 0, 0, 5, 5, 6, 0]\n",
      "langs: ['de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "element = panx_ch[\"de\"][\"train\"][0]\n",
    "for key, value in element.items():\n",
    "    print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d0e3b61d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokens: List(Value('string'))\n",
      "ner_tags: List(ClassLabel(names=['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC']))\n",
      "langs: List(Value('string'))\n"
     ]
    }
   ],
   "source": [
    "for key, value in panx_ch[\"de\"][\"train\"].features.items():\n",
    "    print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d0df4c49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ClassLabel(names=['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC'])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "tags = panx_ch[\"de\"][\"train\"].features[\"ner_tags\"].feature\n",
    "print(tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9acc3d31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['tokens', 'ner_tags', 'langs', 'ner_tags_str'],\n",
       "        num_rows: 12580\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['tokens', 'ner_tags', 'langs', 'ner_tags_str'],\n",
       "        num_rows: 6290\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['tokens', 'ner_tags', 'langs', 'ner_tags_str'],\n",
       "        num_rows: 6290\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def create_tag_names(batch):\n",
    "    return {\"ner_tags_str\": [tags.int2str(idx) for idx in batch[\"ner_tags\"]]}\n",
    "\n",
    "panx_de = panx_ch[\"de\"].map(create_tag_names)\n",
    "panx_de"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d5c98f40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokens: ['2.000', 'Einwohnern', 'an', 'der', 'Danziger', 'Bucht', 'in', 'der', 'polnischen', 'Woiwodschaft', 'Pommern', '.']\n",
      "ner_tags: [0, 0, 0, 0, 5, 6, 0, 0, 5, 5, 6, 0]\n",
      "langs: ['de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de']\n",
      "ner_tags_str: ['O', 'O', 'O', 'O', 'B-LOC', 'I-LOC', 'O', 'O', 'B-LOC', 'B-LOC', 'I-LOC', 'O']\n"
     ]
    }
   ],
   "source": [
    "for key, value in panx_de[\"train\"][0].items():\n",
    "    print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "24507432",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 0, 5, 6, 0, 0, 5, 5, 6, 0]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "panx_de[\"train\"][0][\"ner_tags\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "23cfea35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ClassLabel(names=['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC'])\n"
     ]
    }
   ],
   "source": [
    "tags_en = panx_ch[\"en\"][\"train\"].features[\"ner_tags\"].feature\n",
    "print(tags_en)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8f98ee9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['tokens', 'ner_tags', 'langs', 'ner_tags_str'],\n",
       "        num_rows: 1180\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['tokens', 'ner_tags', 'langs', 'ner_tags_str'],\n",
       "        num_rows: 590\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['tokens', 'ner_tags', 'langs', 'ner_tags_str'],\n",
       "        num_rows: 590\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def create_tag_names(batch):\n",
    "    return {\"ner_tags_str\": [tags_en.int2str(idx) for idx in batch[\"ner_tags\"]]}\n",
    "\n",
    "panx_en = panx_ch[\"en\"].map(create_tag_names)\n",
    "panx_en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "74d892a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokens: ['Vaivara', 'concentration', 'camp', ',', 'Vaivara', '(', \"''1943–1944\", ',', 'during', 'German', 'occupation', \"''\", ')']\n",
      "ner_tags: [5, 6, 6, 0, 5, 0, 0, 0, 0, 3, 4, 0, 0]\n",
      "langs: ['en', 'en', 'en', 'en', 'en', 'en', 'en', 'en', 'en', 'en', 'en', 'en', 'en']\n",
      "ner_tags_str: ['B-LOC', 'I-LOC', 'I-LOC', 'O', 'B-LOC', 'O', 'O', 'O', 'O', 'B-ORG', 'I-ORG', 'O', 'O']\n"
     ]
    }
   ],
   "source": [
    "for key, value in panx_en[\"train\"][2].items():\n",
    "    print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "62044014",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Tokens</th>\n",
       "      <td>2.000</td>\n",
       "      <td>Einwohnern</td>\n",
       "      <td>an</td>\n",
       "      <td>der</td>\n",
       "      <td>Danziger</td>\n",
       "      <td>Bucht</td>\n",
       "      <td>in</td>\n",
       "      <td>der</td>\n",
       "      <td>polnischen</td>\n",
       "      <td>Woiwodschaft</td>\n",
       "      <td>Pommern</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tags</th>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>B-LOC</td>\n",
       "      <td>I-LOC</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>B-LOC</td>\n",
       "      <td>B-LOC</td>\n",
       "      <td>I-LOC</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           0           1   2    3         4      5   6    7           8   \\\n",
       "Tokens  2.000  Einwohnern  an  der  Danziger  Bucht  in  der  polnischen   \n",
       "Tags        O           O   O    O     B-LOC  I-LOC   O    O       B-LOC   \n",
       "\n",
       "                  9        10 11  \n",
       "Tokens  Woiwodschaft  Pommern  .  \n",
       "Tags           B-LOC    I-LOC  O  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "de_example = panx_de[\"train\"][0]\n",
    "pd.DataFrame([de_example[\"tokens\"], de_example[\"ner_tags_str\"]],\n",
    "['Tokens', 'Tags'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "687faeba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LOC</th>\n",
       "      <th>ORG</th>\n",
       "      <th>PER</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>train</th>\n",
       "      <td>6186</td>\n",
       "      <td>5366</td>\n",
       "      <td>5810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>validation</th>\n",
       "      <td>3172</td>\n",
       "      <td>2683</td>\n",
       "      <td>2893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test</th>\n",
       "      <td>3180</td>\n",
       "      <td>2573</td>\n",
       "      <td>3071</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             LOC   ORG   PER\n",
       "train       6186  5366  5810\n",
       "validation  3172  2683  2893\n",
       "test        3180  2573  3071"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from collections import Counter\n",
    "\n",
    "split2freqs = defaultdict(Counter)\n",
    "for split, dataset in panx_de.items():\n",
    "    for row in dataset[\"ner_tags_str\"]:\n",
    "        for tag in row:\n",
    "            if tag.startswith(\"B\"):\n",
    "                tag_type = tag.split(\"-\")[1]\n",
    "                split2freqs[split][tag_type] += 1\n",
    "pd.DataFrame.from_dict(split2freqs, orient=\"index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bab70f6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(collections.Counter,\n",
       "            {'train': Counter({'LOC': 6186, 'PER': 5810, 'ORG': 5366}),\n",
       "             'validation': Counter({'LOC': 3172, 'PER': 2893, 'ORG': 2683}),\n",
       "             'test': Counter({'LOC': 3180, 'PER': 3071, 'ORG': 2573})})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split2freqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8a1fb596",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "bert_model_name = \"bert-base-cased\"\n",
    "xlmr_model_name = \"xlm-roberta-base\"\n",
    "bert_tokenizer = AutoTokenizer.from_pretrained(bert_model_name)\n",
    "xlmr_tokenizer = AutoTokenizer.from_pretrained(xlmr_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8cbfe8cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XLMRobertaTokenizerFast(name_or_path='xlm-roberta-base', vocab_size=250002, model_max_length=512, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<s>', 'eos_token': '</s>', 'unk_token': '<unk>', 'sep_token': '</s>', 'pad_token': '<pad>', 'cls_token': '<s>', 'mask_token': '<mask>'}, clean_up_tokenization_spaces=False, added_tokens_decoder={\n",
       "\t0: AddedToken(\"<s>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t1: AddedToken(\"<pad>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t2: AddedToken(\"</s>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t3: AddedToken(\"<unk>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t250001: AddedToken(\"<mask>\", rstrip=False, lstrip=True, single_word=False, normalized=False, special=True),\n",
       "}\n",
       ")"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xlmr_tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2e8d431a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'unk_token': '[UNK]',\n",
       " 'sep_token': '[SEP]',\n",
       " 'pad_token': '[PAD]',\n",
       " 'cls_token': '[CLS]',\n",
       " 'mask_token': '[MASK]'}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_tokenizer.special_tokens_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f4bb0602",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bos_token': '<s>',\n",
       " 'eos_token': '</s>',\n",
       " 'unk_token': '<unk>',\n",
       " 'sep_token': '</s>',\n",
       " 'pad_token': '<pad>',\n",
       " 'cls_token': '<s>',\n",
       " 'mask_token': '<mask>'}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xlmr_tokenizer.special_tokens_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "665c4a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Jack Sparrow loves New York!\"\n",
    "bert_tokens = bert_tokenizer(text).tokens()\n",
    "xlmr_tokens = xlmr_tokenizer(text).tokens()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "eda1979a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[CLS]', 'Jack', 'Spa', '##rrow', 'loves', 'New', 'York', '!', '[SEP]']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "01f0fe94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<s>', '▁Jack', '▁Spar', 'row', '▁love', 's', '▁New', '▁York', '!', '</s>']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xlmr_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "337bda00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<s>▁Jack▁Sparrow▁loves▁New▁York!</s>'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\".join(xlmr_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "47cda699",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<s> Jack Sparrow loves New York!</s>'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\".join(xlmr_tokens).replace(u\"\\u2581\", \" \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "09643af0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[CLS]JackSpa##rrowlovesNewYork![SEP]'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\".join(bert_tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1047557a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from transformers import XLMRobertaConfig\n",
    "from transformers.modeling_outputs import TokenClassifierOutput\n",
    "from transformers.models.roberta.modeling_roberta import RobertaModel\n",
    "from transformers.models.roberta.modeling_roberta import RobertaPreTrainedModel\n",
    "\n",
    "class XLMRobertaForTokenClassification(RobertaPreTrainedModel):\n",
    "    config_class = XLMRobertaConfig\n",
    "\n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "        self.num_labels = config.num_labels\n",
    "        # Load model body\n",
    "        self.roberta = RobertaModel(config, add_pooling_layer=False)\n",
    "        # Set up token classification head\n",
    "        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
    "        self.classifier = nn.Linear(config.hidden_size, config.num_labels)\n",
    "        # Load and initialize weights\n",
    "        self.init_weights()\n",
    "\n",
    "    def forward(self, input_ids=None, attention_mask=None, token_type_ids=None, \n",
    "                labels=None, **kwargs):\n",
    "        # Use model body to get encoder representations\n",
    "        outputs = self.roberta(input_ids, attention_mask=attention_mask,\n",
    "                               token_type_ids=token_type_ids)\n",
    "        # Apply classifier to encoder representation\n",
    "        sequence_output = self.dropout(outputs[0])\n",
    "        logits = self.classifier(sequence_output)\n",
    "        # Calculate losses\n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "            loss_fct = nn.CrossEntropyLoss()\n",
    "            loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1))\n",
    "        # Return model output object\n",
    "        return TokenClassifierOutput(loss=loss, logits=logits, \n",
    "                                     hidden_states=outputs.hidden_states, \n",
    "                                     attentions=outputs.attentions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "374e4cc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ClassLabel(names=['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC'])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bd410340",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags.num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "650af991",
   "metadata": {},
   "outputs": [],
   "source": [
    "index2tag = {idx: tag for idx, tag in enumerate(tags.names)}\n",
    "tag2index = {tag: idx for idx, tag in enumerate(tags.names)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "60d8b887",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ed55aa0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XLMRobertaConfig {\n",
       "  \"architectures\": [\n",
       "    \"XLMRobertaForMaskedLM\"\n",
       "  ],\n",
       "  \"attention_probs_dropout_prob\": 0.1,\n",
       "  \"bos_token_id\": 0,\n",
       "  \"classifier_dropout\": null,\n",
       "  \"eos_token_id\": 2,\n",
       "  \"hidden_act\": \"gelu\",\n",
       "  \"hidden_dropout_prob\": 0.1,\n",
       "  \"hidden_size\": 768,\n",
       "  \"id2label\": {\n",
       "    \"0\": \"O\",\n",
       "    \"1\": \"B-PER\",\n",
       "    \"2\": \"I-PER\",\n",
       "    \"3\": \"B-ORG\",\n",
       "    \"4\": \"I-ORG\",\n",
       "    \"5\": \"B-LOC\",\n",
       "    \"6\": \"I-LOC\"\n",
       "  },\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"intermediate_size\": 3072,\n",
       "  \"label2id\": {\n",
       "    \"B-LOC\": 5,\n",
       "    \"B-ORG\": 3,\n",
       "    \"B-PER\": 1,\n",
       "    \"I-LOC\": 6,\n",
       "    \"I-ORG\": 4,\n",
       "    \"I-PER\": 2,\n",
       "    \"O\": 0\n",
       "  },\n",
       "  \"layer_norm_eps\": 1e-05,\n",
       "  \"max_position_embeddings\": 514,\n",
       "  \"model_type\": \"xlm-roberta\",\n",
       "  \"num_attention_heads\": 12,\n",
       "  \"num_hidden_layers\": 12,\n",
       "  \"output_past\": true,\n",
       "  \"pad_token_id\": 1,\n",
       "  \"position_embedding_type\": \"absolute\",\n",
       "  \"transformers_version\": \"4.57.3\",\n",
       "  \"type_vocab_size\": 1,\n",
       "  \"use_cache\": true,\n",
       "  \"vocab_size\": 250002\n",
       "}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoConfig\n",
    "\n",
    "xlmr_config = AutoConfig.from_pretrained(xlmr_model_name,\n",
    "                                         num_labels=tags.num_classes,\n",
    "                                         id2label=index2tag,\n",
    "                                         label2id=tag2index,\n",
    "                                         device=device)\n",
    "xlmr_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "5013c201",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "xlmr_model1 = XLMRobertaForTokenClassification.from_pretrained(xlmr_model_name ,config=xlmr_config).cpu()\n",
    "xlmr_model1 = XLMRobertaForTokenClassification(config=xlmr_config).cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "c9514357",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Tokens</th>\n",
       "      <td>&lt;s&gt;</td>\n",
       "      <td>▁Jack</td>\n",
       "      <td>▁Spar</td>\n",
       "      <td>row</td>\n",
       "      <td>▁love</td>\n",
       "      <td>s</td>\n",
       "      <td>▁New</td>\n",
       "      <td>▁York</td>\n",
       "      <td>!</td>\n",
       "      <td>&lt;/s&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Input IDs</th>\n",
       "      <td>0</td>\n",
       "      <td>21763</td>\n",
       "      <td>37456</td>\n",
       "      <td>15555</td>\n",
       "      <td>5161</td>\n",
       "      <td>7</td>\n",
       "      <td>2356</td>\n",
       "      <td>5753</td>\n",
       "      <td>38</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             0      1      2      3      4  5     6      7   8     9\n",
       "Tokens     <s>  ▁Jack  ▁Spar    row  ▁love  s  ▁New  ▁York   !  </s>\n",
       "Input IDs    0  21763  37456  15555   5161  7  2356   5753  38     2"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids = xlmr_tokenizer.encode(text, return_tensors=\"pt\")\n",
    "\n",
    "pd.DataFrame([xlmr_tokens, input_ids[0].numpy()], index=[\"Tokens\", \"Input IDs\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "bfb78d6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[    0, 21763, 37456, 15555,  5161,     7,  2356,  5753,    38,     2]])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids.to(device)\n",
    "input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "c41bc8c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<s>', '▁Jack', '▁Spar', 'row', '▁love', 's', '▁New', '▁York', '!', '</s>']"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xlmr_tokenizer(text).tokens()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "18d35ce2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "f9f0dbe2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.1196,  0.5664, -0.5502,  0.5771, -0.4268,  0.5773,  0.2438],\n",
       "         [ 0.7433,  0.0669,  0.3027, -0.1026, -1.1820,  0.3063,  0.3082],\n",
       "         [ 0.2319,  0.1787, -0.1477,  0.3634, -0.3781, -0.6858,  1.3420],\n",
       "         [-0.5762,  0.0567,  0.7895,  0.4917, -0.7455,  0.1416,  1.2848],\n",
       "         [ 0.4184,  0.0890,  1.0477,  0.4860, -0.8394,  0.5345,  0.2766],\n",
       "         [-0.7429,  0.3653,  0.3284,  1.0996, -1.5057,  0.3363,  0.3359],\n",
       "         [ 0.4232,  0.5209,  0.1701, -0.9166, -1.2541,  0.0804,  0.4161],\n",
       "         [ 0.0275,  0.3311,  0.3503,  0.2729, -1.6838, -0.4275,  0.2839],\n",
       "         [-0.7831,  0.4785,  0.0381, -0.0293, -0.2708,  0.2184,  0.0749],\n",
       "         [-0.1421,  0.0553, -0.1704, -0.0115, -0.7101, -0.1696,  0.4193]]],\n",
       "       grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs = xlmr_model1(input_ids).logits\n",
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "b758278d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[5, 0, 6, 6, 2, 3, 1, 2, 1, 6]])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = outputs.argmax(-1)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "96a66f2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tokens in sequence: 10\n",
      "Shape of outputs: torch.Size([1, 10, 7])\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of tokens in sequence: {len(xlmr_tokens)}\")\n",
    "print(f\"Shape of outputs: {outputs.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "ed06fa45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC']"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags.names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "eee86078",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['B-LOC',\n",
       " 'O',\n",
       " 'I-LOC',\n",
       " 'I-LOC',\n",
       " 'I-PER',\n",
       " 'B-ORG',\n",
       " 'B-PER',\n",
       " 'I-PER',\n",
       " 'B-PER',\n",
       " 'I-LOC']"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = [tags.names[p] for p in predictions[0].cpu().numpy()]\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "fdb79006",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Tokens</th>\n",
       "      <td>&lt;s&gt;</td>\n",
       "      <td>▁Jack</td>\n",
       "      <td>▁Spar</td>\n",
       "      <td>row</td>\n",
       "      <td>▁love</td>\n",
       "      <td>s</td>\n",
       "      <td>▁New</td>\n",
       "      <td>▁York</td>\n",
       "      <td>!</td>\n",
       "      <td>&lt;/s&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tags</th>\n",
       "      <td>B-LOC</td>\n",
       "      <td>O</td>\n",
       "      <td>I-LOC</td>\n",
       "      <td>I-LOC</td>\n",
       "      <td>I-PER</td>\n",
       "      <td>B-ORG</td>\n",
       "      <td>B-PER</td>\n",
       "      <td>I-PER</td>\n",
       "      <td>B-PER</td>\n",
       "      <td>I-LOC</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            0      1      2      3      4      5      6      7      8      9\n",
       "Tokens    <s>  ▁Jack  ▁Spar    row  ▁love      s   ▁New  ▁York      !   </s>\n",
       "Tags    B-LOC      O  I-LOC  I-LOC  I-PER  B-ORG  B-PER  I-PER  B-PER  I-LOC"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame([xlmr_tokens, preds], index=[\"Tokens\", \"Tags\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "61983d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tag_text(text, tags, model,tokenizer):\n",
    "    tokens = tokenizer(text).tokens()\n",
    "    input_ids = tokenizer(text, return_tensors=\"pt\").input_ids.to(device)\n",
    "    outputs = model(input_ids)[0]\n",
    "    predictions = outputs.argmax(-1)\n",
    "    preds = [tags.names[p] for p in predictions[0].cpu().numpy()]\n",
    "    return pd.DataFrame([tokens, preds], index=[\"Tokens\", \"Tags\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "a51788e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokens: ['2.000', 'Einwohnern', 'an', 'der', 'Danziger', 'Bucht', 'in', 'der', 'polnischen', 'Woiwodschaft', 'Pommern', '.']\n",
      "ner_tags: [0, 0, 0, 0, 5, 6, 0, 0, 5, 5, 6, 0]\n",
      "langs: ['de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de']\n",
      "ner_tags_str: ['O', 'O', 'O', 'O', 'B-LOC', 'I-LOC', 'O', 'O', 'B-LOC', 'B-LOC', 'I-LOC', 'O']\n"
     ]
    }
   ],
   "source": [
    "for key, value in de_example.items():\n",
    "    print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "00e7077f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['2.000',\n",
       "  'Einwohnern',\n",
       "  'an',\n",
       "  'der',\n",
       "  'Danziger',\n",
       "  'Bucht',\n",
       "  'in',\n",
       "  'der',\n",
       "  'polnischen',\n",
       "  'Woiwodschaft',\n",
       "  'Pommern',\n",
       "  '.'],\n",
       " [0, 0, 0, 0, 5, 6, 0, 0, 5, 5, 6, 0])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = de_example[\"tokens\"]\n",
    "labels = de_example[\"ner_tags\"]\n",
    "words, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1ad73b4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [0, 70101, 176581, 19, 142, 122, 2290, 708, 1505, 18363, 18, 23, 122, 127474, 15439, 13787, 14, 15263, 18917, 663, 6947, 19, 6, 5, 2], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_input = xlmr_tokenizer(words, is_split_into_words=True)\n",
    "tokenized_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "383121f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Tokens</th>\n",
       "      <td>&lt;s&gt;</td>\n",
       "      <td>▁2.000</td>\n",
       "      <td>▁Einwohner</td>\n",
       "      <td>n</td>\n",
       "      <td>▁an</td>\n",
       "      <td>▁der</td>\n",
       "      <td>▁Dan</td>\n",
       "      <td>zi</td>\n",
       "      <td>ger</td>\n",
       "      <td>▁Buch</td>\n",
       "      <td>...</td>\n",
       "      <td>▁Wo</td>\n",
       "      <td>i</td>\n",
       "      <td>wod</td>\n",
       "      <td>schaft</td>\n",
       "      <td>▁Po</td>\n",
       "      <td>mmer</td>\n",
       "      <td>n</td>\n",
       "      <td>▁</td>\n",
       "      <td>.</td>\n",
       "      <td>&lt;/s&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0       1           2  3    4     5     6   7    8      9   ...   15  \\\n",
       "Tokens  <s>  ▁2.000  ▁Einwohner  n  ▁an  ▁der  ▁Dan  zi  ger  ▁Buch  ...  ▁Wo   \n",
       "\n",
       "       16   17      18   19    20 21 22 23    24  \n",
       "Tokens  i  wod  schaft  ▁Po  mmer  n  ▁  .  </s>  \n",
       "\n",
       "[1 rows x 25 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = xlmr_tokenizer.convert_ids_to_tokens(tokenized_input[\"input_ids\"])\n",
    "pd.DataFrame([tokens],index=[\"Tokens\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "aefd15e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "transformers.tokenization_utils_base.BatchEncoding"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(tokenized_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fbdc1f46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Tokens</th>\n",
       "      <td>&lt;s&gt;</td>\n",
       "      <td>▁2.000</td>\n",
       "      <td>▁Einwohner</td>\n",
       "      <td>n</td>\n",
       "      <td>▁an</td>\n",
       "      <td>▁der</td>\n",
       "      <td>▁Dan</td>\n",
       "      <td>zi</td>\n",
       "      <td>ger</td>\n",
       "      <td>▁Buch</td>\n",
       "      <td>...</td>\n",
       "      <td>▁Wo</td>\n",
       "      <td>i</td>\n",
       "      <td>wod</td>\n",
       "      <td>schaft</td>\n",
       "      <td>▁Po</td>\n",
       "      <td>mmer</td>\n",
       "      <td>n</td>\n",
       "      <td>▁</td>\n",
       "      <td>.</td>\n",
       "      <td>&lt;/s&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Word ids</th>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0       1           2  3    4     5     6   7    8      9   ...  \\\n",
       "Tokens     <s>  ▁2.000  ▁Einwohner  n  ▁an  ▁der  ▁Dan  zi  ger  ▁Buch  ...   \n",
       "Word ids  None       0           1  1    2     3     4   4    4      5  ...   \n",
       "\n",
       "           15 16   17      18   19    20  21  22  23    24  \n",
       "Tokens    ▁Wo  i  wod  schaft  ▁Po  mmer   n   ▁   .  </s>  \n",
       "Word ids    9  9    9       9   10    10  10  11  11  None  \n",
       "\n",
       "[2 rows x 25 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "pd.DataFrame([tokens,tokenized_input.word_ids()],index=[\"Tokens\",\"Word ids\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "f52dfe64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 0, 5, 6, 0, 0, 5, 5, 6, 0]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3dbc5285",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-100,\n",
       " 0,\n",
       " 0,\n",
       " -100,\n",
       " 0,\n",
       " 0,\n",
       " 5,\n",
       " -100,\n",
       " -100,\n",
       " 6,\n",
       " -100,\n",
       " 0,\n",
       " 0,\n",
       " 5,\n",
       " -100,\n",
       " 5,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " 6,\n",
       " -100,\n",
       " -100,\n",
       " 0,\n",
       " -100,\n",
       " -100]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "previous_word_idx = None\n",
    "label_ids = []\n",
    "\n",
    "for word_idx in tokenized_input.word_ids():\n",
    "    if word_idx is None or word_idx == previous_word_idx:\n",
    "        label_ids.append(-100)\n",
    "    elif word_idx != previous_word_idx:\n",
    "        label_ids.append(labels[word_idx])\n",
    "    previous_word_idx = word_idx\n",
    "\n",
    "label_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d92f73d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['IGN',\n",
       " 'O',\n",
       " 'O',\n",
       " 'IGN',\n",
       " 'O',\n",
       " 'O',\n",
       " 'B-LOC',\n",
       " 'IGN',\n",
       " 'IGN',\n",
       " 'I-LOC',\n",
       " 'IGN',\n",
       " 'O',\n",
       " 'O',\n",
       " 'B-LOC',\n",
       " 'IGN',\n",
       " 'B-LOC',\n",
       " 'IGN',\n",
       " 'IGN',\n",
       " 'IGN',\n",
       " 'I-LOC',\n",
       " 'IGN',\n",
       " 'IGN',\n",
       " 'O',\n",
       " 'IGN',\n",
       " 'IGN']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = [index2tag[l] if l != -100 else \"IGN\" for l in label_ids]\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "41f819fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Tokens</th>\n",
       "      <td>&lt;s&gt;</td>\n",
       "      <td>▁2.000</td>\n",
       "      <td>▁Einwohner</td>\n",
       "      <td>n</td>\n",
       "      <td>▁an</td>\n",
       "      <td>▁der</td>\n",
       "      <td>▁Dan</td>\n",
       "      <td>zi</td>\n",
       "      <td>ger</td>\n",
       "      <td>▁Buch</td>\n",
       "      <td>...</td>\n",
       "      <td>▁Wo</td>\n",
       "      <td>i</td>\n",
       "      <td>wod</td>\n",
       "      <td>schaft</td>\n",
       "      <td>▁Po</td>\n",
       "      <td>mmer</td>\n",
       "      <td>n</td>\n",
       "      <td>▁</td>\n",
       "      <td>.</td>\n",
       "      <td>&lt;/s&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Word IDs</th>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Label IDs</th>\n",
       "      <td>-100</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-100</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>6</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>0</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Labels</th>\n",
       "      <td>IGN</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>IGN</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>B-LOC</td>\n",
       "      <td>IGN</td>\n",
       "      <td>IGN</td>\n",
       "      <td>I-LOC</td>\n",
       "      <td>...</td>\n",
       "      <td>B-LOC</td>\n",
       "      <td>IGN</td>\n",
       "      <td>IGN</td>\n",
       "      <td>IGN</td>\n",
       "      <td>I-LOC</td>\n",
       "      <td>IGN</td>\n",
       "      <td>IGN</td>\n",
       "      <td>O</td>\n",
       "      <td>IGN</td>\n",
       "      <td>IGN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0       1           2     3    4     5      6     7     8   \\\n",
       "Tokens      <s>  ▁2.000  ▁Einwohner     n  ▁an  ▁der   ▁Dan    zi   ger   \n",
       "Word IDs   None       0           1     1    2     3      4     4     4   \n",
       "Label IDs  -100       0           0  -100    0     0      5  -100  -100   \n",
       "Labels      IGN       O           O   IGN    O     O  B-LOC   IGN   IGN   \n",
       "\n",
       "              9   ...     15    16    17      18     19    20    21  22    23  \\\n",
       "Tokens     ▁Buch  ...    ▁Wo     i   wod  schaft    ▁Po  mmer     n   ▁     .   \n",
       "Word IDs       5  ...      9     9     9       9     10    10    10  11    11   \n",
       "Label IDs      6  ...      5  -100  -100    -100      6  -100  -100   0  -100   \n",
       "Labels     I-LOC  ...  B-LOC   IGN   IGN     IGN  I-LOC   IGN   IGN   O   IGN   \n",
       "\n",
       "             24  \n",
       "Tokens     </s>  \n",
       "Word IDs   None  \n",
       "Label IDs  -100  \n",
       "Labels      IGN  \n",
       "\n",
       "[4 rows x 25 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index = [\"Tokens\", \"Word IDs\", \"Label IDs\", \"Labels\"]\n",
    "\n",
    "word_ids = tokenized_input.word_ids()\n",
    "\n",
    "pd.DataFrame([tokens, word_ids, label_ids, labels], index=index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d53ce79f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets.arrow_dataset import Dataset\n",
    "\n",
    "def tokenize_and_align_labels(examples: Dataset):\n",
    "    tokenized_input = xlmr_tokenizer(examples[\"tokens\"], is_split_into_words=True, truncation=True)\n",
    "    labels = []\n",
    "    for idx, label_row in enumerate(examples[\"ner_tags\"]):\n",
    "        word_ids = tokenized_input.word_ids(batch_index=idx)\n",
    "\n",
    "        previous_word_idx = None\n",
    "        label_ids = []\n",
    "\n",
    "        for word_idx in word_ids:\n",
    "            if word_idx is None or word_idx == previous_word_idx:\n",
    "                label_ids.append(-100)\n",
    "            elif word_idx != previous_word_idx:\n",
    "                label_ids.append(label_row[word_idx])\n",
    "            previous_word_idx = word_idx\n",
    "        labels.append(label_ids)\n",
    "    tokenized_input[\"labels\"] = labels\n",
    "    return tokenized_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a43795ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1180/1180 [00:00<00:00, 21215.68 examples/s]\n",
      "Map: 100%|██████████| 590/590 [00:00<00:00, 42697.85 examples/s]\n",
      "Map: 100%|██████████| 590/590 [00:00<00:00, 48499.52 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 1180\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 590\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 590\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def encode_panx_dataset(corpus):\n",
    "    return corpus.map(tokenize_and_align_labels, batched=True, \n",
    "                      remove_columns=['langs', 'ner_tags', 'tokens'])\n",
    "     \n",
    "panx_en_encoded = encode_panx_dataset(panx_ch[\"en\"])\n",
    "panx_en_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "693d569e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [0, 242, 5106, 90915, 54012, 425, 5106, 242, 2],\n",
       " 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       " 'labels': [-100, 0, 0, 3, 4, -100, 0, 0, -100]}"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "panx_en_encoded[\"train\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "f3f549d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [0, 242, 5106, 90915, 54012, 425, 5106, 242, 2], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xlmr_tokenizer(panx_en[\"train\"][0][\"tokens\"], is_split_into_words=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "22f21156",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Column([[0, 0, 0, 0, 5, 6, 0, 0, 5, 5, 6, 0], [0, 0, 0, 3, 0, 0, 0, 3, 4, 0, 0], [0, 0, 0, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 0], [0, 0, 3, 4, 0, 0], [0, 1, 2, 2, 2]])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "panx_ch[\"de\"][\"train\"][\"ner_tags\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "3a0872d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datasets.arrow_dataset.Dataset"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(panx_ch[\"de\"][\"train\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e83838ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [0, 70101, 176581, 19, 142, 122, 2290, 708, 1505, 18363, 18, 23, 122, 127474, 15439, 13787, 14, 15263, 18917, 663, 6947, 19, 6, 5, 2], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_input = xlmr_tokenizer(panx_de[\"train\"][\"tokens\"][0], is_split_into_words=True)\n",
    "tokenized_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5530283e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'O',\n",
       " 1: 'B-PER',\n",
       " 2: 'I-PER',\n",
       " 3: 'B-ORG',\n",
       " 4: 'I-ORG',\n",
       " 5: 'B-LOC',\n",
       " 6: 'I-LOC'}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index2tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "cbd276ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<s>',\n",
       " '▁2.000',\n",
       " '▁Einwohner',\n",
       " 'n',\n",
       " '▁an',\n",
       " '▁der',\n",
       " '▁Dan',\n",
       " 'zi',\n",
       " 'ger',\n",
       " '▁Buch',\n",
       " 't',\n",
       " '▁in',\n",
       " '▁der',\n",
       " '▁polni',\n",
       " 'schen',\n",
       " '▁Wo',\n",
       " 'i',\n",
       " 'wod',\n",
       " 'schaft',\n",
       " '▁Po',\n",
       " 'mmer',\n",
       " 'n',\n",
       " '▁',\n",
       " '.',\n",
       " '</s>']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xlmr_tokenizer.convert_ids_to_tokens(tokenized_input[\"input_ids\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "273c9c2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 70101,\n",
       " 176581,\n",
       " 19,\n",
       " 142,\n",
       " 122,\n",
       " 2290,\n",
       " 708,\n",
       " 1505,\n",
       " 18363,\n",
       " 18,\n",
       " 23,\n",
       " 122,\n",
       " 127474,\n",
       " 15439,\n",
       " 13787,\n",
       " 14,\n",
       " 15263,\n",
       " 18917,\n",
       " 663,\n",
       " 6947,\n",
       " 19,\n",
       " 6,\n",
       " 5,\n",
       " 2]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_input[\"input_ids\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "be0f0272",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Column([['2.000', 'Einwohnern', 'an', 'der', 'Danziger', 'Bucht', 'in', 'der', 'polnischen', 'Woiwodschaft', 'Pommern', '.'], ['Sie', 'geht', 'hinter', 'Walluf', 'nahtlos', 'in', 'die', 'Bundesautobahn', '66', 'über', '.'], ['Dirigenten', 'von', 'Weltruf', 'wie', 'Wilhelm', 'Furtwängler', ',', 'Erich', 'Kleiber', ',', 'Wolfgang', 'Sawallisch', ',', 'Karl', 'Böhm', ',', 'Herbert', 'von', 'Karajan', ',', 'Rafael', 'Kubelík', ',', 'Erich', 'Kleiber', ',', 'Bernard', 'Haitink', ',', 'Josef', 'Krips', ',', 'Zubin', 'Mehta', ',', 'Dimitri', 'Mitropoulos', ',', 'Antal', 'Doráti', ',', 'Sergiu', 'Celibidache', 'und', 'andere', 'haben', 'seine', 'Werke', 'dirigiert', ',', 'zuletzt', 'besonders', 'Horst', 'Stein', '.'], [\"'\", \"''\", 'Stade', 'Reims', \"''\", \"'\"], ['2011', 'David', 'J.', 'P.', 'Barker']])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "panx_de[\"train\"][\"tokens\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f1e76afb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2.000',\n",
       " 'Einwohnern',\n",
       " 'an',\n",
       " 'der',\n",
       " 'Danziger',\n",
       " 'Bucht',\n",
       " 'in',\n",
       " 'der',\n",
       " 'polnischen',\n",
       " 'Woiwodschaft',\n",
       " 'Pommern',\n",
       " '.']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "panx_ch[\"de\"][\"train\"][\"tokens\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f44113b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clients</th>\n",
       "      <th>first_model</th>\n",
       "      <th>second_model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   clients  first_model  second_model\n",
       "0        0            0             0\n",
       "1        0            0             0\n",
       "2        0            1             0\n",
       "3        0            1             0\n",
       "4        0            1             0\n",
       "5        1            1             1\n",
       "6        1            1             1\n",
       "7        1            1             0\n",
       "8        1            1             0\n",
       "9        1            1             0"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clients = [0, 0, 0, 0, 0, \n",
    "           1, 1, 1, 1, 1]\n",
    "first_model_pred = [0, 0, 1, 1, 1,\n",
    "                    1, 1, 1, 1, 1]\n",
    "second_model_pred = [0, 0, 0, 0, 0,\n",
    "                     1, 1, 0, 0, 0]\n",
    "\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'clients': clients,\n",
    "    'first_model': first_model_pred,\n",
    "    'second_model': second_model_pred\n",
    "})\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "69e7d311",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.40      0.57         5\n",
      "           1       0.62      1.00      0.77         5\n",
      "\n",
      "    accuracy                           0.70        10\n",
      "   macro avg       0.81      0.70      0.67        10\n",
      "weighted avg       0.81      0.70      0.67        10\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(df['clients'], df['first_model']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "549fca7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        MISC       0.00      0.00      0.00         1\n",
      "         PER       1.00      1.00      1.00         1\n",
      "\n",
      "   micro avg       0.50      0.50      0.50         2\n",
      "   macro avg       0.50      0.50      0.50         2\n",
      "weighted avg       0.50      0.50      0.50         2\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from seqeval.metrics import classification_report\n",
    "\n",
    "y_true = [[\"O\", \"O\", \"O\", \"B-MISC\", \"I-MISC\", \"I-MISC\", \"O\"],\n",
    "          [\"B-PER\", \"I-PER\", \"O\"]]\n",
    "\n",
    "y_pred = [[\"O\", \"O\", \"B-MISC\", \"I-MISC\", \"I-MISC\", \"I-MISC\", \"O\"],\n",
    "          [\"B-PER\", \"I-PER\", \"O\"]]\n",
    "\n",
    "print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6d5bec3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['O', 'O', 'O', 'B-MISC', 'I-MISC', 'I-MISC', 'O'], ['B-PER', 'I-PER', 'O']]\n"
     ]
    }
   ],
   "source": [
    "print(y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "48d61d87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['O', 'O', 'B-MISC', 'I-MISC', 'I-MISC', 'I-MISC', 'O'], ['B-PER', 'I-PER', 'O']]\n"
     ]
    }
   ],
   "source": [
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "fee676f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 12580/12580 [00:00<00:00, 42727.49 examples/s]\n",
      "Map: 100%|██████████| 6290/6290 [00:00<00:00, 47659.45 examples/s]\n",
      "Map: 100%|██████████| 6290/6290 [00:00<00:00, 47069.33 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 12580\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 6290\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 6290\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "panx_de_encoded = encode_panx_dataset(panx_ch[\"de\"])\n",
    "panx_de_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "9d39f474",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': [0, 70101, 176581, 19, 142, 122, 2290, 708, 1505, 18363, 18, 23, 122, 127474, 15439, 13787, 14, 15263, 18917, 663, 6947, 19, 6, 5, 2], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'labels': [-100, 0, 0, -100, 0, 0, 5, -100, -100, 6, -100, 0, 0, 5, -100, 5, -100, -100, -100, 6, -100, -100, 0, -100, -100]}\n"
     ]
    }
   ],
   "source": [
    "print(panx_de_encoded[\"train\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d88bb2d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<s>', '▁2.000', '▁Einwohner', 'n', '▁an', '▁der', '▁Dan', 'zi', 'ger', '▁Buch', 't', '▁in', '▁der', '▁polni', 'schen', '▁Wo', 'i', 'wod', 'schaft', '▁Po', 'mmer', 'n', '▁', '.', '</s>']\n"
     ]
    }
   ],
   "source": [
    "print(xlmr_tokenizer.convert_ids_to_tokens(panx_de_encoded[\"train\"][0][\"input_ids\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "878aef8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'tokens': ['2.000', 'Einwohnern', 'an', 'der', 'Danziger', 'Bucht', 'in', 'der', 'polnischen', 'Woiwodschaft', 'Pommern', '.'], 'ner_tags': [0, 0, 0, 0, 5, 6, 0, 0, 5, 5, 6, 0], 'langs': ['de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de'], 'ner_tags_str': ['O', 'O', 'O', 'O', 'B-LOC', 'I-LOC', 'O', 'O', 'B-LOC', 'B-LOC', 'I-LOC', 'O']}\n"
     ]
    }
   ],
   "source": [
    "print(panx_de[\"train\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "5084408e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25, 25)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "len(panx_de_encoded[\"train\"][0]['labels']), len(panx_de_encoded[\"train\"][0][\"input_ids\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d6520704",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(panx_de[\"train\"][0][\"ner_tags\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "772ae16b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def align_predictions(predictions, label_ids):\n",
    "    preds = np.argmax(predictions, axis=2)\n",
    "    batch_size, seq_len = preds.shape\n",
    "    labels_list, preds_list = [], []\n",
    "\n",
    "    for batch_idx in range(batch_size):\n",
    "        example_labels, example_preds = [], []\n",
    "        for seq_idx in range(seq_len):\n",
    "            # Ignore label IDs = -100\n",
    "            if label_ids[batch_idx, seq_idx] != -100:\n",
    "                example_labels.append(index2tag[label_ids[batch_idx][seq_idx]])\n",
    "                example_preds.append(index2tag[preds[batch_idx][seq_idx]])\n",
    "\n",
    "        labels_list.append(example_labels)\n",
    "        preds_list.append(example_preds)\n",
    "\n",
    "    return preds_list, labels_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "3e5e8546",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'xlmr_model_name' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[57]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      5\u001b[39m batch_size = \u001b[32m16\u001b[39m\n\u001b[32m      6\u001b[39m logging_steps = \u001b[38;5;28mlen\u001b[39m(panx_de_encoded[\u001b[33m\"\u001b[39m\u001b[33mtrain\u001b[39m\u001b[33m\"\u001b[39m]) // batch_size\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m model_name = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mxlmr_model_name\u001b[49m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m-finetuned-panx-de\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      8\u001b[39m training_args = TrainingArguments(\n\u001b[32m      9\u001b[39m     output_dir=model_name, log_level=\u001b[33m\"\u001b[39m\u001b[33merror\u001b[39m\u001b[33m\"\u001b[39m, num_train_epochs=num_epochs, \n\u001b[32m     10\u001b[39m     per_device_train_batch_size=batch_size, \n\u001b[32m     11\u001b[39m     per_device_eval_batch_size=batch_size, eval_strategy=\u001b[33m\"\u001b[39m\u001b[33mepoch\u001b[39m\u001b[33m\"\u001b[39m, \n\u001b[32m     12\u001b[39m     save_steps=\u001b[32m1e6\u001b[39m, weight_decay=\u001b[32m0.01\u001b[39m, disable_tqdm=\u001b[38;5;28;01mFalse\u001b[39;00m, \n\u001b[32m     13\u001b[39m     logging_steps=logging_steps, push_to_hub=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[31mNameError\u001b[39m: name 'xlmr_model_name' is not defined"
     ]
    }
   ],
   "source": [
    "# hide_output\n",
    "from transformers import TrainingArguments\n",
    "\n",
    "num_epochs = 2\n",
    "batch_size = 16\n",
    "logging_steps = len(panx_de_encoded[\"train\"]) // batch_size\n",
    "model_name = f\"{xlmr_model_name}-finetuned-panx-de\"\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=model_name, log_level=\"error\", num_train_epochs=num_epochs, \n",
    "    per_device_train_batch_size=batch_size, \n",
    "    per_device_eval_batch_size=batch_size, eval_strategy=\"epoch\", \n",
    "    save_steps=1e6, weight_decay=0.01, disable_tqdm=False, \n",
    "    logging_steps=logging_steps, push_to_hub=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "68362d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from seqeval.metrics import f1_score\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    y_pred, y_true = align_predictions(eval_pred.predictions, \n",
    "                                       eval_pred.label_ids)\n",
    "    return {\"f1\": f1_score(y_true, y_pred)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "5f386c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForTokenClassification\n",
    "\n",
    "data_collator = DataCollatorForTokenClassification(xlmr_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "b0fd4b45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataCollatorForTokenClassification(tokenizer=XLMRobertaTokenizerFast(name_or_path='xlm-roberta-base', vocab_size=250002, model_max_length=512, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<s>', 'eos_token': '</s>', 'unk_token': '<unk>', 'sep_token': '</s>', 'pad_token': '<pad>', 'cls_token': '<s>', 'mask_token': '<mask>'}, clean_up_tokenization_spaces=False, added_tokens_decoder={\n",
       "\t0: AddedToken(\"<s>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t1: AddedToken(\"<pad>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t2: AddedToken(\"</s>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t3: AddedToken(\"<unk>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t250001: AddedToken(\"<mask>\", rstrip=False, lstrip=True, single_word=False, normalized=False, special=True),\n",
       "}\n",
       "), padding=True, max_length=None, pad_to_multiple_of=None, label_pad_token_id=-100, return_tensors='pt')"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_collator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "70f0f3a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XLMRobertaTokenizerFast(name_or_path='xlm-roberta-base', vocab_size=250002, model_max_length=512, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<s>', 'eos_token': '</s>', 'unk_token': '<unk>', 'sep_token': '</s>', 'pad_token': '<pad>', 'cls_token': '<s>', 'mask_token': '<mask>'}, clean_up_tokenization_spaces=False, added_tokens_decoder={\n",
       "\t0: AddedToken(\"<s>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t1: AddedToken(\"<pad>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t2: AddedToken(\"</s>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t3: AddedToken(\"<unk>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t250001: AddedToken(\"<mask>\", rstrip=False, lstrip=True, single_word=False, normalized=False, special=True),\n",
       "}\n",
       ")"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xlmr_tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "2ec95eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_init():\n",
    "    return (XLMRobertaForTokenClassification\n",
    "            .from_pretrained(xlmr_model_name, config=xlmr_config)\n",
    "            .to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "98931051",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer\n",
    "\n",
    "trainer = Trainer(model_init=model_init, args=training_args, \n",
    "                  data_collator=data_collator, compute_metrics=compute_metrics,\n",
    "                  train_dataset=panx_de_encoded[\"train\"],\n",
    "                  eval_dataset=panx_de_encoded[\"validation\"], \n",
    "                  processing_class=xlmr_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "65c7af83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<transformers.trainer.Trainer at 0x2cf450ef390>"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "03328b3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1574' max='1574' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1574/1574 04:44, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.249900</td>\n",
       "      <td>0.154983</td>\n",
       "      <td>0.823351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.120000</td>\n",
       "      <td>0.135701</td>\n",
       "      <td>0.853692</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1574, training_loss=0.1847677727003867, metrics={'train_runtime': 284.4927, 'train_samples_per_second': 88.438, 'train_steps_per_second': 5.533, 'total_flos': 528300598518528.0, 'train_loss': 0.1847677727003867, 'epoch': 2.0})"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "898cb65a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Upload 0 LFS files: 0it [00:00, ?it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/NurekeKZ/xlm-roberta-base-finetuned-panx-de/commit/cdd6af3d86c86da562f85b3dfa6c63b0c2b4ab11', commit_message='XLMR first train', commit_description='', oid='cdd6af3d86c86da562f85b3dfa6c63b0c2b4ab11', pr_url=None, repo_url=RepoUrl('https://huggingface.co/NurekeKZ/xlm-roberta-base-finetuned-panx-de', endpoint='https://huggingface.co', repo_type='model', repo_id='NurekeKZ/xlm-roberta-base-finetuned-panx-de'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.push_to_hub(commit_message=\"XLMR first train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "160bd262",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.2499</td>\n",
       "      <td>0.154983</td>\n",
       "      <td>0.823351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.1200</td>\n",
       "      <td>0.135701</td>\n",
       "      <td>0.853692</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Epoch  Training Loss  Validation Loss        F1\n",
       "0      1         0.2499         0.154983  0.823351\n",
       "2      2         0.1200         0.135701  0.853692"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(trainer.state.log_history)[['epoch','loss' ,'eval_loss', 'eval_f1']]\n",
    "df = df.rename(columns={\"epoch\":\"Epoch\",\"loss\": \"Training Loss\", \"eval_loss\": \"Validation Loss\", \"eval_f1\":\"F1\"})\n",
    "df['Epoch'] = df[\"Epoch\"].apply(lambda x: round(x))\n",
    "df['Training Loss'] = df[\"Training Loss\"].ffill()\n",
    "df[['Validation Loss', 'F1']] = df[['Validation Loss', 'F1']].bfill().ffill()\n",
    "df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "fa0aa888",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'trainer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[61]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m text_de = \u001b[33m\"\u001b[39m\u001b[33mJeff Dean ist ein Informatiker bei Google in Kalifornien\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m tag_text(text_de, tags, \u001b[43mtrainer\u001b[49m.model, xlmr_tokenizer)\n",
      "\u001b[31mNameError\u001b[39m: name 'trainer' is not defined"
     ]
    }
   ],
   "source": [
    "text_de = \"Jeff Dean ist ein Informatiker bei Google in Kalifornien\"\n",
    "tag_text(text_de, tags, trainer.model, xlmr_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a28a9b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tag_text(text, tags, model, tokenizer):\n",
    "    tokens = tokenizer(text).tokens()\n",
    "    input_ids = tokenizer(text, return_tensors=\"pt\").to(device)\n",
    "    model = model.to(device)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**input_ids).logits\n",
    "    predictions = outputs.argmax(-1)\n",
    "    preds = [tags.names[p] for p in predictions[0].cpu().numpy()]\n",
    "    return pd.DataFrame([tokens, preds], index=[\"Tokens\", \"Tags\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "c906e5f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
    "\n",
    "model_name = \"NurekeKZ/xlm-roberta-base-finetuned-panx-de\"\n",
    "\n",
    "xlmr_tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForTokenClassification.from_pretrained(model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "c9269501",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.functional import cross_entropy\n",
    "\n",
    "def forward_pass_with_label(batch):\n",
    "    # Convert dict of lists to list of dicts suitable for data collator\n",
    "    features = [dict(zip(batch, t)) for t in zip(*batch.values())]\n",
    "    # Pad inputs and labels and put all tensors on device\n",
    "    batch = data_collator(features)\n",
    "    input_ids = batch[\"input_ids\"].to(device)\n",
    "    attention_mask = batch[\"attention_mask\"].to(device)\n",
    "    labels = batch[\"labels\"].to(device)\n",
    "    with torch.no_grad():\n",
    "        # Pass data through model  \n",
    "        output = model(input_ids, attention_mask)\n",
    "        # Logit.size: [batch_size, sequence_length, classes]\n",
    "        # Predict class with largest logit value on classes axis\n",
    "        predicted_label = torch.argmax(output.logits, axis=-1).cpu().numpy()\n",
    "    # Calculate loss per token after flattening batch dimension with view\n",
    "    loss = cross_entropy(output.logits.view(-1, 7), \n",
    "                         labels.view(-1), reduction=\"none\")\n",
    "    # Unflatten batch dimension and convert to numpy array\n",
    "    loss = loss.view(len(input_ids), -1).cpu().numpy()\n",
    "\n",
    "    return {\"loss\":loss, \"predicted_label\": predicted_label}\n",
    "     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "43a35fc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 6290/6290 [00:53<00:00, 117.32 examples/s]\n"
     ]
    }
   ],
   "source": [
    "valid_set = panx_de_encoded[\"validation\"]\n",
    "valid_set = valid_set.map(forward_pass_with_label, batched=True, batch_size=32)\n",
    "df = valid_set.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "c18ebf19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [0, 10699, 11, 15, 16104, 1388, 2],\n",
       " 'attention_mask': [1, 1, 1, 1, 1, 1, 1],\n",
       " 'labels': [-100, 3, -100, 4, 4, 4, -100]}"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "panx_de_encoded[\"validation\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "558aa1c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [4, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, ...\n",
       "1    [0, 0, 0, 0, 0, 0, 5, 6, 6, 6, 6, 6, 6, 6, 6, ...\n",
       "Name: predicted_label, dtype: object"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[:1,\"predicted_label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "5e49c815",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [0, 10699, 11, 15, 16104, 1388, 2],\n",
       " 'attention_mask': [1, 1, 1, 1, 1, 1, 1],\n",
       " 'labels': [-100, 3, -100, 4, 4, 4, -100],\n",
       " 'loss': [0.0,\n",
       "  0.024126620963215828,\n",
       "  0.0,\n",
       "  0.019560888409614563,\n",
       "  0.01616455614566803,\n",
       "  0.019825981929898262,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0],\n",
       " 'predicted_label': [4,\n",
       "  3,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4]}"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_set[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "edeb39ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input_ids</th>\n",
       "      <th>attention_mask</th>\n",
       "      <th>labels</th>\n",
       "      <th>loss</th>\n",
       "      <th>predicted_label</th>\n",
       "      <th>input_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[0, 10699, 11, 15, 16104, 1388, 2]</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1]</td>\n",
       "      <td>[IGN, B-ORG, IGN, I-ORG, I-ORG, I-ORG, IGN]</td>\n",
       "      <td>[0.0, 0.024126621, 0.0, 0.019560888, 0.0161645...</td>\n",
       "      <td>[I-ORG, B-ORG, I-ORG, I-ORG, I-ORG, I-ORG, I-ORG]</td>\n",
       "      <td>[&lt;s&gt;, ▁Ham, a, ▁(, ▁Unternehmen, ▁), &lt;/s&gt;]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            input_ids         attention_mask  \\\n",
       "0  [0, 10699, 11, 15, 16104, 1388, 2]  [1, 1, 1, 1, 1, 1, 1]   \n",
       "\n",
       "                                        labels  \\\n",
       "0  [IGN, B-ORG, IGN, I-ORG, I-ORG, I-ORG, IGN]   \n",
       "\n",
       "                                                loss  \\\n",
       "0  [0.0, 0.024126621, 0.0, 0.019560888, 0.0161645...   \n",
       "\n",
       "                                     predicted_label  \\\n",
       "0  [I-ORG, B-ORG, I-ORG, I-ORG, I-ORG, I-ORG, I-ORG]   \n",
       "\n",
       "                                 input_tokens  \n",
       "0  [<s>, ▁Ham, a, ▁(, ▁Unternehmen, ▁), </s>]  "
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index2tag[-100] = \"IGN\"\n",
    "df[\"input_tokens\"] = df[\"input_ids\"].apply(\n",
    "    lambda x: xlmr_tokenizer.convert_ids_to_tokens(x))\n",
    "df[\"predicted_label\"] = df[\"predicted_label\"].apply(\n",
    "    lambda x: [index2tag[i] for i in x])\n",
    "df[\"labels\"] = df[\"labels\"].apply(\n",
    "    lambda x: [index2tag[i] for i in x])\n",
    "df['loss'] = df.apply(\n",
    "    lambda x: x['loss'][:len(x['input_ids'])], axis=1)\n",
    "df['predicted_label'] = df.apply(\n",
    "    lambda x: x['predicted_label'][:len(x['input_ids'])], axis=1)\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "e21a8512",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [<s>, ▁Ham, a, ▁(, ▁Unternehmen, ▁), </s>]\n",
       "Name: input_tokens, dtype: object"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(1)[\"input_tokens\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "39f8680c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input_ids</th>\n",
       "      <th>attention_mask</th>\n",
       "      <th>labels</th>\n",
       "      <th>loss</th>\n",
       "      <th>predicted_label</th>\n",
       "      <th>input_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10699</td>\n",
       "      <td>1</td>\n",
       "      <td>B-ORG</td>\n",
       "      <td>0.02</td>\n",
       "      <td>B-ORG</td>\n",
       "      <td>▁Ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>0.02</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>▁(</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16104</td>\n",
       "      <td>1</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>0.02</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>▁Unternehmen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1388</td>\n",
       "      <td>1</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>0.02</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>▁)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>56530</td>\n",
       "      <td>1</td>\n",
       "      <td>O</td>\n",
       "      <td>0.00</td>\n",
       "      <td>O</td>\n",
       "      <td>▁WE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>83982</td>\n",
       "      <td>1</td>\n",
       "      <td>B-ORG</td>\n",
       "      <td>1.94</td>\n",
       "      <td>B-LOC</td>\n",
       "      <td>▁Luz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>1.25</td>\n",
       "      <td>I-LOC</td>\n",
       "      <td>▁a</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  input_ids attention_mask labels  loss predicted_label  input_tokens\n",
       "0     10699              1  B-ORG  0.02           B-ORG          ▁Ham\n",
       "0        15              1  I-ORG  0.02           I-ORG            ▁(\n",
       "0     16104              1  I-ORG  0.02           I-ORG  ▁Unternehmen\n",
       "0      1388              1  I-ORG  0.02           I-ORG            ▁)\n",
       "1     56530              1      O  0.00               O           ▁WE\n",
       "1     83982              1  B-ORG  1.94           B-LOC          ▁Luz\n",
       "1        10              1  I-ORG  1.25           I-LOC            ▁a"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# hide_output\n",
    "df_tokens = df.apply(pd.Series.explode)\n",
    "df_tokens = df_tokens.query(\"labels != 'IGN'\")\n",
    "df_tokens[\"loss\"] = df_tokens[\"loss\"].astype(float).round(2)\n",
    "df_tokens.head(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "3c8fd01b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>input_tokens</th>\n",
       "      <td>▁</td>\n",
       "      <td>▁in</td>\n",
       "      <td>▁von</td>\n",
       "      <td>▁der</td>\n",
       "      <td>▁und</td>\n",
       "      <td>▁/</td>\n",
       "      <td>▁(</td>\n",
       "      <td>▁)</td>\n",
       "      <td>▁''</td>\n",
       "      <td>▁D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>6066</td>\n",
       "      <td>989</td>\n",
       "      <td>808</td>\n",
       "      <td>1388</td>\n",
       "      <td>1171</td>\n",
       "      <td>163</td>\n",
       "      <td>246</td>\n",
       "      <td>246</td>\n",
       "      <td>2898</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.03</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sum</th>\n",
       "      <td>180.76</td>\n",
       "      <td>119.13</td>\n",
       "      <td>117.52</td>\n",
       "      <td>110.93</td>\n",
       "      <td>92.48</td>\n",
       "      <td>90.86</td>\n",
       "      <td>75.02</td>\n",
       "      <td>67.16</td>\n",
       "      <td>63.7</td>\n",
       "      <td>49.04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   0       1       2       3      4      5      6      7  \\\n",
       "input_tokens       ▁     ▁in    ▁von    ▁der   ▁und     ▁/     ▁(     ▁)   \n",
       "count           6066     989     808    1388   1171    163    246    246   \n",
       "mean            0.03    0.12    0.15    0.08   0.08   0.56    0.3   0.27   \n",
       "sum           180.76  119.13  117.52  110.93  92.48  90.86  75.02  67.16   \n",
       "\n",
       "                 8      9  \n",
       "input_tokens   ▁''     ▁D  \n",
       "count         2898     89  \n",
       "mean          0.02   0.55  \n",
       "sum           63.7  49.04  "
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "(\n",
    "    df_tokens.groupby(\"input_tokens\")[[\"loss\"]]\n",
    "    .agg([\"count\", \"mean\", \"sum\"])\n",
    "    .droplevel(level=0, axis=1)  # Get rid of multi-level columns\n",
    "    .sort_values(by=\"sum\", ascending=False)\n",
    "    .reset_index()\n",
    "    .round(2)\n",
    "    .head(10)\n",
    "    .T\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "3597a212",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>labels</th>\n",
       "      <td>I-ORG</td>\n",
       "      <td>B-ORG</td>\n",
       "      <td>O</td>\n",
       "      <td>B-LOC</td>\n",
       "      <td>I-PER</td>\n",
       "      <td>B-PER</td>\n",
       "      <td>I-LOC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3820</td>\n",
       "      <td>2683</td>\n",
       "      <td>43648</td>\n",
       "      <td>3172</td>\n",
       "      <td>4139</td>\n",
       "      <td>2893</td>\n",
       "      <td>1462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.48</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sum</th>\n",
       "      <td>1825.4</td>\n",
       "      <td>1728.86</td>\n",
       "      <td>1317.43</td>\n",
       "      <td>943.09</td>\n",
       "      <td>864.04</td>\n",
       "      <td>840.18</td>\n",
       "      <td>777.77</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             0        1        2       3       4       5       6\n",
       "labels   I-ORG    B-ORG        O   B-LOC   I-PER   B-PER   I-LOC\n",
       "count     3820     2683    43648    3172    4139    2893    1462\n",
       "mean      0.48     0.64     0.03     0.3    0.21    0.29    0.53\n",
       "sum     1825.4  1728.86  1317.43  943.09  864.04  840.18  777.77"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(\n",
    "    df_tokens.groupby(\"labels\")[[\"loss\"]]\n",
    "    .agg([\"count\", \"mean\", \"sum\"])\n",
    "    .droplevel(level=0, axis=1)  # Get rid of multi-level columns\n",
    "    .sort_values(by=\"sum\", ascending=False)\n",
    "    .reset_index()\n",
    "    .round(2)\n",
    "    .head(10)\n",
    "    .T\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "1d69016f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import ConfusionMatrixDisplay, confusion_matrix\n",
    "\n",
    "def plot_confusion_matrix(y_preds, y_true, labels):\n",
    "    cm = confusion_matrix(y_true, y_preds, normalize=\"true\")\n",
    "    fig, ax = plt.subplots(figsize=(6, 6))\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels)\n",
    "    disp.plot(cmap=\"Blues\", values_format=\".2f\", ax=ax, colorbar=False)\n",
    "    plt.title(\"Normalized confusion matrix\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "6d456f5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAi0AAAIjCAYAAADP4ysCAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjgsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvwVt1zgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAjn5JREFUeJzt3QdYU1cbB/C/gFtBRXAgDhzgwomibcW96q51V62j7r3r3qO2jta9FfdWHHWjrXvvvXAjoLgX+Z73YEISEtR+Krn6/z1PlNyc3OS+OffeN2fcxNHpdDoQERER2Ti72H4DRERERO+DSQsRERFpApMWIiIi0gQmLURERKQJTFqIiIhIE5i0EBERkSYwaSEiIiJNYNJCREREmsCkhYiIiDSBSQvRV6h48eLqpnf16lXEiRMHs2fP/qzvo3HjxsiYMSNs1ePHj9GsWTOkTp1axadjx44f/TVk+yUOpK26QbGDSQuRBXLylpNUggQJcPPmzWiPywk/V65cjN0XbtiwYaoutGrVCvPmzcNPP/0U229Jc54+fYoBAwZgx44dsf1W6AvgENtvgMiWvXjxAiNGjMCff/6JL1mGDBnw7NkzxI0bN7bfik3Ztm0bfH190b9//0/2GufOnYOdnd0XnbQMHDhQ/W3cuvcu06ZNQ0RExCd8Z6RFX+6eQvQR5M2bVx08b9269cniKb9ZKglDbNK3Ktnb28fq+7A19+7dQ7JkyT7pa8SPH5/JopEnT56o/yWBltgQGWPSQhSDX3/9FW/evFGtLe/y+vVrDB48GJkzZ1YHW+mPl+dLa40xWV6pUiX8/fffKFiwIBImTIgpU6ao5nNJHpYsWaK+mbq5uSFp0qSoWbMmHj58qNYjYypcXV2RJEkS/Pzzz9HWPWvWLJQsWVKVkfeQI0cOTJo06Z3v3XxMi/69WLqZjzPYsGEDvvvuOyROnFi93++//x6nTp2K9hqrVq1SXWqSHMn/K1eufOf7Mn8dPz8/9RqOjo7w8fHBggULTMosXboUBQoUUDFNmTIlGjRoEK17T8ZKSPxkebVq1dTfLi4u6Nq1q/qsjbf/ypUrWLdunWHbJU76rkP525j+OcbdIBcuXMAPP/ygxsTIdqdLlw516tRRn2dMY1ouX76MH3/8ESlSpECiRIlUa4+8D0uvJ/Vl6NChat3yGqVKlcLFixffGU/pspHnnz9/XsXJyclJxaFv374qkQ4KCkLVqlVVrOX9//777ybPf/nyJfr166fiLc+Vz1/qwfbt2w1lJEayTiF1Wh9HeW3jz+LSpUuoWLGi+mzr169veMy4rklrl7RIbd261eR9/PLLL4gXLx6OHTv2zm0m7WP3EFEMMmXKhIYNG6rWlp49eyJt2rRWy8qAzTlz5qgko0uXLti3bx+GDx+OM2fORDtBS5dA3bp10aJFCzRv3hyenp6Gx+Q5ctKV15OTj3RNybdOOWCHhYWpA/7evXvVyVPen5w49CRByZkzJ6pUqQIHBwesXbsWrVu3Vs3sbdq0ee/POnv27GoMh7EHDx6gc+fOKiHSkzKNGjVCuXLlMHLkSNUVIO/h22+/xZEjRwwnnU2bNqmTtyRRsn0hISEq6ZIT7fuQbW3SpInatl69eqnWD1n/xo0bUa9ePUMZWackM/Iad+/exbhx4/Dvv/+qssYtJpKcyHsuXLgwRo8ejS1btqiTsiScMn5Fv/2dOnVS71E+T6E/Ab8POanLa0hi2a5dO3Xil0QpICBAxVJO9JbI+y5atKiKZfv27eHs7KzqlXymy5YtQ/Xq1U3KS0ItdUOSLkmGRo0apU78Uv/eR+3atdX2ynokMRoyZIhKliSRlgRYPtf58+er9UtsixUrpp4XHh6O6dOnq3osdfjRo0eYMWOG2ub9+/erVkqJl9QHiam87xo1aqjnent7myT78hypM/JZSJJmSZ8+fVR9btq0KU6cOKESHEn8Zd+ULwt58uR578+GNExHRNHMmjVLJ7vHgQMHdJcuXdI5ODjo2rdvb3jcz89PlzNnTsP9o0ePqvLNmjUzWU/Xrl3V8m3bthmWZciQQS3buHGjSdnt27er5bly5dK9fPnSsLxu3bq6OHHi6CpUqGBSvkiRImpdxp4+fRptW8qVK6fz8PAwWSbvX256V65cUa8t221JRESErlKlSrokSZLoTp06pZY9evRIlyxZMl3z5s1Nyt65c0fn5ORksjxv3ry6NGnS6B48eGBYtmnTJvWa5ttgTp6TNGlSXeHChXXPnj2L9r6ExMvV1VXFzrhMQECAeo1+/foZljVq1EgtGzRokMm68uXLpytQoIDJMnlv33//vcW6ITGz9PnJ/+LIkSPq/tKlS2PcPnkNeU96HTt2VM/btWuXYZnEOlOmTLqMGTPq3rx5Y/J62bNn17148cJQdty4cWr5iRMnYnzd/v37q3K//PKLYdnr16916dKlU/VtxIgRhuVhYWG6hAkTmrxPKWv8uvpyqVKl0jVp0sSwLDg4WL2OvJ45/WfRs2dPi4+Z1w3Zpnjx4qn9TF7Lzc1NV7BgQd2rV69i3Fb6crB7iOgdPDw81KyRqVOn4vbt2xbLrF+/Xv0vLRHG9N/QzZv2pYVEvl1aIi07xgNipTVAmuulpcGYLJcmfPmmqictNHryrfv+/fuqS0W6G4y7JD6UfJOVFgJpzZDWErF582bVYiDftOV19DcZFyPvTd9NIDE7evSoapExbl0oU6aMYV0xkdeRb/HS8iTdH8akq0EcPHhQjT+RViXjMtJV5eXlFS3+omXLlib3pWtD4vSx6LdVWgOk1eR9SV0qVKiQannQky4U6QaR7pbTp0+blJfWJekeMd4O8b7bIi2EevLZSZel1Ddp0dCTVippDTRep5TVv6605IWGhqq6KM8/fPgwPoS0xLwP6VaUbiZp4ZH9R+qbtEJJqyJ9HZi0EL0HaZqWA7K1sS3Xrl1TTfRZsmQxWS5dAnLAl8fNkxZr0qdPb/Hk5+7uHm25nCyMkxHpCildurQaXyCvK83zMq5G/NekRbpg5EQh3TLSxWM8XkNIF4K8jvFNuoMkiRD6bc+aNWu0dRt3i1kj4x1ETFPM9a9haX2StJjHXxIb866e5MmTq+63j0U+Y0li5QQr42vkJDthwoR3fg7yXi1th3Th6B+Pqb7Idoj33RZL9U3iI+/ZfLn5OiVhkK4eKS/dWBJTSRA/pK5JwvG+3YSiW7duqitIuqBknMv7JL705WB6SvSerS0yWFFaW+QbvzX6b/7vYtwiYs7aDB5ry+Vbsf7kLoMw5ST9xx9/qCRHvgnLN/cxY8b8p+mjMhBVxkdIq4iMdTCmX5+M/ZDkzJwtf/v9f2ZJWfuM9YN4jck4GRlQunr1apXIyRgVGW8jY5I+5EQdk3fVi//y/PdZp7+/v9o2GcwsiYSMdZLnyfbpE833IQPGP2TKt7T26BNmGdtCXxfbPaoQ2WBrixyoZWCipeucyElcDqb6b8T6QZXShSKPf2oySFEGfa5Zs8bk27PxbI4PIdOwZeCktNgsXLgw2olFBq0KOVlJ6441+m3Xn2jMByS/i/51Tp48Ga0ly/w1ZH3S8mP+Gh8z/vqWDPlcjZm3gOjlzp1b3aT+7N69G9988w0mT54cLQnUk/dqKS5nz541PG4LZFCwJPMrVqwwSeTMr2nzvon8+5B9TBIlmdEkM+nk4n8y8F0/wJe+fOweInpPcvKU1haZVXHnzh2Tx2S6phg7dqzJcmnx0I+t+NT0346Nvw1LM71Mg/4vZMyHTIeVmU/6E7Ux6e6Qk4ecOF69ehXt8eDgYPV/mjRp1EwS6Uow7jaQsSrm4zMsKVu2rJopIt/gnz9/bvKYfltlHIUkT5IMGE8Dl2nSMnvrY8Zfn0Tt3LnTpJVFWuGMyewa4/FGQpIXSf7Mp6qb1yXp+tizZ4/JtUtk/TIby1a6QyzVN5mxZPy+hX42kHmS91/I/iSJn8RCxlnJLCsZDyNjW+jrwJYWog/Qu3dv1R0i34Rl+q2e9LHLQFM5mMrBWQa/yolHTtTSfF6iRIlPHmc5uUt3UOXKldVUavndHJkOKidzawOIrZFxCXPnzlVjWI4fP65uxoNCZZskYZHprDJIOX/+/Or6IzKm4fr16+r50qLw119/qedIwiGJgwwulQHFMmhTpnJLDOV9xkReR7q3ZMCoTLmVKc6SRMl1OWSAq8RYBi5LC5gMSpXYy+Bg/ZRnOdHL1OWPRd6zXDdFxvjIdsj04EWLFkVLUORqum3btlXXW8mWLZt6XOqOnOyNxwaZk+5HadmqUKGC6k6S9cs2Slfd8uXLbebquXKtIWllkanM8tnK+5OkUZIq489UukJl2eLFi1UcZHtkfNKH/gyGJJ9yDRlpaZE6LmRguCTEMgBbrldDX4HYnr5EZOtTnq1N0zSe8ixk2uXAgQPV1NS4cePq3N3ddb169dI9f/78ndNojaewmk+RtfZe9FNWZUqp3po1a3Te3t66BAkSqOmxI0eO1M2cOTPaFN13TXnWv6alm/k0VHnfMq1apjnL62bOnFnXuHFj3cGDB03KLV++XE3PjR8/vi5Hjhy6FStWWJzWao1sW9GiRdXUW0dHR12hQoV0CxcuNCmzePFiNXVZXiNFihS6+vXr627cuGFSRl4zceLE0davj+f7fFYyDb506dLqdWSK76+//qrbvHmzyZTny5cvq6m/Eg+Ji7yfEiVK6LZs2RLtNYynEuvXX7NmTTWlXJ4r2yrTt9+nvrxr+npM9Sem+JhP85fp5sOGDVPvX+IgcZf3aOkz3b17t5pOLtOVjac/W3st/WP69cj0ah8fHzUd23javPEUb/ns6csXR/6J7cSJiIiI6F1so52RiIiI6B2YtBAREZEmMGkhIiIiTWDSQkRERJrApIWIiIg0gUkLERERaQIvLveRyWWmb926pa7g+TEvX01ERPQlkiuvyC+5p02b9p0XT2TS8pFJwmL+a7xEREQUs6CgoHf+kCiTlo9MWlhEvLIjESduAnzNTk2pH9tvwSYkjPfff1H4S2LHlkeFV/OMZG/Hlmi9128+/BfYvySPHoXDK3MGw/kzJkxaPjJ9l5AkLHHiJsTXLKmjY2y/BZuQiEmLwqQlEpOWSExaonztSYve+wyp4EBcIiIi0gQmLURERKQJTFqIiIhIE5i0EBERkSYwaSEiIiJNYNJCREREmsCkhYiIiDSBSQsRERFpApMWIiIi0gQmLURERKQJTFqIiIhIE5i0EBERkSYwaSEiIiJNYNJCREREmsCkhYiIiDSBSQsRERFpApMWIiIi0gQmLURERKQJTFqIiIhIE5i0EBERkSYwaSEiIiJNYNJCREREmsCkhYiIiDSBSQsRERFpgkNsvwF6P83K5UC7Kt5wTZYQJ6+FosfM3Th8Mdhq+ZYVc6FJuexIlzIJQsOfY/XeKxi04ABevHqjHj82oQ7SuyaN9rzpG0+h24zdNvuxzFnxD6Yu2obg0EfInjktBnaogbw5Mlgtv277Ufw+YwNu3AlFRjcX9GxZCSWL5DA8nqFYJ4vP69WqMlrWLQlbNWPZTkzw34Z7oeHImcUNw7vURP6c1uOweusRjJi6DkG3Q+Hh7oK+baqgTNGc6rFXr99g+OQAbNlzGtduhiBpkgTw8/FE39ZVkNrFCbZs+tKd+Gv+VtwLCUfOrG4Y0aUmCuTMGGMchk0JMMShf5uqKPNNZBzE2u1HMXvFvzh29jrCwp9ix7weyJ0tHWzdDAtxyP+OOAw3ikM/szgEmMVhu0biMG1JIP70j4xDrqxuGNntxxjrw6othzFs8jpcvx2i4jCgXTWUNYqDTqfD8CnrMHfVbjx8/AyFvT3we8/ayJzeFbZsxhd8fGBLiwZUL+qBIY18MXLpYRTvsRInr4Vgee8KSOmYwGL5mt9mRv/6Phi19DAKd1yKdpN2qnX0redjKFOy1yp4Nvc33KoNWqeWr9pzBbZq7dYjGDJhFTo0LoeA6V2QPUta/NR1Cu6HPbJY/uCJK2g3aB5qfV8Y66Z3RdnvcuGX3jNx7vJtQ5kDKwea3H7rWQdx4sRBRT9v2KqVmw+j37iV6NqsPLbO6aZOUrU6TlSJnCX7j19Gi35zUL9yEWyb0x0VinmjUffpOHPplnr82fOXOH7uBjr/XE6tb/aIprh47R4adJsKW7Zy8yH0HbcS3ZpWUNuVK4sbfuwQcxya952NBpWLYPvcHqhYzBs/dZ9miIN4+uwlfPN4oH/bqtAK8zjkfI84/NJ3tqoP+jg0tBCHwnk80E9DcVix6RD6jF2JHs0qqGRTkpYf2k2wGod9xy6jWZ/ZaFC1CAL9e+J7vzxo0HUqTl+MisO4uVswZXEg/uhVB5tndUWihPHUOp+/eAVbtfILPz4waTETFBSEJk2aIG3atIgXLx4yZMiADh06ICQkBLGldaXcmLv1LBbsOI9zNx6g89R/8PTlazQo6WmxfCHPVNh37i6W/XMJQcGPsf34TSz/9xIKZHExlAkJf457D54ZbuUKpMflOw/x7+moE7qtmb5kB+pUKoJaFQsjW8bUGNblRyRMEA9L1u2zWH7Wsp3wK+SlWkyyZkyFrs0qIle2dJizYpehjKuzo8lt8z8nUSRfFqRPmxK2avLC7WhQtSjqVfKFZ6Y0GN2jlorDgoC9FstPXRyIkr7Z0bZBKWTLlBq9WnwPb890mLEsMg6OSRJi2Z9tUK10fmTJkAoFc2XCiK41cexskGqhslUTF27HT1WLoH5lX3h5pFHfgCUO89fusVh+yuIdKOWbHe1+Kg3PTKnxa8tK8PZ0V601erUrFkK3ZhXUN0mtmPQ2DvUq+8LTKA4LYohDybdxUPXBQhxqaTAOExdsQ8NqRVG/ShFVHyTRSJQgHvzXWInDoh0oVSQ72r+tD71bVUIeL3dMWxpoaGWRfa1rk3LqS4wkQZMGNsSd+w+xLvAYbNXkL/z4wKTFyOXLl1GwYEFcuHABCxcuxMWLFzF58mRs3boVRYoUQWjo5/+A4jrYIa9HSuw4ftOwTKcDAo/fhE82y02U+8/dVc/J/zZJyeCaFGXyuWPz4SCrr1Hru6yYv+08bNXLV69x4vwNfFswm2GZnZ0dvi2QFYdPXbP4nMOnruLbAlHlRbFCnlbLyzeRbXtOo/b3hWHLcTh2LsjkZCJxKObjqVqWLDl48iqK+ZjGoYRvdqvlRfjj56rFySlpQthsHM4Gwa+QaRwkLgdOXLX4HFlufhIu6euFAzHEwdb9lzgctBCHEr5eMdYHLcTh6NkgFDePQyGJg+Xt2n/iCor7eJksk5O3Pm7SFXI3JBzFC0WVcUqSUHU3HThuObax7eVXcHzgmBYjbdq0Ua0rmzZtQsKEkR9G+vTpkS9fPmTOnBm9e/fGpEmTPusH5Jw0ARzs7RD88JnJcrmf1S2ZxedIC0uKpAmwYXBlxEEclZTM3HQaf6w8arH89z4Z4ZQ4nmrJsVVhD5/gzZsIpExuOg4nZYqkuHT9ntUkRB43KZ88KYJDwy2WX75xPxInSoDyxWy3ayj0QWQcXMy2yzV5Uly8etfic6R/3zWFo8kyl+RJcS/EcnOxNH0PmrAaNcrkR9LEtpm0hLyNg/l2uaZIigvXrMfBPG5y31octEAfBxfzz/cD4+Cq+Tg8trhfSFwuxLBfuDhbqg+RxwdJWNQyszKuzlFlbE3oV3B8YEvLW9KK8vfff6N169aGhEUvderUqF+/PhYvXqyaDI29ePEC4eHhJrfY9k2ONOhcIy+6TvsXxXusQIPfNqNs/vTo+kM+i+Wlm2nLkSDcCXuKr9mS9ftRrUx+JIgfF18rGXTXrPcs1Zr3W49asf12iMiGvLKB4wOTlrekS0gSkuzZs1sMlCwPCwtDcLDpjJ3hw4fDycnJcHN3d/+oH1DIo+d4LZmzk2kiJffvPbCcZPSuUxBLdl7AvG3ncPp6GNbtv4rBCw6gU/W8iBPHtKx7yiQo7p0Wc7eegy1L7pQY9vZ20Qbd3g99FO1bpp5825DHTcqHWS6//9gl1WJTp5IvbFmKZJFxMB9Udy/skfoGaImM1ZFZBMaCLZTXH5Ckn1r6sG21lUU4v42D+XbdC30U7VujcRzM4yb3rcVNC/RxMG89DP7AONzTfBySWNwvJC6yvVbjEGKpPkSWT/X2f/My0gJhbZ2xLcVXcHxg0mLGvCXlXXr16oWHDx8abjKQ92N69ToCRy/fh19uN8MySTyK5U6LA+ctd4skjG+PiAjTZW8iIrdL+iGN1SuRDcEPn2PT4euwZfHiOqgpl/8eiurCioiIwL+HL1idyidTPv89bNrltevAeYvlF6/bh9ye6ZAjS1ScbTUOeTzdsfOAaRx2HTiHgrkzWXxOwVwZ1XYbC9x/1qS8/oB0OShYHZBSOCWGzcfBK3oc5L5PbstTXGX5zoOmcdix/xx8rMRNC/5LHApaiEPgfuv1RytxyOvljsAD5yzEwfJ2FcqdyaS82L7vrCFuGdycVeJiXCb88TMcOnUVPt7Wp1HHpnhfwfGBSctbWbJkUSf0M2fOWAyULE+ePDlcXKJm4Ij48ePD0dHR5PaxTQw4gYalPFHHLyuyuSXDH82/ReL4cTF/e2RFm9S2OPoZTWfeePA6fi6bHTWKeqhrsRT3dsOvdQpg46FriHibvAjJX+qXyIZFgecNSY0ta1arOBYF7MWyDftVP3Xv35epqZk/VowcONtp6HyMnBJgKP9zzWII3HcWUxdtx8VrdzFm5kacOBeERjW+M1nvoyfPsW7HMZtvZdFrWbcE/NfsxqJ1+3D+yh10G7UET5+/RN23A4jbDJyHwRPXGMr/UtsP2/aewcT521TcRk1bj6NngtC05neGA1KTXjNw9Mx1NTtC6oL058tNBvbZqtZ1S2De6t1YuG4fzl25g64jJQ4v1KwJ0WrAXAyaEBWHFrWLY+ue05gwfyvOX72DkSoO19Hsx2ImY6dkwLesT0i9kfv68Q22qNXbOOjrgz4Odd/GofWAuRhsFodtb+Nw4QuKQ+t6JdX1VBYG7FXvu/OIxXjy7IWaXSZa9p+LgX+tNpRvUSeyPvzlH1kf5DolEofmP/qpx+V8IPva6JkbsT7wOE5dvIlWA+YhdUonNT3aVrX8wo8PHIj7lrOzM8qUKYOJEyeiU6dOJuNa7ty5g/nz56Nhw4bRWio+h5W7L6trsvxauwBckyXCiashqDl0g2FwbrqUiRFh1EI0evkR1efYu25BpEmRWE1v3njwGgYvPGiy3uK53eDukhT+NjxryFjlUvnUgLs/Zm5Uzb7SKjJ3dAvDoLNbd8NgZ/T5yDeF8f1+wujp6/HbtHXImM4FU4c2UdNCja3deli1sFUplR9aUL1MfhUHOdlEXkQrHRaPaWVosr5xJ8yknhby9sDkQY3URbKGTl4LD3dXzBnVTF2cT9y+9wAbd51Uf5f4aaTJa62a0A7fFMgKW1S9TAHcf/BYnWykyT5XNjcsGdvaEIebUh/sTOMwdXBjDJ0cgCGTAtRFtOaNam6Ig9iw6wTaDZ5vuC/X8RDdm1VAj+YVYatxCIkhDjcsxGHK4MYYNjkAQ9/GYa5ZHDaaxaH52zh0s+E41CgbWR+GTYmMQ+5sblg2vo3RfhFqcnyQ69BMG9JYxWDwRNkvXOA/+hfkyBIVhw4NS+PpsxfoNGyhuricb57MWDa+tU2Pe6v+hR8f4ug+tD/kCx/XUrRoUTV+ZciQIciUKRNOnTqFbt26qQG3e/fuRYoUKWJchwzElbEt8b8fhzhxbXdMwOdwbW7j2H4LNiFRPPvYfgs2wfiE8TXjATeSvVEi9bWTcYtfs/DwcLi5JldDLN7VW8HuISNZs2bFwYMH4eHhgVq1aqlpzr/88gtKlCiBPXv2vDNhISIiok+H3UNm5Aq4s2dHNoUSERGR7WBLCxEREWkCkxYiIiLSBCYtREREpAlMWoiIiEgTmLQQERGRJjBpISIiIk1g0kJERESawKSFiIiINIFJCxEREWkCkxYiIiLSBCYtREREpAlMWoiIiEgTmLQQERGRJjBpISIiIk1g0kJERESawKSFiIiINIFJCxEREWkCkxYiIiLSBCYtREREpAlMWoiIiEgTmLQQERGRJjBpISIiIk1g0kJERESawKSFiIiINIFJCxEREWmCQ2y/gS/V2WkN4OjoiK9ZhqbzY/st2ITrMxvE9luwCQnj8TuSeBOhi+2PgmzMi1cR+Jq9/IDt51GEiIiINIFJCxEREWkCkxYiIiLSBCYtREREpAlMWoiIiEgTmLQQERGRJjBpISIiIk1g0kJERESawKSFiIiINIFJCxEREWkCkxYiIiLSBCYtREREpAlMWoiIiEgTmLQQERGRJjBpISIiIk1g0kJERESawKSFiIiINIFJCxEREWkCkxYiIiLSBCYtREREpAlMWoiIiEgTmLQQERGRJjBpISIiIk1g0kJERESawKSFiIiINIFJCxEREWkCkxYiIiLSBIfYfgP0fmYv34VJC7chOPQRcmROi8GdfkC+HBmsll+77Sh+m74eN+6EIlM6F/zaqjJKFclheLzj0PlYuuGAyXOKF/LC/D9a2vRH0qS0J9p8nwuuTglx6nooes3djyOX71st36JcdjQu7Qk358QIffQCa/dfw5Alh/DiVUS0su0r50Lf2gUwZeNp9PE3jY2tmSX1YYHUh3DkyOKGIe+sD0cwalpUfegt9aFoTotle4xajHmrd2Ng++poXrs4bNm0JYH4038r7oWEI1dWN4zs9iMK5MxotfyqLYcxbPI6XL8dAg93FwxoVw1lv4mKg06nw/Ap6zB31W48fPwMhb098HvP2sic3hW2bMbSnfhrfmQccmZ1w4guNZE/hjis3noEw6cEIOh2qIpDvzZVUcYoDgHbj2L2in9x7Ox1hIU/xfZ5PZA7WzrYOtaHSLNX7MLkt+eL7HK+6Bjz8UE+b/35IqOcL1qani/Ehat3MGzyWuw9egmv30QgW8ZUmDqkCdxSJcfnxJYWDVi99TAG/rUKnX8uj40zuqqTVP3Ok3E/7JHF8gdOXEGbgXNRt5Iv/p7ZFeW+y42mvWbg7OXbJuVKFPbCkdWDDLcJAxrCllUrnBGD6vtg9MpjKNVnLU5dD8OSHqWR0jGBxfI1imRCn9oF8NuKY/im+yp0nLYb1Xwzonet/NHK5vVwRsMS2XDyWihs3eothzHwz5Xo3KQc/p7ZDTmypEW9zpNirA+tB0TWh02zuqH8d7nRRNWHW9HKbgg8hkOnriF1SifYuhWbDqHP2JXo0awCdszroZKWH9pNUAdqS/Ydu4xmfWajQdUiCPTvie/98qBB16k4fTEqDuPmbsGUxYH4o1cdbJ7VFYkSxlPrfP7iFWzVys2H0HfcSnRrWgHb5nRHzixu+LHDRKtx2H/8Mn7pOxv1KxfB9rk9ULGYNxp2n4Yzl6Li8PTZSxTO44F+batCK1gfIq3ZehiD/lqFTo3LY8P0yPNFgy7WzxcH354v6nzvq84vcnxo9qvp+eLqzfuo3mY8MqdPhaXj22Lz7O7o0Kgc4sf7/O0eNpe0NG7cGHHixDHcnJ2dUb58eRw/ftzqc65evRrtOWXLlsWRI0cMZYoXL25SRn9r2TKqZcF4uaOjI3x8fLB69WrEtmmLdqBe5SKo/X1hZMuUGiO6/YiECeJhUcA+i+VnLA1E8cJeaFWvJLJmTI3uzSsiV7Z06tu5sXjxHODq7Gi4JXNMBFvWskIO+G+/gIU7L+L8rYfoOmsPnr14g3p+WSyWL5TVFfsv3MOKPVcQdP8Jdpy8pf7O75HSpFzi+A6Y3Oo7dJ6xBw+fvoStm7pY6kNRdZCR+jCyWy0kjB8PCwP2Wiw/fUmgSlBb1y8VWR9++V59a561zLQ+3A5+gD5jlmNC/5/g4GAPWzdxwTY0rFYU9asUgZdHGpVoJEoQD/5r9lgsP2XRDpQqkh3tfyoNz0yp0btVJeTxcse0pYGGVpbJC7eja5NyqOjnrZKgSQMb4s79h1gXeAy2atLC7fipahHUq+wLT480qmVIjg8L1lqJw+IdKOmbHe1+Kq3qT6+WleDt6Y7pS3caytSqWAjdmlWAn48ntIL1Ier4UNf4fNH1RySQ88U6K+eLZYGqlV1/vujWLPJ8Ia01eqOmrkNJ3xzo07qKeiyjW0qU/TYXUiZPCnztSYuQJOX27dvqtnXrVjg4OKBSpUrvfN6WLVvUc/7++288fvwYFSpUwIMHDwyPN2/e3LBe/W3UqFEm65g1a5ZafvDgQXzzzTeoWbMmTpw4gdjy8tVrHD9/A98VzGZYZmdnh28LZsOhU1ctPufQyasm5YUkMbLc2J4jF+FdqQ++qzsUPUcvQejDJ7BVce3tkCeTMwJPRX0b1OmAnaduoWAWF4vPkYQlT0Zn5HubpGRwSYLSedyw5dhNk3IjGxfG5qM3sfOUaUuULVL14VwQvvMxrQ/yeZt/vnqHTl3BdwVNTz5+Uh+M6k9ERATaD/JXBy458WkhDkfPBqF4IU+TOPgV8lQtS5bsP3EFxX28TJbJyfvAicg4XLsZgrsh4eoArueUJKHqbjpw3HJsbSEOx84Gqe02iYOPxMHyez544mq0ZKSEr5f6xq1VrA9RcTgh54sC0Y8Phz/gfOFXKOp8IceGrXtOq27E+p0nIU/lPqj0yx/YuNN6Q8JXl7TEjx8fqVOnVre8efOiZ8+eCAoKQnBwcIzPkxYWeU7BggUxevRo3L17F/v2RWWXiRIlMqxXf5MWFWPJkiVTy7Nly4bBgwfj9evX2L59O2KLJBJv3kQgZQrTjNYlRVIEh4RbfI40C7uYZcCSEcv4B70ShbNjXJ8GWDyutRrfIP2UP3Wdol7LFqVIGh8O9nYIfvjcZPm9h8/V+BZLpFVl5PIjCOhXHrdm/4SDY37Av2fuYuyaqCRUuotyZ3RW41y0IPRBZH2Qz9+Y1A9r3QHBIY8s1h8Z/6A3wX8r7O3t0PRHP2hByIPHFuPgksLRZLuMyXIXZ+txkIRFLTMr4+psGitbEmKoD47Rt8tof48WB7O4uao4WK4/WsD6YHq+iHZ8SG69Dstxw+L55W39uR/2GE+evcCE+VtRvHB2LPijJcoX80bzPrPUF9/PzeYH4kqLib+/P7JkyaKSkveVMGHkiezly//W3C/JyowZM9Tf8eLFs1ruxYsX6qYXHm6bBzdzVUtHjeuQgVpyK1p7CHYfuRgt69aqotlToWMVb/SYvQ+HLgYjU2pHDG3gg87VvPHHquNImyIRhv5UCD+O2GxxYO7X4vjZIExfGqjGx0jXKBGRXoQ0aQOqO0g/MD9n1nQ4dPIK/Ff/iyL5LHfPf1VJS0BAAJIkSaL+fvLkCdKkSaOWSTPX+5AuIWklkXUUKlTIsHzixImYPn26SdkpU6agfv36hvt169aFvb09nj17pprFMmbMiFq1all9reHDh2PgwIH4VFI4JVbfgO+bfYtWrSnOpt+uTLJks0FXMgjL/NuYsQxuKZEiWWJcvRFsk0mLzPyREesuTqaDbl2dEuDew2cWn9OrZj4s+fcS/HdcUPfP3HiARPEd8HuTIhiz+rjqbpJWmq1DoroepTWniGcqNC3jBbfG/oYd1lbIZyT1wbxVReqH+bcrPWk5sFR/ZByT2Hfskvo25fPDAMPj8m1NBn/LbIz9y/vD1jgnS2IxDvLtUL9d5mS5tDpZi0Oqt/9LGeOByNICYaszZ5wN9SE8+naliCEOZnG7p+Lw+ccnfCysD6bni2jHh7Coem5OjhsWzy9v64+sU46L2TKmNimTJUMqHDj++bsUbbJ7qESJEjh69Ki67d+/H+XKlVPjU65du6b+l2REbjlzmk7ZLFq0qFqePHlyHDt2DIsXL0aqVKkMj0tyol+v/lalShWTdYwZM0Yt37BhA3LkyKGSnBQpUlh9r7169cLDhw8NN+nG+pjixXWAd7Z0+OdQ5IlXSDL1z6HzVqd2FsiVEf8cjCovdh44p5Zbc+veA4Q9fIpUNjpr5NWbCBy7EoJiOaPGW0ijwHc50+DgRcvdhgnjOSAiwjTpePP2fhzEUWNYvuu5GiV6rzXcZPr0st2X1d+2lrAY6oOnO/45eD56fbDy+RbImQm7DkWVN9SHt/Xnh/I+2Dq3OzbP7ma4yUlbxrdIU7Atkjjk9XJH4IFzJnHYeeA8fHJnsvicQrkzmZQX2/edhU/uyDhkcHNWiYtxmfDHz9TYHx9v6/tObMdBBhPLdkePg+X3XDB3Ruw0qj8icP85FLQSNy1gfYiKQ24r54v8MZ0vjMqLXQejzheqjmVPj0vX75mUuRwUDLfUn3e6s822tCROnFh1B+lJ4uDk5IRp06apv6UVRMSNG9fkeZKkSKIh3UgyNsWcrMN4vZbIeBYpIzcZlFuxYkWcPn0arq6uVsffyO1Tal6nODoNXQBvL3fky55efft99uylGh0u2g/2RxoXJ/RqWVndl3EJNdv+qWZClC6aQ02RlS6AUd1rq8efPH2BP2ZtREW/POrb1dWbIRg6cY0aES4DsGzV5A2n8WeLb3H0SggOX7qPFuWzq5aThYGR/ap/tfgWd8KeYsiSw+r+30eC0KpCDpy4FqrKZ0qVFL1q5sWmI0EqIXny/DXO3ogaqC2evniNsMcvoi23Jb/ULq6us5PHKz3y5YisD0+fv0Qdo/ogSYdcm0c0q+WHH9qMV9dtkGuz6OvDbz1qG75Jyc2YzB6Sb+rybcpWta5XEq0HzlP7hByQZRaN9L3Xr+yrHm/Zf67aL/q/nbbbok5xVGoxFn/5b0XZb3OqKbJHz1zH2F/rqsfVbMK6JTB65kY16FCSGLmmi8RSpkfbqlZ1S6DtIH/klTjkyIDJi3bg6fMXaoq7kOnuaVySoW+byC9oLWoXR5WW49QYBblGzYrNh1UcZPaVXtjDJ7hxNwx3gh+q+xev3VX/y7d1fYuUrWF9iDo+dBq2QCWzUiek61edLypGHh86DIk8PhjOFzX9ULPdn5iyaLu6NotcYkOODyO7RR4fRMu6JdG6/xwUzpMZRfNnwY59Z7Fl9yk1/flzs8mkxZwcTKRrSJIVNzc3q+Xc3d2ROXPmj/a60rVUoEABDB06FOPGjUNsqVoqvxqAOXr6BtUMLNdh8P+9haE74NbdMNjZRY1FkG+af/VviFHT1mHk1AB1MbEZw5uqaaHCzj6OuiaDXFxOvkmmSukIPx8vdGteMVbm3b+vVfuuwtkxAXr8kFd168g1VWqP2oLg8MjBuelSJlbTVvVk3Irc/fXHfEidPBFCwp9j05EbGLo0MqnRKhmPJAMP5WJQqj5kTYf5v7c0NOfelPoQx7Q+yDV4Rk5djxFTIuvDTFUf0kLLapQtgPsPHmPYlHVvu3DcsGx8G0MzuFwoyzgOct2RaUMaY+ikAAyeuFYlJv6jf1HXudHr0LA0nj57gU7DFqqLy/nmyYxl41sjQXzTL0i2pHqZAqo+jJgaGYdc2dywZGzrqDiYHR8KeXtgyuDGGDY5QMVC4jB3VHM1rk1v464TaDd4vuF+8z6z1f8yDbpH84qwRawPkaqUkuPDE4yeEXm+kOu0zBsddb4wPz4UtHC+mD4s6nwhKhTzxvCuP+Iv/y3oN24FMqd3wdTBP6u69LnF0Rkf5W3kOi0y60daOURYWBj++usvTJo0Cdu2bVPXW7F0nZZMmTKp67LIbCNL5HkyI2jQoEEmy6WVRLqT9MnRypUrUa1aNcPj0k1UvXp1XLp0KcaEyXggrrToXLkVEm1m0tcmQ9Oog97X7PrMBrH9FmxCwni2f+2Xz0HfRfm1szdKpL520ur7NXsUHo5Mbs5qiMW7zps2OaZl48aNavCt3AoXLowDBw5g6dKlFhOWDyHdS/r16m8y8PZd14yRhEhaW4iIiCj22FxLi9axpSUKW1oisaUlEltaIrGlJRJbWqKwpSVc2y0tREREROaYtBAREZEmMGkhIiIiTWDSQkRERJrApIWIiIg0gUkLERERaQKTFiIiItIEJi1ERESkCUxaiIiISBOYtBAREZEmMGkhIiIiTWDSQkRERJrApIWIiIg0gUkLERERaQKTFiIiItIEJi1ERESkCUxaiIiISBOYtBAREZEmMGkhIiIiTWDSQkRERJrApIWIiIg0gUkLERERaQKTFiIiItIEJi1ERESkCUxaiIiISBMcYvsNfKkSxLVXt6/Zrdk/xfZbsAmupfrG9luwCWGBQ2P7LdgEe7s4sf0WbEJEhC6234LNSBT/6z5XvP6A7WdLCxEREWkCkxYiIiLSBCYtREREpAlMWoiIiEgTmLQQERGRJjBpISIiIk1g0kJERESawKSFiIiINIFJCxEREWkCkxYiIiLSBCYtREREpAlMWoiIiEgTmLQQERGRJjBpISIiIk1g0kJERESawKSFiIiINIFJCxEREWkCkxYiIiLSBCYtREREpAlMWoiIiEgTmLQQERGRJjBpISIiIk1g0kJERESawKSFiIiINIFJCxEREWkCkxYiIiLSBCYtREREpAkOsf0G6P1MX7oTf83finsh4ciZ1Q0jutREgZwZrZZfvfUIhk0JQNDtUHi4u6B/m6oo801Ow+Nrtx/F7BX/4tjZ6wgLf4od83ogd7Z0Nv9xzFi2ExPnb8O90HDkzOKGYZ1rIn/ODFbLr9l6BCOmrkPQnVB4pHNB3zZVULpoVBxGTV+PVZsP49a9B4gb1x7enu74tWWlGGNrC5pVK4x2db6Da4okOHnpDnqMC8DhszcslnWwt0OnBn6oWy4f0qR0xMWg+xgw5W9s3X/BUKZH45Lo+XMpk+edvxaMwg3HwpZNWxKIP/0j94tcWd0wstuPMX52q7YcxrDJ63D9dojaLwa0q4ayRvuFTqfD8CnrMHfVbjx8/AyFvT3we8/ayJzeFbaMcYjE42RUHPT7hZwvRnaN+XyxassRDJ8SgOtvzxcD2kY/X8yS88WZyPNFoH/snS/Y0qIBKzcfQt9xK9GtaQVsm9MdubK44ccOExEc+shi+f3HL6N539loULkIts/tgYrFvPFT92k4c+mWoczTZy/hm8cD/dtWhVbICaf/+JXo2rQ8tszupnbG2p1ijkOL/nNQr3IRbJ3THRWKeaNRj+kmccjs7orhXX7EDv+eWDu5I9KnSYFaHSbifpjlddqC6iVyY0ibihg5ZxuKN5+gkpbloxsjZbLEFsv3aVYGjSsXUomNb6NxmLVmP+YNqY/cWdOYlDtz+S48qw833Cq0mwpbtmLTIfQZuxI9mlVQSbckLT+0m2C1Puw7dhnN+sxGg6pFEOjfE9/75UGDrlNx+mJUfRg3dwumLA7EH73qYPOsrkiUMJ5a5/MXr2CrGIdIPE5GWrE5cr/o3qwCts/trvaLmu2tHyf3vT1f1K9SRO1HFf280aDbNJy20fOFJpKWxo0bo1q1alYfL168OOLEiaNuCRIkQI4cOTBx4kTD47NnzzY8bnyTssavoV8eN25cZMqUCd27d8fz588R2yYu3I6fqhZB/cq+8PJIo775JUwQD/PX7rFYfsriHSjlmx3tfioNz0ypVcuBtCBI9q1Xu2IhdGtWAX4+ntCKyQu3o0GVoqhbyReemdLgt+61kDB+PCwM2Gv122fJwtnRtkEpZMuYGj1bfA9vz3SYsWyXocwP5QrCr5AnMrqlVLEd1KE6Hj15bnIiszWta32DuQEHsWDDYZy7FozOv6/G0+ev0KBiAYvla5XNizH+O7B533lcux2Gmav3Y/Pec2hb61uTcq/fROBe6GPDLfThU9iyiQu2oWG1oupgK5+dJBqJEsSD/xor+8WiHShVJDvav90vereqhDxe7pi2NNDQyiJ1rGuTcurALQf7SQMb4s79h1gXeAy2inF4GwceJ5WJC7ajYbWo88UfPWur/cLq+UL2C1+j/ULOF17umL7E9HwhSVDxQrF/vtBE0vI+mjdvjtu3b+P06dOoVasW2rRpg4ULFxoed3R0VI8b365du2ayjvLly6vlly9fxpgxYzBlyhT0798fsenlq9c4djZInVj17OzsVLJx4MRVi8+R5ebJSElfLxw4cQVapeJwLgjFfEzjIPcPnrS8XQdPXkUxn2wmy4oXzm61vLyGdAs4JkmoWnFsUVwHe+TNlhY7Dl00LJOTbeChi/DJmd7ic+LHdcDzl69Nlj1/8Rq+uU271TzSOeP08h44srALpvb5EelcnWCr5LM6ejbI5CCq9otCsl9Y/nz3n7iC4j5eJstK+mY37EfXbobgbkg4iheKKuOUJKFqVj9w3PK+FtsYh6g48DiJqDj4fOD5opB2zhdfTNKSKFEipE6dGh4eHhgwYACyZs2KNWvWGB6XFhR53PiWKlUqk3XEjx9fLXd3d1ctO6VLl8bmzZsRm0IePMGbNxFwTeFostw1RVI1rsMS6cd0SZHUZJncvxdiu10e7xL6Ng4fsl2RcXB8Z/lN/5xExpJd4e7XRX3rWDquNZyTJYEtcnZKBAcHewSHPTZZLvdlfIsl2w5cUK0zHm7Oaj8oXjAzKhXLgVTOUbE8dOYG2oxYjh+7zUaXP1YjQ5rkWP9ncyRJGA+2KOTBYyv1wVF97lbrg3NSC/UhsrwkLGqZWRlX56gytoZx0MeBx0njOFg67unrtzmp23I+iX5+sc3zxRc7EDdhwoR4+fLlf37+yZMnsXv3bmTIYH2Qp3jx4oW66YWH2+bBjaz7pkBWbJvTA6EPH8N/9R407zMLG6Z3iXZC1Kqe4wMwrlt17J/XUbXKXLkVqrqW6ht1J23Zd97w96nLd3HwzA2cWNwN1Urkhv/6Q7H0zomIvtCWFr03b97A398fx48fR8mSJQ3LHz58iCRJkpjcKlSoYPLcgIAAtVzGuuTOnRv37t1Dt27dYny94cOHw8nJyXCTVpqPyTlZYtjb20VrVZEs2Lz1Rc/V2THaoCu5L98YtSrF2zh8yHZFxiH8neUTJ4yvRswXzJUJY3vXg729PRZY6f+NbSEPn+L16zdwSW7aqiL3ZRyKtec06DMfbuUHwrv2aBT6aSyePHuJq7dCrb5O+OPnuHjjvmqdsUXSEma5PoSrz91qfTBrZYusD5HlU73937yMtMxZW2dsYxz0ceBx0jgOlo57+vptTuq2eatK5PnFNs8Xmkpa5s+fb5J07NoVNaBSBt7KMmlhkfEtnTp1QqtWrQyPJ02aFEePHjW5TZ8+3WT9JUqUUMv37duHRo0a4eeff8YPP/wQ43vq1auXSoj0t6CgoI+6zfHiOqjBgjsPRH0TjoiIUPd9cluewibLdx6MKi927D8Hn9yZoFUqDp7u2HXQNA67Dp5TyYYlBXNlNCkvAveftVresF5dBF68Mh0DYitevX6Do+dvwa9AZsMy6fIplj8zDpy6HuNzX7x8jdv3w9UU6MrFcmLDv2eslk2cMB4ypU2BOzbaRCz1Ia+XOwIPnLOwX1j+fAvlzmRSXmzfd9awH2Vwc1YHduMy4Y+f4dCpq/Dxts0p8IxDVBx4nITVOAQefMf5wqi82LHPds8XmuoeqlKlCgoXLmy47+YWNViyfv366N27t0pa0qRJowYfGZP7WbJkiXH9iRMnNpSZOXMm8uTJgxkzZqBp06ZWnyPjYOT2KbWuWwJtBvkjb/b0yJ8jgxp38fT5C9Sr5KsebzVgLtK4JEO/NlXU/Ra1i6Nyy3GYMH+rmmu/cvNhHD1zHWN61TGsM+zhE9y4G4Y7wQ/V/YvX7hqybmsZeWxrWbcE2g32VzulXJslMg4vUadSZJ1oM3Ae0rg4oU/ryDg0r+WHaq3Hq9kVZYrmxMoth9Qgtd97RsbhybMXGDt7E8p9lwupnJ1U99DMZbtUTKqUzAdbNXHJv5jY6wccOXtTXZulVc2iKsmYvyGyG2fSrzVxOzgcg6ZtUvcLZE+nrs9y4uJtpHVxRI/GpWBnFwfjFkYl/YNalcfG3WcRdPcB0jg7omeTUngTocPyLbY7a6Z1vZJoPXAe8sl+kTMjJi3crj5TmTUhWvaX/cLJME2zRZ3iqNRiLP7y34qy3+ZUU4Vlvxj7a11D8id1bPTMjarlTZIYuaZL6pROanq0rWIc3saBx0mldb0SaDPw7fkiZwZMluPkM6PzhewXrkbnizrFUbnFOHUdMLlm0YpNb88Xv1o/X1zQny9SOCJVys97vtBU0iKtJXKzRLpm3pWUfAhJcn799Vd07twZ9erVU8lQbKlepgDuP3isLpImTdW5srlhydjWhibrm3fD1ElIr5C3B6YOboyhkwMwZFKAOgDPG9Uc2TOnNZTZsOsE2g2eb7gv168QMq2tR/OKsEXVSudHSNhjdUG4yIuJpcOiMa0M3WSW4jB5YCMMn7oOwyavhYe7K+aMbGaIg72dndr5Fq/frxKW5E6J1QlwzaQOaqqgrVq5/YS6JsuvTUqpJlxJRmp2m43gsCfqcZn1ExGhM5SPH88BvZuVQcY0yVW3kEx9bjl0qeoC0nNzccL0frWRwjER7j94gn0nrqFMq8mqa8lW1SgbuV8MmxK5X+TO5oZl49sY9osbd0JhFyeqPhTO44FpQxpj6KQADJ4o9cEF/qN/QY4sUftFh4al1QG+07CF6uJyvnkyY9n41kgQPy5sFeMQicfJSDXKFFDHyeFG5wuZXGDYL8yOk4Xfni+GyfliYuT5wv+35shhdr5oO8jofNE76nzR85fPe76Io5OReTZOrqHy4MEDrFq1yup1WvLmzYuxYy1fvVOu09KhQwecO2faNCxcXV1VgmLpNV6/fo2MGTOiY8eO6Nq163u9VxmIKwnU7eAHapr110y+qRPgWqovwyDf1gKHMg5kYJxYf+2McuuvUnh4OFKnTKaGWLzrvKmpMS3/b1Ck28j8JoNtrXFwcEDbtm0xatQoPHkS+S2WiIiIYocmWlq0hC0tUdjSEoktLZHY0kLG2NIShS0t4WxpISIioi/LV9M9RERERNrGpIWIiIg0gUkLERERaQKTFiIiItIEJi1ERESkCUxaiIiISBOYtBAREZEmMGkhIiIiTWDSQkRERJrApIWIiIg0gUkLERERaQKTFiIiItIEJi1ERESkCUxaiIiISBOYtBAREZEmMGkhIiIiTWDSQkRERJrApIWIiIg0gUkLERERaQKTFiIiItIEJi1ERESkCUxaiIiISBOYtBAREZEmMGkhIiIiTXCI7TfwpYrQ6dTtaxbXgTmxCAscGtsfhU1I3cg/tt+CTTg+vmZsvwWbkCJJvNh+C7bj6z5V4E3E+weAZxUiIiL6clpa1qxZ894rrFKlyv/zfoiIiIj+e9JSrVq19ymGOHHi4M2bN+9VloiIiOijJy0REREftFIiIiKij+3/GtPy/Pnzj/dOiIiIiD5m0iLdP4MHD4abmxuSJEmCy5cvq+V9+/bFjBkzPnR1RERERJ8maRk6dChmz56NUaNGIV68qClruXLlwvTp0z90dURERESfJmmZO3cupk6divr168Pe3t6wPE+ePDh79uyHro6IiIjo0yQtN2/eRJYsWSwO1n316tWHro6IiIjo0yQtOXLkwK5du6ItX7ZsGfLly/ehqyMiIiL6NJfx79evHxo1aqRaXKR1ZcWKFTh37pzqNgoICPjQ1RERERF9mpaWqlWrYu3atdiyZQsSJ06skpgzZ86oZWXKlPnQ1RERERF9uh9M/O6777B58+b/8lQiIiKiz/srzwcPHlQtLPpxLgUKFPivqyIiIiL6+EnLjRs3ULduXfz7779IliyZWvbgwQMULVoUixYtQrp06T50lUREREQff0xLs2bN1NRmaWUJDQ1VN/lbBuXKY0REREQ20dISGBiI3bt3w9PT07BM/v7zzz/VWBciIiIim2hpcXd3t3gROflNorRp036s90VERET0/yUtv/32G9q1a6cG4urJ3x06dMDo0aM/dHVEREREH697KHny5IgTJ47h/pMnT1C4cGE4OEQ+/fXr1+rvJk2aoFq1au/3ykREREQfO2kZO3bsh6yTiIiIKHaSFrlsPxEREZEmLy4nnj9/jpcvX5osc3R0/H/fExEREdH/PxBXxrO0bdsWrq6u6reHZLyL8Y2IiIjIJpKW7t27Y9u2bZg0aRLix4+P6dOnY+DAgWq6s/zSMxEREZFNdA/JrzlLclK8eHH8/PPP6oJyWbJkQYYMGTB//nzUr1//k7xRIiIi+rp9cEuLXLbfw8PDMH5F7otvv/0WO3fu/PjvkIiIiOi/tLRIwnLlyhWkT58eXl5eWLJkCQoVKqRaYPQ/oEgf34xlOzHBfxvuhYYjZxY3DO9SE/lzZrBafvXWIxgxdR2CbofCw90FfdtUQZmiOdVjr16/wfDJAdiy5zSu3QxB0iQJ4Ofjib6tqyC1i5NNf3zTlgTiT/+tuBcSjlxZ3TCy248okDOj1fKrthzGsMnrcP12iIrDgHbVUPabyDgInU6H4VPWYe6q3Xj4+BkKe3vg9561kTm9K2wZ4xDp51LZ0LpCDrg4JcTpoDD09j+AI5dDrMateVkvNCqZDW7OiRD66AUCDl7HsKVH8OJVhHq8Ucms6nH3lInV/XM3H+KP1Sew7fgt2LL5q//FjCU7EBz6CF6Z06Bv2+rw9kpvseyFq3cwfvbfOHXhBm7eDUOvVlXQ+IdiJmUOHL+k1nfywk0Eh4RjwsDGKP1NLtg6Hie//Dh8cEuLdAkdO3ZM/d2zZ09MmDABCRIkQKdOndCtW7dP8R6/eis3H0a/cSvRtVl5bJ3TDTmzuqFWx4nqAGXJ/uOX0aLfHNSvXATb5nRHhWLeaNR9Os5cijzwPnv+EsfP3UDnn8up9c0e0RQXr91Dg25TbTrWKzYdQp+xK9GjWQXsmNdDJS0/tJtgNQ77jl1Gsz6z0aBqEQT698T3fnnQoOtUnL4YdQIaN3cLpiwOxB+96mDzrK5IlDCeWufzF9F/qsJWMA6RqhbKgAF1C+D31cdRtv96nAoKw8KuJZEyaXyLcavumxG9f8yH31cdR7Fea9F55l61jl418xnK3Ap9iqFLjqBs/w0o138D/jl9B7M7+MHTzXaT+fXbj2L45DVo81MZrJzcEV4eadG05zSEhFneL2T/T5cmBbo0qwiXFEktlnn6/CU8PdKif7vq0AoeJ7+OOHxw0iLJSfv27dXfpUuXxtmzZ7FgwQIcOXJEXcr/QzRu3FhdaVd/c3Z2Rvny5XH8+PF3PvfUqVOoVasWXFxc1IDgbNmyoV+/fnj69KlJuYwZMxrWnyhRIuTOnVsNHjYn37inTZuGIkWKqG6vJEmSIGfOnGqbLl68iNg0eeF2NKhaFPUq+cIzUxqM7lELCRPEw4KAvRbLT10ciJK+2dG2QSlky5QavVp8D2/PdJixbJd63DFJQiz7sw2qlc6PLBlSoWCuTBjRtSaOnQ3CjTuR3X22aOKCbWhYrSjqVykCL480KtFIlCAe/NfssVh+yqIdKFUkO9r/VBqemVKjd6tKyOPljmlLAw2fucS2a5NyqOjnrZKgSQMb4s79h1gXGJmY2yLGIVKL8tkxP/AiFu26jPO3HqL77H149vIN6hTLYjFuPlldcODCPazcexVB958g8ORtrNp7Ffk8nA1lNh+9ia3Hb+HK3Ue4fPcRRiw/hifPXyN/5pSwVbOWB6JWxcL4oXwhZMmQGgM7/oAE8eNi+cYDFstLC0yPFpXxfYl8iBfXcmO7X6Hs6NSkAsp8mxtawePk1xGHD05azMkA3Bo1asDb2/s/PV+SlNu3b6vb1q1b1c8BVKpUKcbn7N27V/2MgFwjZt26dTh//jyGDh2K2bNno0yZMtGuHTNo0CC1/pMnT6JBgwZo3rw5NmzYYHhcTl716tVTyVjFihWxadMmnD59GjNmzFCtSEOGDEFsefnqNY6dC1LNcXp2dnYo5uOJgyeuWHzOwZNXUcwnm8myEr7ZrZYX4Y+fq8TOKWlC2CKJw9GzQSheyDQOfoU8ccDKdu0/cQXFfbxMlsnOeeDEVfW3NHXeDQlH8UJRZZySJFTdTQeOR5axNYxDpLj2dvDOmAI7T902xEanA3aduo2CWSwnGAcuBMM7o7MhSUnvkgQl87hh67GbFsvbxYmDqoUzIFF8Bxy6eB+2Wh9Onb+JovmzmewXRfNnxZHT1/C14HHy64nDe41pGT9+/HuvUN8K876klSR16tTqb/lfupxkRlJwcLBqRTEnCUbTpk2RPXt2rFixQn0g+uRJWlvy5cuHMWPGoEePHobnJE2a1PAasnzUqFHYvHkzKlSooJYtXrwYixYtwurVq1GlShXD82Tcjq+vr3rN2BL64AnevImI1ozrmjwpLl69a/E5Mt7DNYXpRf5ckifFvRDLzYPSFTJowmrUKJMfSRPbZtIS8uCxxTi4pHDEhRji4OJsXl7iEK7+loRFLTMr4+ocVcbWMA6RUiSNDwd7OwQ/fG4SH7mfJY3lrhxpYZHnre5dFnEQB3Ed7DBn23mMDzhlUs4rXTKs61sO8ePaq1aWJuMDVUuOLQp7+ARvIiLgnDyJyXLn5ElxOegevhY8Tn49cXivpEWSgPchmdeHJi3GHj9+DH9/fzWFWrqKLDl69KhqBZEuKX3CopcnTx7VZbVw4UKTpEUvIiICK1euRFhYGOLFi2dYLuU9PT1NEhbz7bLmxYsX6qYXHm6bJztrZJBVs96z1LfU33rUiu23Q/TJFPVKhQ6VcqHn3AM4fOk+MqVKisH1C6JTldwYs+aEodyl2+Eo1XcdHBPFQyWf9BjfvCiqD99ss4kLfXo8TtpOHN4raZHZQp9KQECAGj+iv9pumjRp1DLzhERPuoKEtLRYIsv/+ecfk2WSwPTp00clF/KL1ClSpECzZs1M1ilJi7GOHTsaxr7IrKgbN25YfL3hw4eri+t9KimSJYa9fKM0G0R1L+yRahGwxNXZUY0aNxZsoby+Akq/5IoJ7Wy2lUU4J0tiMQ7BoeFqey2R5cFm3xbk+fryqd7+L2VSp4z6di7fMHJnSwdbxDhEkpk/r+UbpVMCk/jI/XsPn1mMXfcaebBs9xUsCIwco3b2xgPV9fNb48IYu/aEOhCLV28icPXeY/X38auhyJvJGc3KeqkxM7YmuVNi2NvZISQs8v3qySDclMm/np9U4XHy64nD/z2m5f9VokQJ1Xoit/3796NcuXKq2+batWvqf0lo9INijX1Il43MapL1y5V8ZSyMtBxJa05MevfurZ4jg3ulBciaXr164eHDh4ZbUFAQPiYZKJfH0x07D0Qma/oWo10HzqFg7kwWn1MwV0bsMiovAvefNSmvr4CXg4LVIKsUTpFTPG2VxCGvlzsCD5wziYPExcdKHArlzmRSXmzfdxY+uSOnSGdwc1aJi3GZ8MfPcOjUVfh4W59GHZsYh6jEQhKK73JEdvsKaRD9NkdqHLQy/iRhfHtEmB033kRE3pfuImtkbEt8h1g/VFqtDzmzuWHP4Qsm+8WeIxeRL4f1Ka5fGh4nv544/F8/mPgxyO8XGScQ0rrh5OSkZvLI38+eRX5rihs3rvpfxq2IM2fOqPEr5mS5voxeypQp1WvIbenSpWoGUcGCBZEjRw71eNasWXHunOnJTcbTyE1+Y+ldY3Lk9im1rFsC7Qb7I292d+TPkQFTFu9QUxLrfl9YPd5m4Dw1X17mzYtfavuhaqvxmDh/G8p8kxMrNx/C0TNB+L1nHUMFbNJrhprGNv/3FurArR/fkdwxkdUZBbGtdb2SaD1wHvJlT4/8OTNi0sLtePLsBepX9lWPt+w/F2lcnNC/bVV1v0Wd4qjUYiz+8t+Kst/mVFOFj565jrG/1jV0+0lsR8/cqK5NIEmMXNNFWl1kerStYhwiTdl4BuOaF8WxK6E4cvk+mpfLrlpOFu26pB7/85eiuB32FMOWHlX3Nx+5iRblvXDiWiiOXLqPjKmSokeNPNh89IYhmfn1x7zqmiw3Q54gcYK4qFEko+pWqjN6K2zVzz/4oceoRcjlmQ7enukxZ8UuNU21Rnkf9Xj3EQuRKqWTmuKsH6x56Vrk+IaXr9/g7v2HOHPxJhIljI8MbpGDmGW/un4zKvm7cTtUlXFKmghpU9nmb8zxOPl1xMHmzk5yIpGuIUlW3Nzcoj2eN29edVE7aS2pU6eOSTeSXD9my5YtqsvGGnd3d9SuXVu1kMjAW1G3bl01e0juV60aecKzJdXL5FcDMEdOW//2omrpsHhMK0M3x407YSbjbgp5e2DyoEbqomlDJ6+Fh7sr5oxqhuyZ06rHb997gI27Tqq/S/w00uS1Vk1oh28KZIUtqlG2AO4/eIxhU9a97cJxw7LxbYziEKq+FesVzuOBaUMaY+ikAAyeKHFwgf/oX5AjS2QcRIeGpfH02Qt0GrZQXVzON09mLBvfWk0ZtVWMQ6TV+6/B2TE+utfwVheXO3U9DHVHb8P98MjBuW4pEiPibUuKkHErOujQ84e8SJ08IUIevcDmIzcwfHlkUiNSJk2AP5sXhWuyhHj07JW6YJ0kLDtP3YGtqlgiL0IfPlYXjJNmfdnPpw9vhpTJI5v3b98Lg51d1H4hx5BqLaPGKc5cGqhuctyY90drtezkuSA07DrZUEauAyOqly2IEd0jT2a2hsfJryMOcXSxODVGrtNy9+5dzJo1S92XAbJ//fWX+jFG6cqR3zeyZPfu3Wpqc9myZVXyITOD9u3bhy5duqikRJ6rb/2Q67TI+BS56clA3ly5cqnuKGlxkRDINV9kLI2sT7qoUqVKpbqoRowYocqFhFi/yqYxGYgrLUU374Wp6718zWR2B5Fe6kb+DIaMkxlfk3GQ8RdJoiZD0NctPDwcbq7J1RCLd503Y/2ssnHjRjX4Vm4y3uTAgQOqC8dawiKKFi2qrtVib2+vxr1It48kG40aNVJTmd/VXSPdQpLwyHgVIVmnTHseO3Ys1q9fj1KlSqmBuU2aNFFJkPnAXiIiIvr8/lNLy65duzBlyhRcunQJy5YtU9048+bNQ6ZMmdQPJ37N2NIShS0tZIwtLZHY0hKJLS30WVpali9frrpPEiZMqC7dr79GibzYsGHDPnR1RERERO/lg5MWuaT95MmT1ewe/Ywe8c033+Dw4cMfujoiIiKiT5O0yNTgYsVMf8ZcyODTBw8efOjqiIiIiD5N0iIzdSz96rEMVvXw8PjQ1RERERF9mqRFfiG5Q4cOaoqxzLq5desW5s+fj65du6JVq1YfujoiIiKiT3NxOfkVZrkssEwLfvr0qeoqkinGkrS0a9fuQ1dHRERE9GmSFmldkd/lkd/zkW4i+V0eue6J/kcPiYiIiGzqMv7x4sUz/HYPERERkc0lLfKrzMa/W2BOLqFPREREFOtJi/xgobFXr17h6NGjOHnypLqMPhEREZFNJC3y68qWDBgwQI1vISIiIvoUPtoPJjZo0AAzZ878WKsjIiIi+jRJy549e5AgQYKPtToiIiKi/697qEaNGib35Ueib9++jYMHD6Jv374fujoiIiKiT5O0yG8MGbOzs4OnpycGDRqEsmXLfujqiIiIiD5+0vLmzRv8/PPPyJ07N5InT/4hTyUiIiL6fGNa7O3tVWsKf82ZiIiIbH4gbq5cuXD58uVP826IiIiIPlbSMmTIEPXjiAEBAWoAbnh4uMmNiIiIKFbHtMhA2y5duqBixYrqfpUqVUwu5y+ziOS+jHshIiIiirWkZeDAgWjZsiW2b9/+0d8EERER0UdLWqQlRfj5+b3vU4iIiIhiZ0xLTL/uTERERGQz12nJli3bOxOX0NDQ//c9EREREf1/SYuMazG/Ii4RERHR5xBHpx+s8g5yuf47d+7A1dX1078rDZNp35LY3Q15CEdHR3zN3rNqffHYrRrpxSvOLBSpq4+P1fpoK26vbB/bb8Fm2H/lQy/Cw8ORLlVyPHz47vPme49p4YGXiIiIYtN7Jy381kxERESaGNMSERHxad8JERER0ce8jD8RERFRbGDSQkRERJrApIWIiIg0gUkLERERaQKTFiIiItIEJi1ERESkCUxaiIiISBOYtBAREZEmMGkhIiIiTWDSQkRERJrApIWIiIg0gUkLERERaQKTFiIiItIEJi1ERESkCUxaiIiISBOYtBAREZEmMGkhIiIiTWDSQkRERJrApIWIiIg0gUkLERERaQKTFiIiItIEJi1ERESkCUxaiIiISBOYtBAREZEmOMT2G6D3M21JIP7034p7IeHIldUNI7v9iAI5M1otv2rLYQybvA7Xb4fAw90FA9pVQ9lvchoe1+l0GD5lHeau2o2Hj5+hsLcHfu9ZG5nTu9r0RzJ96U5DHHJKHLrWfEccjmD4lABcvx0aGYe2VVHGKA5rtx/FrBX/4tiZ6wgLf4pA/x7InS0dbB3rQ6SZy3dh4vxtCA4NR44sbhja+Qfkz5HBatzWbDuCUVPXI+hOKDKlc0Gf1pVRumhUffht+gas3nIYN+89QLy49vD2dEevFt8jfwx1zBY0+z4P2tUoANfkiXHySjB6TNmOw+fvWizrYG+HTj/6oG6pHEjjnAQXb4ZhwKxd2Hr42n9ep62YZaE+5IuhPqzddgQjp67HDaP6UMqoPhjrPmox5q3ajYEdquOX2sVhy2Ys26nicC80HDmzuGFY55rInzOG/WLrEYyYuk7tFx7pXNC3TRXDfvHq9Rt1DN26+zSu3QpB0iQJUKygJ/q2roLULk743NjSogErNh1Cn7Er0aNZBeyY10MlLT+0m4Dg0EcWy+87dhnN+sxGg6pFEOjfE9/75UGDrlNx+uItQ5lxc7dgyuJA/NGrDjbP6opECeOpdT5/8Qq2asXmyDh0b1YB2+d2V3Go2X6i9Tgcv4zmfWejfpUiKm4V/bzRoNs0nL4UFYenz17CN48H+retCq1gfYhKzAeMX4kuTcph06xuyJklLep2mmS1Phw4cQWt+s9F3cq+2Dy7GyoUy42fe87AGaP6kDm9C4Z1qanqy+pJHeCeJgVqd5yE+2GPYauqf5cNQ5oVw8iFe1G8w3ycvHIfywfVQEqnhBbL9/mpKBpX8FZJiG+ruZi1/jjm9a6C3B4u/3mdtmC1UX34e1Y35HhbH+6/oz7Uq+yLTbO7ofzb+nDWqD7orQ88hsOnriF1ys9/kv4v+0X/8SvRtWl5bJndTX25q93J+nFy//HLaNF/DupVLoKtc7qjQjFvNOox3bBfPHv+EsfP3UDnn8up9c0a3hSXrt/DT92nIjbYZNLSuHFjVKtWLcYyz549Q//+/ZEtWzbEjx8fKVOmxI8//ohTp06ZlBswYADixImjbvb29nB3d8cvv/yC0NDQaOs8cuQIateujTRp0qh1ZsiQAZUqVcLatWtVy0RsmbhgGxpWK6pOvl4eaVSikShBPPiv2WOx/JRFO1CqSHa0/6k0PDOlRu9WlZDHyx3Tlgaqx2VbJi/cjq5NyqkTuZz8Jw1siDv3H2Jd4DHYqokLtqNhtSKoX9k3Mg49a6s4zF8bQxx8jeLQshK8vdwxfclOQ5naFQupJKh4IU9oBetD1Odbv0pR1K3kqz7fUd1rIWH8eFgUsNdq61SJwl5oU78UsmVMjR6/fI/cnunUt3O9GmULopiPJzK4pVR1bGD76nj05DnOXLoJW9W6Wn7M/fskFmw5jXNBoeg8YQuevniNBmVyWSxfq0R2jFmyH5sPXsW1uw8xc8NxbD54BW2rF/jP67Sl+lDHrD4stFIfpr+tD63N6oO03hm7HfwAff5Yjgn9f4KDgz1s3eSF29HAsF+kwW/viIPsFyULZ0fbBpFx6Nnie3h7psOMZZFxcEySEMvGt0HV0vmRJUMqFMyVCcO71MSxs0Gqhepzs8mk5V1evHiB0qVLY+bMmRgyZAjOnz+P9evX4/Xr1yhcuDD27jX9cHLmzInbt2/j+vXrmDVrFjZu3IhWrVqZlFm9ejV8fX3x+PFjzJkzB2fOnFHlqlevjj59+uDhw4eIDS9fvcbRs0EmJ1U7Ozv4FfJU3xQs2X/iCor7eJksK+mbHQdOXFV/X7sZgrsh4SheKKqMU5KEqpvlwPHIMrZG4iA7iZ+PWRx8JA6W37MslzgZK+nrZTVuWsD6EBWH4+eCUKxgNpP68J1PNhw8abk+HDp5RSUkxooX9rJaXl5j3urd6qAtXQ22KK6DHfJmSYUdR68blsn3q8Cj1+Hjlcbic+LHtcfzl69Nlsl93xxp//M6baU+fGehPhyy8vkePHkF31moD8blIyIi0G6gP1rVKwlPD9vc9mjHSdkvzI6Tcl+21xKp/8V8ouImihfObrW8CH/8XDUEOCX9/C1vmhzTMnbsWOzZs0e1jOTJk0ctk1aR5cuXq6SladOmOHnypAqqcHBwQOrUqdXfbm5uqkVGkhe9J0+eqOd8//33WLFihclrZc+eXT0WWy0tIQ8e482bCLikSGqy3CWFIy5ctdy/LOM9XJzNyydVy4UkLGqZWRlX56gytibkwZO3cXCMtl3nr1mPg6tZ3OT+PSvNpFrA+hAp1FAfotfzi9fuWYzdvZBHcEluVj559Dq/6d+TaNlvDp49f4VUzo5YPLYVnJMlgS1ydkyoxqgEP3hqslzuZ02X3OJzth2+htbVCmD3qZu4cvsB/PKkR6UiWWBvH+c/r1OL9SH4PerDX/5bYW9vh2a1/KAFoTHGIYbzhYXjquwvlsgQgsETV6N6mfxImvjzJy2abGlZsGABypQpY0hYjDPKTp064fTp0zh2zHI3x9WrV/H3338jXrx4hmWbNm1CSEgIunfvbvU19QmQpVaf8PBwkxsRadc3+bOqvv2AKR1RwtcLv/SdbXU8gBb1nLoDl2+FYf+kRri3qgNGtSyBBVtOISIitt+ZbZGWXelCGtenvtXj/9fm1es3aN5nlmp5k26n2KDJpEW6g6QFxBL9cimjd+LECSRJkgQJEyZEpkyZ1LiXHj16mKxPeHpGNakdOHBAPUd/CwgIsPh6w4cPh5OTk+EmY2Y+JvmGJ5m++UFTRse7Optmx3qyXL5FmJZ/ZCgv3x7VMrMykllbW2dsc06W+G0cwqNtl357zMm2mLeqyH3z1hctYX2IlMJQHyzUcyufr7QkBoeZlQ+LXucTJ4yvZpIUyJURY36tp1odrI0HiG0h4c/wWr5ZJ0tkslzu3wt7avU5DYauhVvNv+DdZDoKtZyDJ89f4eqdh/95nVqsDy7vqA/7jl1SA7AL1hiAdN91UjcZwzHwz1XwqTEQmouDs7X9wtHicdW8vCQszXrPUjOMlo5vEyutLDaftMyfP98kcdi1K2qA1Id010gycvToUZWISLJSrlw5tGvXLsbneHt7q+fITbqPZLyMJb169VLjXfS3oKAgfEzx4jogr5c7Ag+cM+ln3XngPHxyZ7L4nEK5M5mUF9v3nYVP7shpmxncnNWJ3rhM+ONnOHTqKny8bXNqp8RBBhPLdhvHIfCgxMHye5blxuXFjn3nrMZNC1gfouIg05F3HTKtD/8cPI+CuSzXhwK5MmHXQdP6sHP/Oavlo9arwwuzMSC24tXrCBy9eBd+eaK+LEmjQLE87jhw9naMz33x6g1uhzxRSVnlolmxYd+l/3udsV0f/rFQHyT5tEQGlMrj5vVBX75meR9sm9tdzZjR32T2UOt6JbFwTEvY7HHS092knkscdh2Uem75uCf133y/CNx/1qS8PmG5ciNYDcpN4ZQYscWmk5YqVaoYEge5FSxYUC2XGUMyUNYS/XIpoyddQVmyZEGuXLkwYsQINYto4MCoTDlr1qzq/3Pnok7iMntIniO3mEg5R0dHk9vHJjuJXE9Fvu2du3IHnUcsxpNnL9QsGtGy/1wM/Gu1oXyLOsWxdc9p1R97/uodNf/+6JnraP5jZL+sNHW2rFsCo2duxPrA4zh18SZaDZindkiZHm2rWtcrgbmrJQ77VBy6jFyCp89eoF6lyDjI9MVBE9ZEj8N8fRzWqzg0q1XMUCbs4ROcOH9DrU9cuHZX3b9733a7+Vgfoj7f+Wv2YPH6/erz7fHbUjx9/hJ1KhVWj7cd5I+hk9Ya4ta8lh+27z2DSQu2qfFgck0W6QL4+Yfv1OOyTw2bvFYNxAy6Haoe6zh0gZpVV7lkXtiqiasOo2G53KhTMgeypUuBP1qXQuIEcTF/S+RMykmdy6Ffo28M5QtkS63GsGRI5YQiOd2wbFB12NnFwbjlB997nbZcH5ZYqQ/tzOpDs7f1YfLb+jD6bX1o8rY+yInZK3Nak5vMHnJxdlSzaGxVy7ol4L9mNxat26fi0G3UEpM4tBk4D0MmrjHZL7btPaNmJUocRk1fr+LQtOZ3hoSl6a8zcOzsdUwc0BBvInRqXKTcZODv52bTA3GTJk2qbubq1KmD3r17q3ErxuNaJKMcM2YMcuTIEW28izGZDVSyZEk1gyht2rQoW7YsUqRIgZEjR2LlypWwNTXKFsD9B48xbMo61YWTO5ubynb1zZjSZGln1OdaOI8Hpg1pjKGTAjB44lp1UTX/0b+o6xbodWhYWp3wOw1bqC4u55snM5aNb40E8ePCVtUoUwAhYY8xfGpkHHJlc8PSca2j4nA3TB189eSCeVMHN8awyQEYMjEgMg6/NUeOzFFx2LDrBNoOmm+436z3bPW/TIPu+UtF2CLWh0jVSudXA5NHTVuvmrdzZk2HhX+0NAwqvGlWH6SFbeLAhupiYnKxLOkCmjWiKbK/rQ/2dnZq0OaS9TMR+vAxkjslRl6v9Fg1sb2a/myrVu46r66f8muDInBNnggnLgejZr+VhoG06VySqtYivfjx7NH7p6LImNoJT569wuZDV9Dy940If/Livddpi6paqA8L/kN9kOREy6pJHMIeq+Qj8mKk6bBoTCu4WolDIW8PTB7YSB1XJWn3cHfFnJHNDPuFTPneuOuk+rtkw5Emr7VyQjs1BuxziqOLzQuQxHCdlgcPHmDVqlUWH3/+/DmKFy+OW7du4ffff1czhu7evYthw4Zh8+bN2LJli5q+rL9Oi6xHWmqMyXN8fHzw119/qfuSrMg1WmSAb/v27VXri0x/lmnP0qW0Zs0aVK5c+Z3vXQbiytiWuyEPP0mri5bYYNWKFRzEF9UdQUDq6uMZBjkZrmzPOLxl/5UP9A0PD0e6VMnVEIt3nTdtunvImgQJEmDbtm1o2LAhfv31V9WFU758edXtI9do0ScsMZFZRtOnTzeMQZHrsezevRuJEiVS65VxMNIaI6+zaNEidZE5IiIiij022dKiZWxpicKqFYktLZHY0hKJLS2R2NIShS0t4V92SwsRERF9fZi0EBERkSYwaSEiIiJNYNJCREREmsCkhYiIiDSBSQsRERFpApMWIiIi0gQmLURERKQJTFqIiIhIE5i0EBERkSYwaSEiIiJNYNJCREREmsCkhYiIiDSBSQsRERFpApMWIiIi0gQmLURERKQJTFqIiIhIE5i0EBERkSYwaSEiIiJNYNJCREREmsCkhYiIiDSBSQsRERFpApMWIiIi0gQmLURERKQJTFqIiIhIE5i0EBERkSY4xPYboC9XnDhxYvstkA2J58DvSCJ4dYfY/ihsgkuxHrH9FmxG6D+j8DVzsH//cwWPIkRERKQJTFqIiIhIE5i0EBERkSYwaSEiIiJNYNJCREREmsCkhYiIiDSBSQsRERFpApMWIiIi0gQmLURERKQJTFqIiIhIE5i0EBERkSYwaSEiIiJNYNJCREREmsCkhYiIiDSBSQsRERFpApMWIiIi0gQmLURERKQJTFqIiIhIE5i0EBERkSYwaSEiIiJNYNJCREREmsCkhYiIiDSBSQsRERFpApMWIiIi0gQmLURERKQJTFqIiIhIExxi+w3Q+5m2JBB/+m/FvZBw5MrqhpHdfkSBnBmtll+15TCGTV6H67dD4OHuggHtqqHsNzkNj+t0Ogyfsg5zV+3Gw8fPUNjbA7/3rI3M6V1t+iNhHBgHY9OX7jTsFzllv+ha8x37xREMnxKA67dDI/eLtlVRxmi/WLv9KGat+BfHzlxHWPhTBPr3QO5s6WDrZizbiQn+23AvNBw5s7hheJeayJ8zg9Xyq7cewYip6xD0Ng5921RBmaKRcXj1+g2GTw7Alj2nce1mCJImSQA/H0/0bV0FqV2cYMua1SiKdvX84JoiKU5evI0eY1bh8Jkgi2Ud7O3QqWFJ1K1QEGlSOuLi9WAMmLQeW/edMyknjw1o/T1K+3oiYYJ4uHLjPtoMW4KjZ2/AVk3/gvcLtrRowIpNh9Bn7Er0aFYBO+b1UEnLD+0mIDj0kcXy+45dRrM+s9GgahEE+vfE93550KDrVJy+eMtQZtzcLZiyOBB/9KqDzbO6IlHCeGqdz1+8gq1iHBgHk/qwOXK/6N6sArbP7a72i5rtJ1rfL45fRvO+s1G/ShG1H1X080aDbtNw+lLUfvH02Uv45vFA/7ZVoRUrNx9Gv3Er0bVZeWyd002dpGp1tB6H/ccvo0W/OahfuQi2zemOCsW80aj7dJx5G4dnz1/i+Lkb6PxzObW+2SOa4uK1e2jQbSpsWfVSeTCkXWWMnLkZxZuMxcmLt7D8j2ZImSyxxfJ9fimPxlV9VWLj22A0Zq3ai3nDGyF31rSGMk5JE2Lj5DYqkfuxywz41v8Nff4KwINHz2CrVnzh+4VNJS2NGzdGnDhxDDdnZ2eUL18ex48ft/qcq1evqrJHjx61Wmb37t2oWLEikidPjgQJEiB37tz4448/8ObNm2hlt2/frsrKaydKlAg5cuRAly5dcPPmTcSWiQu2oWG1oqpSeXmkUYlGogTx4L9mj8XyUxbtQKki2dH+p9LwzJQavVtVQh4vd0xbGmhoZZm8cDu6NimnKqhU6kkDG+LO/YdYF3gMtopxYBxM68N2NKxWBPUr+0buFz1rq/1i/toY9gtfo/2iZSV4e7lj+pKdhjK1KxZSB/vihTyhFbIvN6haFPUq+cIzUxqM7lFLtQgsCNhrsfzUxYEo6ZsdbRuUQrZMqdGrxffw9kyHGct2qccdkyTEsj/boFrp/MiSIRUK5sqEEV1r4tjZINy4Ewpb1bp2Mcxduw8L1h/Euav30Pm3FXj64hUaVCpksXyt8vkxZu42bN5zFtduhWLmqj3q77Z1/QxlOtYvjpv3HqDtsCWqxeb67TBs338eV2+GwFZN/ML3C5tKWoQkKbdv31a3rVu3wsHBAZUqVfrP61u5ciX8/PyQLl06lZCcPXsWHTp0wJAhQ1CnTh11AtebMmUKSpcujdSpU2P58uU4ffo0Jk+ejIcPH+L3339HbHj56jWOng0yqSx2dnbwK+SJAyeuWHzO/hNXUNzHy2SZHKQOnLiq/pYm37sh4SheKKqMU5KEqvnwwPHIMraGcWAczOuDnESl28Jkv/CR/cJyHZblst8YK+nrZXU/0gIVh3PR41DMxxMHrWzXwZNXUcwnm8myEr7ZrZYX4Y+fqy+H0vJgi+I62COvpxt2HLhgWCbH9sCDF+CTy3I3Wfy4Dnj+0rRlWVqafb2julHKf5sTR87ewKzBDXA+oD8CZ3VEw8qWkyBb8PIr2C9sbkxL/PjxVdIg5P+ePXviu+++Q3BwMFxcXD5oXU+ePEHz5s1RpUoVTJ0a1bTZrFkzpEqVSi1fsmQJateujRs3bqB9+/bqNmbMGEPZjBkzolixYnjw4AFiQ8iDx3jzJgIuKZKaLHdJ4YgLV+9afI70Y7o4m5dPqpYLSVjUMrMyrs5RZWwN48A4mNaHJ2/3C8do9fz8Nev7hYx1MCb371lpNteCUEMczLYreVJcjOH44Goet+Sy71uOg5zIB01YjRpl8iNpYttMWpyTJYaDgz2CQx+bLJf7Wa2M09u27zxa1ymG3Uev4MrNEPgVzIJKfrlgbxf1XT5j2hRoUq0IJi7eiT/mbkP+7O4Y0akaXr5+g0UbDsHWhHwF+4XNtbQYe/z4Mfz9/ZElSxbVXfOhNm3ahJCQEHTt2jXaY5UrV0a2bNmwcOFCdX/p0qV4+fIlunfvbnFdyZIls7j8xYsXCA8PN7kREX0JZCxHs96zIA3Sv/WohS9Jz3GrcTnoPvYv6IZ7O4ZjVOdqWLDuICKMWt/t7OLg+PmbGDxlI05cuIU5a/Zh7pp9+LlakVh9718zm0taAgICkCRJEnVLmjQp1qxZg8WLF6smrg91/vx59X/27NktPu7l5WUoc+HCBTg6OiJNmjQf9BrDhw+Hk5OT4ebu7o6PyTlZEtjb20UbRBUcGg5XZ9NsWk+WB5t9a5Ln68unevu/eRn5pmVtnbGNcWAcTOtD4rf7RXi0eq6v3+akbpt/e5T75t8ytSSFIQ5m2xUm+3LSGOJgFjcL5fUJi4xjkTEuttrKom9heP36DVxSJDFZLvettRjIcxr0mgO30r3h/cMwFKr7G548e4Grt6LGq9wNeYSzZi1W56/eQ7pUlr/Exjbnr2C/sLmkpUSJEmpQrdz279+PcuXKoUKFCrh27Zr6X5/Q5MwZNR3rXYzHrcRURvpsP1SvXr3UmBf9LSjI8vS6/ypeXAfk9XJH4IGoaXgRERHYeeA8fHJnsvicQrkzmZQX2/edhU/uyL7aDG7OqgIblwl//AyHTl2Fj1F/ri1hHBgH8/ogg8tlPzDeLwIPyn5huQ7LcuPyYse+c1b3Iy1QcfCMHoddB86hoJXtKpgrI3aZxSFw/1mT8vqE5XJQsEpYUjhZnoFjK+T9Hj13U3Xx6MnxvFiBLDhw8lqMz33x8jVu3w9XU6ArF8+NDbtOGR7bd/wqsqY3HZaQOX1K3LgTBlsU7yvYL2xuTEvixIlVd5De9OnTVQvGtGnT1N/PnkVONYsbN+471yXdP+LMmTMoWrRotMdlucwO0peVpEMGAH9Ia4uMwZHbp9S6Xkm0HjgP+bKnR/6cGTFp4Xb1jUBGh4uW/ecijYuTYTpaizrFUanFWPzlvxVlv82ppgofPXMdY3+ta9iZW9YtgdEzN6o5+ZLEyDVdUqd0UtOjbRXjwDiY1ocSaDPQH3nVfpEBkxftwNNnL9QsGtFK9gvXZOjXpophv6jcYhz+mr9VXbNoxabDar8Y82sdwzrDHj7BjbthuBP8UN2/8HYcgIwBSZXSNlshZV9uN1ji4I78OTJgyuIdePr8Jep+X1g93mbgPHV9FbnOivilth+qthqPifO3qWtxrNwsx4cg/N6zjiEBaNJrhpr2PP/3FngToTOMg0vumEidGG2RjDuZ2Lu2Gjh7+HQQWtX6Doll1sy6A+rxSX3q4Pb9hxg0eYO6XyCHuzpuSrdPWhcn9GhSBnZx4mDc/B0m6/x7Slt0blgSK7ceU89pVMUXnUYtg61q/YXvF7ZZ+4zICVa6hiRZcXNz+6Dnli1bFilSpFAzf8yTFul2ki6hwYMHq/s1a9ZUg35HjRplMhBXTwbiWhvX8qnVKFsA9x88xrAp61QXTu5sblg2vo2hK0eab2Vn0yucxwPThjTG0EkBGDxxrUpM/Ef/ghxZoq4/0KFhaVWROw1bqC4u55snM5aNb40E8d+dDMYWxoFxMKkPZQogJOwxhk+N3C9yZXPD0nGto/aLu2FqTIKeXEBx6uDGGDY5AEMmBkTuF781R47MUfvFhl0n0HbQfMP9Zr1nq/9lumfPXyrCFlUvk18NVB85bf3bi0+mw+IxrYyOD2EmrciFvD0weVAjdXHJoZPl+OCKOaOaIfvbONy+9wAbd51Uf5f4aaTJa62a0A7fFMgKWyRJhVyT5ddm5VTXhiQjNbtMR3BY5OBc6dIxHq8SP15c9G5eXg22ffLspZru3HLwIjVTSk8SoJ96zUG/lhXQrXFpXLsdil/HrcbSTUdgq2p84ftFHN379J18xuu03L17F7NmzVL3w8LC8Ndff2HSpEnYtm0bihcvbvE6LZkyZcKiRYvg6Wk6bUu6kFavXq2mNjdp0gRt27ZV41ZkKnW3bt1QqlQpNXtIv0NPnDhRlfn555/RsGFDNXNIZhXNnTtXdUm9z7RnGYgrLUN3Qx6q1yKiSDZ0qIlV0nJBgEuxHgzDW6H/jPqqYxEeHo7UKZOp3o53nTdtrqVl48aNhu4ZGYgrg2VlZo+lhMWYJCbmZHyJtKDI9VmGDh2qpk4/f/4cWbNmRe/evdGxY0eTbyCtW7dW3USjR49G9erVVeuOJC5ynZjOnTt/gq0lIiIiTba0fAnY0kJkGQ81kdjSEoktLVHY0hL+3i0tNjd7iIiIiMgSJi1ERESkCUxaiIiISBOYtBAREZEmMGkhIiIiTWDSQkRERJrApIWIiIg0gUkLERERaQKTFiIiItIEJi1ERESkCUxaiIiISBOYtBAREZEmMGkhIiIiTWDSQkRERJrApIWIiIg0gUkLERERaQKTFiIiItIEJi1ERESkCUxaiIiISBOYtBAREZEmMGkhIiIiTWDSQkRERJrApIWIiIg0gUkLERERaQKTFiIiItIEJi1ERESkCQ6x/Qboy6XT6WL7LdiEOHHixPZbsAmMQyQHe9YHEfbvb7FaH21Jcp+2+Jrp3rx877JsaSEiIiJNYNJCREREmsCkhYiIiDSBSQsRERFpApMWIiIi0gQmLURERKQJTFqIiIhIE5i0EBERkSYwaSEiIiJNYNJCREREmsCkhYiIiDSBSQsRERFpApMWIiIi0gQmLURERKQJTFqIiIhIE5i0EBERkSYwaSEiIiJNYNJCREREmsCkhYiIiDSBSQsRERFpApMWIiIi0gQmLURERKQJTFqIiIhIE5i0EBERkSYwaSEiIiJNYNJCREREmsCkRSOmLQmEd5V+SP1NR5Ru/BsOnboaY/lVWw6jUM3BqnzROkOx6d9TJo/rdDoMmxwAr/K/Is23nVCt9Z+4dP0ebN30pTuRp2p/9Z5L/zz6PeJwBIV/HKzKf1N3GDZbisOUdcheoTfSftcZ1dtoIw6sD4wD6wP3C2ua/VgMx1YPxO1/xmDzrK7InyOD1bIO9nbo1qw8Dq/sr8rvmt8TpYpkNymTJFF8DOv8A46vGYRbu/7A3zM6I1+O9IgNTFo0YMWmQ+gzdiV6NKuAHfN6IFdWN/zQbgKCQx9ZLL/v2GU06zMbDaoWQaB/T3zvlwcNuk7F6Yu3DGXGzd2CKYsD8UevOqpSJ0oYT63z+YtXsFUrNkfGoXuzCtg+t7uKQ832E63H4fhlNO87G/WrFFFxq+jnjQbdpuH0pag4jJ+7BVMXB+L3nrWxeWYXJEoYX63TpuPA+sA4sD5wv7Ciepn8GNKxOkZO34DiP43EyQs3sfzPNkiZPInF8n1aVUbj6t+ix29L4Vt7CGat+AfzRjVH7mzpDGXG9amH4oW90LL/HPXlb9ves1g1oR3SuDjhc7P5pKVx48aoVq2a1ceLFy+Ojh07Wn08NDRUPZ4hQwbEixcPadOmRZMmTXD9+vVoZe/cuYN27drBw8MD8ePHh7u7OypXroytW7ciNk1csA0NqxVVJ18vjzQq0UiUIB781+yxWH7Koh0qU27/U2l4ZkqN3q0qIY+XO6YtDTS0LkxeuB1dm5RTJ3I5+U8a2BB37j/EusBjsFUTF2xHw2pFUL+yb2QcetZWcZi/NoY4+BrFoWUleHu5Y/qSnVFxWLQDXd7GIafEYcBPb+NwHLaK9YFxYH3gfmFN63olMXfVbixYuxfnrtxB5+GL8PT5SzSoUsRi+VoVC2HM7E3YvPs0rt0Mwczl/6i/2zYoqR5PED8uqpTIiwHjV2H3kUu4cuM+Rk5bj8tBwWjyw3f43Gw+afl/SMLi6+uLLVu2YPLkybh48SIWLVqk/vfx8cHly5cNZa9evYoCBQpg27Zt+O2333DixAls3LgRJUqUQJs2bWJtG16+eo2jZ4NQvJCnYZmdnR38CnniwIkrFp+z/8QVFPfxMllW0jc7DpyI7EqRink3JBzFC0WVcUqSEAVyZsSB4zF3t8RmHI6dDYKfj1kcfCQOlt+zLJc4GSvp62WI27Vb+jhElXHUx8FKbGMb6wPjwPrA/cKauA72yOvljh37zxmWyZezwP3n4JM7k8XnxI/rEK1l+fmLl/DNk9nQfeTgYI/nL83LvIJv3sgyn5MDvmC9e/fGrVu3VJKSOnVqtSx9+vT4+++/kTVrVpWMbNiwQS1v3bo14sSJg/379yNx4sSGdeTMmVO1zMSWkAeP8eZNBFxSJDVZ7pLCEReu3rX4nHsh4XBxNi+fVC0XcqJWy8zKuDpHlbE1IQ+evI2DY7TtOn/NehxczeIm9++97U4yxCFabG05DqwPjAPrA/cLy5yTJVEJhnmXeXBoOLJmTGXxOdv2nkHr+iWx+8hF1YoiXwQrlcgLe7s46vHHT19g//HL6Na0As5fuYt7oeGoWa6gSoIu3wjG5/bFtrRERESoVpX69esbEha9hAkTqiRFkhdpjZGbtKpIEmOcsOglS5bM6uu8ePEC4eHhJjciIiIt6Pn7Mly+fg/7l/bFvd1jMar7j6prKSJCZyjTot9cxIkDnNkwFHf/HYtfavth+aaDJmU+ly82aQkODsaDBw+QPbvpKGg9WS7NZtIKIzf528vLtEvlfQwfPhxOTk6Gm4yD+diZs729ncXM2dXZtNVBT5YHh5iXf2Qon+rt/+Zl7oVElbE1zskSv41DeLTt0m+POdkWfauKntzXt74Y4hAttrYcB9YHxoH1gfuF9ZbY16/fWGyZt9Z6LM+RCQpuxTqrGaoy6/TJ0xe4eivEUObqzfuo1GIc3L7rjFyV+qJ049GqRefazfv43DSTtMyfPx9JkiQx3Hbt2vVez5Nk5GOUsaZXr154+PCh4RYUFISPKV5cB9VHGXjgnEkr0s4D5632URbKncmkvNi+7yx8cmdUf2dwc1YnbOMy4Y+fqenDPt6RZWyNxEEGE8t2G8ch8KDEwfJ7luXG5cWOfVF9uxnSxhAHK7GNbawPjAPrA/cLa169fqPGQBqP/ZNhD8V8sr1znN6Ll69xO/ihGsNSuWRebLAwGUEG9Eq3ulPShGqSw/qdJ/C5aWZMS5UqVVC4cGHDfTc3txjLu7i4qG6dM2fOWHxclsuHmSVLFnVf/j579uwHvy+ZZSS3Tz0avPXAeciXPT3y58yISQu348mzF2oWjWjZf66aeta/bVV1v0Wd4qjUYiz+8t+Kst/mVFNkj565jrG/1jVsa8u6JTB65kZ4uLuoJGbY5HVIndJJTY+2Va3rlUCbgf7Iq+KQQc38efrsBepVioxDK4mDazL0a1PFEIfKLcbhr/lbUfYbicNhFYcxv9aJikOd4vh95t/I7O6qkhi5dk1kHLxhq1gfGAfWB+4XMc0unNj/Jxw5cx2HT11Fq7olkDhhfMxfu1c9LjMkJTkZNGGNul8gZwZ13Dxx/gbSuiRDj18qws4ujroshvFEDukeunDtHjzSuWBQh2o4f/Uu5luZwfopaSZpSZo0qbq9L5lZUqtWLdVCM2jQIJNxLc+ePcPEiRNRrlw5pEiRQi2TvydMmID27dtHG9ci3UwxjWv51GqULYD7Dx6ri6BJF07ubG5YNr6NoQvjxp1Q2EmNeqtwHg9MG9IYQycFYPDEtSox8R/9C3JkSWso06FhaXXC7zRsIR4+fqZGii8b31pNb7NVNcoUQEjYYwyfGhmHXNncsHRc66g43A1TO5teYW8PTB3cWCUiQyYGRMbht+bIkTkqDu0blsaT5y+N4uCh1mnTcWB9YBxYH7hfWLFy82GkTJYEv7b4Xk2uOHH+Jmq2j7quV7rUKRBh1LsQP35cdTmIjG4p1ZdhuQBny35zVauznmOSBOrLYFrXZAgLf4q1245iyMS1eP0mAp9bHN3/0zfyma7TIknDqlWrrF6nRVpdunXrZrI8TZo0cHBwUK0zMvB21KhRyJUrF65cuYI+ffrg3Llz2LNnj7omi5Dpz998841KYiTJ8fb2xuvXr7F582ZMmjTJaouNORmIK2Nb7oY8hKOjbY6L+FxsvGp9NtKiQ0RkTXKftl91cHRvXuLFiWlqiMW7zpuaGdMSkwULFiBfvnwmt2nTpsHZ2Rl79+5V11pp0aIFMmfOrFpf5P8DBw4YEhYhfx8+fFiV7dKli0pwypQpoy4sJ0kLERERxS6bb2nRGra0RGHVisSWFiKKCVtaXn5dLS1ERET05WPSQkRERJrApIWIiIg0gUkLERERaQKTFiIiItIEJi1ERESkCUxaiIiISBOYtBAREZEmMGkhIiIiTWDSQkRERJrApIWIiIg0gUkLERERaQKTFiIiItIEJi1ERESkCUxaiIiISBOYtBAREZEmMGkhIiIiTWDSQkRERJrApIWIiIg0gUkLERERaQKTFiIiItIEJi1ERESkCUxaiIiISBOYtBAREZEmMGkhIiIiTXCI7TfwpdHpdOr/R+Hh+NrpY/G1ixMnTmy/BSKyYbo3L/E1073d/vc5ZzBp+cgePXqk/s+Syf1jr5qIiOiLPn86OTnFWCaOjl+HP6qIiAjcunULSZMmjbVv2OHh4XB3d0dQUBAcHR3xtWIcGAfWB+4XPD7Y/nFS0hBJWNKmTQs7u5hHrbCl5SOTgKdLlw62QCrg15y06DEOjAPrA/cLHh9s+zj5rhYWPQ7EJSIiIk1g0kJERESawKTlCxQ/fnz0799f/f81YxwYB9YH7hc8PnxZx0kOxCUiIiJNYEsLERERaQKTFiIiItIEJi1ERESkCUxaiIiISBOYtHxh5KqGTZo0UVcWjBcvHjJkyIAOHTogJCQEWtG4cWN1NWH9zdnZGeXLl8fx48etPufq1avRnlO2bFkcOXLEUKZ48eImZfS3li1bGsoYL5cLLfn4+GD16tWwhZhUq1bN6uPG25YgQQLkyJEDEydONDw+e/Zsi9suZY1fQ788bty4yJQpE7p3747nz59DK/VA79SpU6hVqxZcXFzUrIhs2bKhX79+ePr0qUm5jBkzGtafKFEi5M6dG9OnT7d4xc5p06ahSJEiql4kSZIEOXPmVPvWxYsXYSv1QDx79kzNBpFtlm1PmTIlfvzxRxUTYwMGDDBsu729vboq6i+//ILQ0NBo65T9qHbt2kiTJo1apxxXKlWqhLVr13723xj7f44PR48etVpm9+7dqFixIpInT672C6kLf/zxB968eROt7Pbt21VZeW2pN7K/denSBTdv3oQtHhs6duxo9XH5vOVx+UzlnCHnDjmHXL9+PVrZO3fuoF27dvDw8FD1QOpM5cqVsXXrVnwuTFq+IJcvX0bBggVx4cIFLFy4UB1MJ0+erCqUHGwtHYxslRyEbt++rW7y/h0cHNRB8l22bNminvP333/j8ePHqFChAh48eGB4vHnz5ob16m+jRo0yWcesWbPU8oMHD+Kbb75BzZo1ceLECdg6/badPn1anbDbtGmj6oGenGzNt/3atWsW4y51acyYMZgyZYo6AWqpHuzduxeFCxfGy5cvsW7dOpw/fx5Dhw5ViVuZMmXUcmODBg1S6z958iQaNGig4rhhwwbD43JSrlevHtq3b69OVJs2bVIxnjFjhjq5DRkyBLbixYsXKF26NGbOnKnel2z7+vXr8fr1axUTiY0xSbxk2+UEJfV+48aNaNWqlUkZSdp9fX3V/jRnzhycOXNGlatevTr69OmDhw8faub4YM3KlSvh5+enrmYuCcnZs2dVQioxrFOnjkliJvuExDh16tRYvny5qgtynJU4/P7779CS0NBQ9dnKcVO2Qc4ZixYtUv/LFzY5DhgnfgUKFMC2bdvw22+/qWOi1IMSJUqoY81nI789RF+G8uXL69KlS6d7+vSpyfLbt2/rEiVKpGvZsqVOCxo1aqSrWrWqybJdu3bJUUN37949i8+5cuWKevzIkSOGZf/++69atnHjRnXfz89P16FDhxhfW8qvXLnScD88PFwtGzdunM7WYmLM0rZlzZpVV6dOHfX3rFmzdE5OTh/8GjVq1NDly5dPp5V6EBERocuRI4euYMGCujdv3pg8dvToUV2cOHF0I0aMMCzLkCGDbsyYMSblUqRIoevUqZPh/sKFC9Vrrl692upr2ko9kG2TbZRtNSaxkJhIbPTvt3///ro8efKYlOvcubMuefLkhvuPHz/WOTs766pXr271NT/n9n/M44P5NkpdN7dmzRr1vEWLFqn7QUFBunjx4uk6duxo8XXCwsJ0Wjg26Mk5IXHixOocYUzOIW5ubuqcolehQgW1TOIVm9vNlpYvhGTM0rrQunVrJEyY0OQx+UZQv359LF68+LM35X4M8g3P398fWbJkUc2x70sfB/Nv1u9Lvp3Kt2khzaZaI9v/X7ddSMuDNJnbyra/Tz2Q5n/55tu5c+doP7yWJ08e9Q3ZuPXJ/MdO5ZtzWFiYyTZLeU9PT1SpUsXi82Lrh1EtWbBggWpNkm01JrHo1KmTis2xY8csPle+ScsxxHjbpVVJupalm9Ca2N7+/3p8MN/Grl27RntMuj6km01fZ5YuXar2KWvxSJYsGbQiIiJCtarIuUHOEebHDjmXSH2Qc4vcpFVFWlQSJ04cq9vNpOULIV1CkpBkz57d4uOyXA7GwcHB0IKAgAA1bkBu8ovZa9asUUnXu34BVE+6hAYPHqyeX6hQIcNyGeehX6/+Nn/+fJPn1q1bVy2XPls50Mu4B+lu0Qrpg5eDuPTxlyxZ0rBcmq/Nt126zyzFXd+nf+/ePXTr1i0WtuK/1QPpDhEx7Qf6Mno9evQwfN7SFShjGpo1a2ayTklajMkYAP37spUfSNW/15i2XV9GT5r4ZRvkJCVjmGTci8TDeH3CePsPHDhgUofkM9La8eFD6oyXl5ehjBxnpZtVxvZoXXBwsDpOxlRf5JwiXUVyk78lFrGNScsXRostKZZIP6l8a5bb/v37Ua5cOXWClTEY8r/+gCV98saKFi2qlsuJR75RyoEsVapUhsflW4V+vfqb+TdoGcshy2Vcgwywk4GZKVKkgC2QBMv4hLFr165oCZmcgGRchiRcxuMT5OBuvu3mg071cd+3bx8aNWqEn3/+GT/88MNn3caPUQ8+ZD+QpEzWL331Mu5DPn/51h6T3r17q+fI4F75pm9L9eBDtl2SEdkOSUQkWZH4ykDLmHh7exs+kydPnqgWSa3Ui5i8T9ykTGy3LP2XOvExtttWOMT2G6CPQw6ysjPJIDkZIGdOlsuJXGZTaIE0QRqfOOTkKj9dLjM45G+ZISFklosxSVIk0ZBmYktNlrKOd52QpKlUyshNBifK4EtpVnd1dUVskwRLTqx6bm5uJgmZnEwlaZFvgubfOuX+u7bdOO4ymFO6GaSLrGnTptBCPZCmfH19z5cvX7T1yXJ9GT2ZXaP/vKX5X1qYZEC71CORNWtWnDt3zuQ5sh/JLbbqhLV6INsm22iJfrnx9ktXkD6+I0aMwPfff4+BAweqVkr9tgvZfhmwKaRF6l31yFaPD5YY1xn50mNOluvrgpSVFksZAGxrrS1VYjg2WCL1V46RMdUXOafo4yx/ywDl2MaWli+EnKSlL1u+bet3WONpapKFy5RFW/2W8C7yvuWkK9smO6P+JCPT9IzJFLzMmTN/tD5W6VqSEfMy+8QWSGuJftvlZjx+SZ+QSXz+SzO5OVnHr7/+qmaImNcpW60HefPmVU3Y0loiffbGpOVNZklI9581Un9kP+nVq5dhmZSXk7YtTH1/Vz2QmS6yjebjViQWEhM5+ZqPdzEmn/Xo0aNx69YtdV8uGyCtjCNHjsSXcHywRL+Nlmb+SLeTdAnp64x0H0qiZz7jUM94pqItHRsskXhJt7eMg5JzhDGJo5xLpAVLYiM3+XvChAmqdS02t5tJyxfkr7/+UlMepXLt3LlTXbNFBk9JMiM7sq2ceN+HbIfsSHKTjF+arKUZXgbG/T/kOh369epvMtYnJjJ+QaY5xsY1GD4maeI133a5mZ/cjcn1PeQaHnKw0kI9kJOXtAxJy5h0a0nXgUznlRYUeY5M/Y/pmhVCprrK9Udkyrs+EZCTlfwv06Ol60wGrQYGBqqWPYmPrZAuQUm0ZVtlm2XbpetHYiHxk9jE9MVF4iPdP8OGDVP3pZtBWi5k6ri0wsjATJkGK+Ol9Cfu2Nj+/3p8kOTTvItUkhDZvyUplevUyLbJ5yuxkmugyGevH9MmSa0kf+PGjVOtj1IHpEvq33//RYsWLQwtVLY4fuWo2XbfvXtXfc7SsiznCOkOl3OGnDvkHPLq1SuT/V7+lvFyUr9kwLokcxL78ePHq3rz2Xy2eUr0WVy9elVNgUuVKpUubty4Ond3d127du109+/f18wnIO9fqqb+ljRpUp2Pj49u2bJlVp8T05RG46l/xuvV38qVK2d1yrN+SqeXl5euVatWutjy/0xr1E95trTtctNPd7T2GsOHD9e5uLhYnOpoa/VA7/jx47offvhBTV+W/SBz5sy6Pn366J48eWJSztKUZyF1QqZ4Gk8Znjx5sq5w4cJqiqhMe/Xw8NA1b95cd/r0aZ2t1AMh29i7d29dlixZ1LZLDCQWJ06cMClnacqzfop3/PjxddevXzcsO3DggK5mzZo6V1dXnYODg5oiLDGSqcCxMeX5vx4fLN1kGrPYuXOn2iZHR0f1+ebMmVM3evRo3evXr6Otb/PmzaqsTA9PkCCBOj507dpVd+vWLZ0tHhtgYbsHDx6sHg8ODlbnCDlXSH2Rc0fjxo11165di7Yu2b42bdqo/UZiJFOgq1Spotu+fbvuc4kj/3y+FImIiIjov2H3EBEREWkCkxYiIiLSBCYtREREpAlMWoiIiEgTmLQQERGRJjBpISIiIk1g0kJERESawKSFiIiINIFJCxHZFLl0erVq1Qz3ixcv/s5L738KO3bsUJe8j+l3VeTxVatWvfc6BwwYoH4f6f8hl5iX15VLsRN9bZi0ENF7JRJyopSb/peB5Xd4Xr9+/cmjt2LFivf+TZf3STSISLscYvsNEJE2lC9fHrNmzVI/Vrd+/Xq0adMGcePGNflFZL2XL1+q5OZjkF+YJSISbGkhovcSP3589YuwGTJkQKtWrVC6dGmsWbPGpEtHfkk8bdq08PT0VMvlV2PlF3KTJUumko+qVauq7g09+dXYzp07q8ednZ3RvXt39WvUxsy7hyRp6tGjh/rFXXlP0uojv8gr6y1RooQqkzx5ctXiIu9LyC9ZDx8+HJkyZULChAmRJ08eLFu2zOR1JBHLli2belzWY/w+35e8L1lHokSJ4OHhgb59+6pfyzUnvyos71/KSXwePnxo8rj8snL27NmRIEECeHl5YeLEiR/8Xoi+RExaiOg/kZO7tKjobd26FefOncPmzZsREBCgTtbyE/dJkybFrl278O+//yJJkiSqxUb/vN9//x2zZ8/GzJkz8c8//yA0NBQrV66M8XUbNmyIhQsXYvz48Thz5oxKAGS9kgQsX75clZH3cfv2bYwbN07dl4Rl7ty5mDx5Mk6dOoVOnTqhQYMGCAwMNCRXNWrUQOXKldVYkWbNmqFnz54fHBPZVtme06dPq9eeNm0axowZY1Lm4sWLWLJkCdauXYuNGzfiyJEjaN26teHx+fPno1+/fioBlO0bNmyYSn7mzJnzwe+H6Ivz2X5Pmog0q1GjRrqqVauqvyMiInSbN2/WxY8fX9e1a1fD4/KT9i9evDA8Z968eTpPT09VXk8eT5gwoe7vv/9W99OkSaMbNWqU4fFXr17p0qVLZ3gt4efnp+vQoYP6+9y5c9IMo17fku3bt6vHw8LCDMueP3+uS5QokW737t0mZZs2baqrW7eu+rtXr166HDlymDzeo0ePaOsyJ4+vXLnS6uO//fabrkCBAob7/fv319nb2+tu3LhhWLZhwwadnZ2d7vbt2+p+5syZdQsWLDBZz+DBg3VFihRRf1+5ckW97pEjR6y+LtGXimNaiOi9SOuJtGhIC4p0t9SrV0/NhtHLnTu3yTiWY8eOqVYFaX0w9vz5c1y6dEl1iUhrSOHChQ2POTg4oGDBgtG6iPSkFcTe3h5+fn7v/anJe3j69CnKlCljslxae/Lly6f+lhYN4/chihQpgg+1ePFi1QIk2/f48WM1UNnR0dGkTPr06eHm5mbyOhJPaR2SWMlzmzZtiubNmxvKyHqcnJw++P0QfWmYtBDRe5FxHpMmTVKJiYxbkQTDWOLEiU3uy0m7QIECqrvDnIuLy3/ukvpQ8j7EunXrTJIFIWNiPpY9e/agfv36GDhwoOoWkyRj0aJFqgvsQ9+rdCuZJ1GSrBF97Zi0ENF7kaREBr2+r/z586uWB1dX12itDXpp0qTBvn37UKxYMUOLwqFDh9RzLZHWHGmVkLEoMhDYnL6lRwb46uXIkUMlJ9evX7faQiODXvWDivX27t2LD7F79241SLl3796GZdeuXYtWTt7HrVu3VOKnfx07Ozs1eDlVqlRq+eXLl1UCRESmOBCXiD4JOemmTJlSzRiSgbhXrlxR11Fp3749bty4ocp06NABI0aMUBdoO3v2rBqQGtM1VjJmzIhGjRqhSZMm6jn6dcrAViFJg8wakq6s4OBg1XIhXS5du3ZVg29lMKt0vxw+fBh//vmnYXBry5YtceHCBXTr1k110yxYsEANqP0QWbNmVQmJtK7Ia0g3kaVBxTIjSLZBus8kLhIPmUEkM7OEtNTIwGF5/vnz53HixAk11fyPP/74oPdD9CVi0kJEn4RM5925c6cawyEzc6Q1Q8ZqyJgWfctLly5d8NNPP6mTuIztkASjevXqMa5Xuqhq1qypEhyZDixjP548eaIek+4fOenLzB9ptWjbtq1aLhenkxk4kgzI+5AZTNJdJFOghbxHmXkkiZBMh5ZZRjJr50NUqVJFJUbymnLVW2l5kdc0J61VEo+KFSuibNmy8Pb2NpnSLDOXZMqzJCrSsiStQ5JA6d8r0dcsjozGje03QURERPQubGkhIiIiTWDSQkRERJrApIWIiIg0gUkLERERaQKTFiIiItIEJi1ERESkCUxaiIiISBOYtBAREZEmMGkhIiIiTWDSQkRERJrApIWIiIigBf8D+nm3fY/uvsMAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 600x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "plot_confusion_matrix(df_tokens[\"labels\"], df_tokens[\"predicted_label\"],\n",
    "                      tags.names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "1465d830",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>tokens</th>\n",
       "      <td>▁'</td>\n",
       "      <td>▁''</td>\n",
       "      <td>▁Τ</td>\n",
       "      <td>Κ</td>\n",
       "      <td>▁''</td>\n",
       "      <td>▁'</td>\n",
       "      <td>▁'</td>\n",
       "      <td>▁''</td>\n",
       "      <td>▁T</td>\n",
       "      <td>▁''</td>\n",
       "      <td>▁'</td>\n",
       "      <td>ri</td>\n",
       "      <td>▁''</td>\n",
       "      <td>▁'</td>\n",
       "      <td>k</td>\n",
       "      <td>▁''</td>\n",
       "      <td>▁'</td>\n",
       "      <td>ala</td>\n",
       "      <td>&lt;/s&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>labels</th>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>IGN</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>B-LOC</td>\n",
       "      <td>I-LOC</td>\n",
       "      <td>I-LOC</td>\n",
       "      <td>I-LOC</td>\n",
       "      <td>I-LOC</td>\n",
       "      <td>IGN</td>\n",
       "      <td>I-LOC</td>\n",
       "      <td>I-LOC</td>\n",
       "      <td>IGN</td>\n",
       "      <td>I-LOC</td>\n",
       "      <td>I-LOC</td>\n",
       "      <td>IGN</td>\n",
       "      <td>IGN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>preds</th>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>B-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>losses</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.43</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>9.98</td>\n",
       "      <td>9.76</td>\n",
       "      <td>7.99</td>\n",
       "      <td>8.27</td>\n",
       "      <td>9.25</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8.77</td>\n",
       "      <td>9.35</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8.83</td>\n",
       "      <td>9.42</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0     1      2      3     4     5      6      7      8      9   \\\n",
       "tokens    ▁'   ▁''     ▁Τ      Κ   ▁''    ▁'     ▁'    ▁''     ▁T    ▁''   \n",
       "labels     O     O      O    IGN     O     O  B-LOC  I-LOC  I-LOC  I-LOC   \n",
       "preds      O     O  B-ORG  I-ORG     O     O      O      O      O      O   \n",
       "losses  0.00  0.00   3.43   0.00  0.00  0.00   9.98   9.76   7.99   8.27   \n",
       "\n",
       "           10    11     12     13    14     15     16    17    18  \n",
       "tokens     ▁'    ri    ▁''     ▁'     k    ▁''     ▁'   ala  </s>  \n",
       "labels  I-LOC   IGN  I-LOC  I-LOC   IGN  I-LOC  I-LOC   IGN   IGN  \n",
       "preds       O     O      O      O     O      O      O     O     O  \n",
       "losses   9.25  0.00   8.77   9.35  0.00   8.83   9.42  0.00  0.00  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>tokens</th>\n",
       "      <td>▁''</td>\n",
       "      <td>8</td>\n",
       "      <td>.</td>\n",
       "      <td>▁Juli</td>\n",
       "      <td>▁''</td>\n",
       "      <td>▁:</td>\n",
       "      <td>▁Protest</td>\n",
       "      <td>camp</td>\n",
       "      <td>▁auf</td>\n",
       "      <td>▁dem</td>\n",
       "      <td>▁Gelände</td>\n",
       "      <td>▁der</td>\n",
       "      <td>▁Republika</td>\n",
       "      <td>n</td>\n",
       "      <td>ischen</td>\n",
       "      <td>▁Gar</td>\n",
       "      <td>de</td>\n",
       "      <td>&lt;/s&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>labels</th>\n",
       "      <td>B-ORG</td>\n",
       "      <td>IGN</td>\n",
       "      <td>IGN</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>IGN</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>IGN</td>\n",
       "      <td>IGN</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>IGN</td>\n",
       "      <td>IGN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>preds</th>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>B-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>losses</th>\n",
       "      <td>8.57</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7.55</td>\n",
       "      <td>7.44</td>\n",
       "      <td>7.49</td>\n",
       "      <td>5.88</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5.51</td>\n",
       "      <td>6.74</td>\n",
       "      <td>6.19</td>\n",
       "      <td>5.47</td>\n",
       "      <td>4.52</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           0     1     2      3      4      5         6     7      8      9   \\\n",
       "tokens    ▁''     8     .  ▁Juli    ▁''     ▁:  ▁Protest  camp   ▁auf   ▁dem   \n",
       "labels  B-ORG   IGN   IGN  I-ORG  I-ORG  I-ORG     I-ORG   IGN  I-ORG  I-ORG   \n",
       "preds       O     O     O      O      O      O         O     O      O      O   \n",
       "losses   8.57  0.00  0.00   7.55   7.44   7.49      5.88  0.00   5.51   6.74   \n",
       "\n",
       "              10     11          12     13      14     15     16    17  \n",
       "tokens  ▁Gelände   ▁der  ▁Republika      n  ischen   ▁Gar     de  </s>  \n",
       "labels     I-ORG  I-ORG       I-ORG    IGN     IGN  I-ORG    IGN   IGN  \n",
       "preds          O      O       B-ORG  I-ORG   I-ORG  I-ORG  I-ORG     O  \n",
       "losses      6.19   5.47        4.52   0.00    0.00   0.03   0.00  0.00  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>tokens</th>\n",
       "      <td>▁United</td>\n",
       "      <td>▁Nations</td>\n",
       "      <td>▁Multi</td>\n",
       "      <td>dimensional</td>\n",
       "      <td>▁Integra</td>\n",
       "      <td>ted</td>\n",
       "      <td>▁Stabil</td>\n",
       "      <td>ization</td>\n",
       "      <td>▁Mission</td>\n",
       "      <td>▁in</td>\n",
       "      <td>▁the</td>\n",
       "      <td>▁Central</td>\n",
       "      <td>▁African</td>\n",
       "      <td>▁Republic</td>\n",
       "      <td>&lt;/s&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>labels</th>\n",
       "      <td>B-PER</td>\n",
       "      <td>I-PER</td>\n",
       "      <td>I-PER</td>\n",
       "      <td>IGN</td>\n",
       "      <td>I-PER</td>\n",
       "      <td>IGN</td>\n",
       "      <td>I-PER</td>\n",
       "      <td>IGN</td>\n",
       "      <td>I-PER</td>\n",
       "      <td>I-PER</td>\n",
       "      <td>I-PER</td>\n",
       "      <td>I-PER</td>\n",
       "      <td>I-PER</td>\n",
       "      <td>I-PER</td>\n",
       "      <td>IGN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>preds</th>\n",
       "      <td>B-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>losses</th>\n",
       "      <td>6.33</td>\n",
       "      <td>5.81</td>\n",
       "      <td>5.39</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5.30</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5.11</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5.28</td>\n",
       "      <td>4.51</td>\n",
       "      <td>4.79</td>\n",
       "      <td>5.10</td>\n",
       "      <td>5.06</td>\n",
       "      <td>5.08</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             0         1       2            3         4      5        6   \\\n",
       "tokens  ▁United  ▁Nations  ▁Multi  dimensional  ▁Integra    ted  ▁Stabil   \n",
       "labels    B-PER     I-PER   I-PER          IGN     I-PER    IGN    I-PER   \n",
       "preds     B-ORG     I-ORG   I-ORG        I-ORG     I-ORG  I-ORG    I-ORG   \n",
       "losses     6.33      5.81    5.39         0.00      5.30   0.00     5.11   \n",
       "\n",
       "             7         8      9      10        11        12         13     14  \n",
       "tokens  ization  ▁Mission    ▁in   ▁the  ▁Central  ▁African  ▁Republic   </s>  \n",
       "labels      IGN     I-PER  I-PER  I-PER     I-PER     I-PER      I-PER    IGN  \n",
       "preds     I-ORG     I-ORG  I-ORG  I-ORG     I-ORG     I-ORG      I-ORG  I-ORG  \n",
       "losses     0.00      5.28   4.51   4.79      5.10      5.06       5.08   0.00  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def get_samples(df):\n",
    "    for _, row in df.iterrows():\n",
    "        labels, preds, tokens, losses = [], [], [], []\n",
    "        for i, mask in enumerate(row[\"attention_mask\"]):\n",
    "            if i not in {0, len(row[\"attention_mask\"])}:\n",
    "                labels.append(row[\"labels\"][i])\n",
    "                preds.append(row[\"predicted_label\"][i])\n",
    "                tokens.append(row[\"input_tokens\"][i])\n",
    "                losses.append(f\"{row['loss'][i]:.2f}\")\n",
    "        df_tmp = pd.DataFrame({\"tokens\": tokens, \"labels\": labels, \n",
    "                               \"preds\": preds, \"losses\": losses}).T\n",
    "        yield df_tmp\n",
    "\n",
    "df[\"total_loss\"] = df[\"loss\"].apply(sum)\n",
    "df_tmp = df.sort_values(by=\"total_loss\", ascending=False).head(3)\n",
    "\n",
    "for sample in get_samples(df_tmp):\n",
    "    display(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "2fcd4dd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input_ids</th>\n",
       "      <th>attention_mask</th>\n",
       "      <th>labels</th>\n",
       "      <th>loss</th>\n",
       "      <th>predicted_label</th>\n",
       "      <th>input_tokens</th>\n",
       "      <th>total_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3558</th>\n",
       "      <td>[0, 242, 5106, 18141, 15020, 5106, 242, 242, 5...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[IGN, O, O, O, IGN, O, O, B-LOC, I-LOC, I-LOC,...</td>\n",
       "      <td>[0.0, 0.00034886473, 0.00042465254, 3.4285994,...</td>\n",
       "      <td>[O, O, O, B-ORG, I-ORG, O, O, O, O, O, O, O, O...</td>\n",
       "      <td>[&lt;s&gt;, ▁', ▁'', ▁Τ, Κ, ▁'', ▁', ▁', ▁'', ▁T, ▁'...</td>\n",
       "      <td>85.054512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5009</th>\n",
       "      <td>[0, 5106, 1019, 5, 19838, 5106, 152, 75198, 27...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[IGN, B-ORG, IGN, IGN, I-ORG, I-ORG, I-ORG, I-...</td>\n",
       "      <td>[0.0, 8.570335, 0.0, 0.0, 7.5512137, 7.4421945...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, B-ORG,...</td>\n",
       "      <td>[&lt;s&gt;, ▁'', 8, ., ▁Juli, ▁'', ▁:, ▁Protest, cam...</td>\n",
       "      <td>65.396805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4671</th>\n",
       "      <td>[0, 14098, 145704, 19335, 157955, 91969, 3674,...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]</td>\n",
       "      <td>[IGN, B-PER, I-PER, I-PER, IGN, I-PER, IGN, I-...</td>\n",
       "      <td>[0.0, 6.3316684, 5.805335, 5.391272, 0.0, 5.30...</td>\n",
       "      <td>[I-ORG, B-ORG, I-ORG, I-ORG, I-ORG, I-ORG, I-O...</td>\n",
       "      <td>[&lt;s&gt;, ▁United, ▁Nations, ▁Multi, dimensional, ...</td>\n",
       "      <td>57.764935</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              input_ids  \\\n",
       "3558  [0, 242, 5106, 18141, 15020, 5106, 242, 242, 5...   \n",
       "5009  [0, 5106, 1019, 5, 19838, 5106, 152, 75198, 27...   \n",
       "4671  [0, 14098, 145704, 19335, 157955, 91969, 3674,...   \n",
       "\n",
       "                                         attention_mask  \\\n",
       "3558  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "5009  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "4671   [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]   \n",
       "\n",
       "                                                 labels  \\\n",
       "3558  [IGN, O, O, O, IGN, O, O, B-LOC, I-LOC, I-LOC,...   \n",
       "5009  [IGN, B-ORG, IGN, IGN, I-ORG, I-ORG, I-ORG, I-...   \n",
       "4671  [IGN, B-PER, I-PER, I-PER, IGN, I-PER, IGN, I-...   \n",
       "\n",
       "                                                   loss  \\\n",
       "3558  [0.0, 0.00034886473, 0.00042465254, 3.4285994,...   \n",
       "5009  [0.0, 8.570335, 0.0, 0.0, 7.5512137, 7.4421945...   \n",
       "4671  [0.0, 6.3316684, 5.805335, 5.391272, 0.0, 5.30...   \n",
       "\n",
       "                                        predicted_label  \\\n",
       "3558  [O, O, O, B-ORG, I-ORG, O, O, O, O, O, O, O, O...   \n",
       "5009  [O, O, O, O, O, O, O, O, O, O, O, O, O, B-ORG,...   \n",
       "4671  [I-ORG, B-ORG, I-ORG, I-ORG, I-ORG, I-ORG, I-O...   \n",
       "\n",
       "                                           input_tokens  total_loss  \n",
       "3558  [<s>, ▁', ▁'', ▁Τ, Κ, ▁'', ▁', ▁', ▁'', ▁T, ▁'...   85.054512  \n",
       "5009  [<s>, ▁'', 8, ., ▁Juli, ▁'', ▁:, ▁Protest, cam...   65.396805  \n",
       "4671  [<s>, ▁United, ▁Nations, ▁Multi, dimensional, ...   57.764935  "
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "069bd9e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s> ' '' ΤΚ '' ' ' '' T '' 'ri '' 'k '' 'ala</s>\n",
      "<s> ''8. Juli '' : Protestcamp auf dem Gelände der Republikanischen Garde</s>\n",
      "<s> United Nations Multidimensional Integrated Stabilization Mission in the Central African Republic</s>\n"
     ]
    }
   ],
   "source": [
    "for i, row in df_tmp.iterrows():\n",
    "    print(xlmr_tokenizer.decode(row['input_ids']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "b16e5e56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([    0,   242,  5106, 18141, 15020,  5106,   242,   242,  5106,\n",
       "         384,  5106,   242,   416,  5106,   242,    92,  5106,   242,\n",
       "        1539,     2], dtype=int32)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tmp.head(1)['input_ids'].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "f6e187c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide_output\n",
    "from transformers import TrainingArguments\n",
    "\n",
    "num_epochs = 2\n",
    "batch_size = 16\n",
    "logging_steps = len(panx_de_encoded[\"train\"]) // batch_size\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=model_name, log_level=\"error\", num_train_epochs=num_epochs, \n",
    "    per_device_train_batch_size=batch_size, \n",
    "    per_device_eval_batch_size=batch_size, eval_strategy=\"epoch\", \n",
    "    save_steps=1e6, weight_decay=0.01, disable_tqdm=False, \n",
    "    logging_steps=logging_steps, push_to_hub=True,use_mps_device=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "0cc20122",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer\n",
    "\n",
    "def model_init():\n",
    "    return (model.to(device))\n",
    "\n",
    "trainer = Trainer(model_init=model_init, args=training_args, \n",
    "                  data_collator=data_collator, compute_metrics=compute_metrics,\n",
    "                  train_dataset=panx_de_encoded[\"train\"],\n",
    "                  eval_dataset=panx_de_encoded[\"validation\"], \n",
    "                  processing_class=xlmr_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "6aa3a31a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[    0,    62, 11468, 15785,   166, 22824,    99, 48909,     2]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n"
     ]
    }
   ],
   "source": [
    "text = \"Adilbek sucks at math\"\n",
    "text_encoded = xlmr_tokenizer(text, return_tensors=\"pt\").to(device)\n",
    "print(text_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "64b7103f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TokenClassifierOutput(loss=None, logits=tensor([[[ 0.6862,  0.0694,  0.3161, -0.6144,  0.1330, -0.3427, -0.5023],\n",
      "         [-1.2207,  5.2658, -1.3666,  2.4725, -1.9593,  1.3295, -3.6927],\n",
      "         [-2.1569,  1.3452,  4.1068, -1.3375,  2.3661, -1.6995,  0.6200],\n",
      "         [-1.4793, -0.4468,  4.4619, -2.2128,  3.0184, -2.1732,  1.9559],\n",
      "         [ 3.3999, -1.8762,  1.5123, -1.9578,  2.2201, -2.9171,  0.1313],\n",
      "         [ 3.3696, -1.5268,  1.6742, -1.3873,  2.1139, -3.4198, -0.5283],\n",
      "         [ 4.0392, -2.0109,  0.1279, -0.9446,  2.3306, -2.6941, -0.7495],\n",
      "         [ 3.6001, -1.2569, -0.3955,  0.1383,  1.6478, -1.7761, -1.0663],\n",
      "         [ 0.8245,  0.0882,  0.3899, -0.6337,  0.2798, -0.4562, -0.5568]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n"
     ]
    }
   ],
   "source": [
    "model.to(device)\n",
    "output = model(**text_encoded)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "aa35219c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1, 2, 2, 0, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_probs = torch.softmax(output[\"logits\"], dim=-1)\n",
    "pred_labels = torch.argmax(pred_probs, dim=-1)\n",
    "pred_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "42330c19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<s>', '▁A', 'dil', 'bek', '▁su', 'cks', '▁at', '▁math', '</s>']"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xlmr_tokenizer.convert_ids_to_tokens(text_encoded[\"input_ids\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "8f2bc846",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O\n",
      "B-PER\n",
      "I-PER\n",
      "I-PER\n",
      "O\n",
      "O\n",
      "O\n",
      "O\n",
      "O\n"
     ]
    }
   ],
   "source": [
    "for i in pred_labels[0]:\n",
    "    print(index2tag[i.item()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "a29070c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2, 2, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "078637d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1, 2, 2, 0, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "f9dbcefa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'O',\n",
       " 1: 'B-PER',\n",
       " 2: 'I-PER',\n",
       " 3: 'B-ORG',\n",
       " 4: 'I-ORG',\n",
       " 5: 'B-LOC',\n",
       " 6: 'I-LOC',\n",
       " -100: 'IGN'}"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index2tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "77215cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_f1_score(trainer, dataset):\n",
    "    return trainer.predict(dataset).metrics[\"test_f1\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "e1131785",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nurma/vscode_projects/NLP/.venv/lib/python3.13/site-packages/torch/utils/data/dataloader.py:692: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score of [de] model on [de] dataset: 0.817\n"
     ]
    }
   ],
   "source": [
    "f1_scores = defaultdict(dict)\n",
    "f1_scores[\"de\"][\"de\"] = get_f1_score(trainer, panx_de_encoded[\"test\"])\n",
    "print(f\"F1-score of [de] model on [de] dataset: {f1_scores['de']['de']:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "77abcae2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Tokens</th>\n",
       "      <td>&lt;s&gt;</td>\n",
       "      <td>▁Jeff</td>\n",
       "      <td>▁De</td>\n",
       "      <td>an</td>\n",
       "      <td>▁est</td>\n",
       "      <td>▁informatic</td>\n",
       "      <td>ien</td>\n",
       "      <td>▁chez</td>\n",
       "      <td>▁Google</td>\n",
       "      <td>▁en</td>\n",
       "      <td>▁Cali</td>\n",
       "      <td>for</td>\n",
       "      <td>nie</td>\n",
       "      <td>&lt;/s&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tags</th>\n",
       "      <td>O</td>\n",
       "      <td>B-PER</td>\n",
       "      <td>I-PER</td>\n",
       "      <td>I-PER</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>B-ORG</td>\n",
       "      <td>O</td>\n",
       "      <td>B-LOC</td>\n",
       "      <td>I-LOC</td>\n",
       "      <td>I-LOC</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         0      1      2      3     4            5    6      7        8    9   \\\n",
       "Tokens  <s>  ▁Jeff    ▁De     an  ▁est  ▁informatic  ien  ▁chez  ▁Google  ▁en   \n",
       "Tags      O  B-PER  I-PER  I-PER     O            O    O      O    B-ORG    O   \n",
       "\n",
       "           10     11     12    13  \n",
       "Tokens  ▁Cali    for    nie  </s>  \n",
       "Tags    B-LOC  I-LOC  I-LOC     O  "
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_fr = \"Jeff Dean est informaticien chez Google en Californie\"\n",
    "tag_text(text_fr, tags, trainer.model, xlmr_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "d5b97fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tag_text(text, tags, model, tokenizer):\n",
    "    tokens = tokenizer(text).tokens()\n",
    "    input_ids = tokenizer(text, return_tensors=\"pt\").to(device)\n",
    "    model = model.to(device)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**input_ids).logits\n",
    "    predictions = outputs.argmax(-1)\n",
    "    preds = [tags.names[p] for p in predictions[0].cpu().numpy()]\n",
    "    return pd.DataFrame([tokens, preds], index=[\"Tokens\", \"Tags\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "2d8b184d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 2290/2290 [00:00<00:00, 38849.66 examples/s]\n",
      "/Users/nurma/vscode_projects/NLP/.venv/lib/python3.13/site-packages/torch/utils/data/dataloader.py:692: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Placeholder storage has not been allocated on MPS device!",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[211]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      2\u001b[39m     panx_ds = encode_panx_dataset(panx_ch[lang])\n\u001b[32m      3\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m get_f1_score(trainer, panx_ds[\u001b[33m\"\u001b[39m\u001b[33mtest\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m f1_scores[\u001b[33m\"\u001b[39m\u001b[33mde\u001b[39m\u001b[33m\"\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mfr\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[43mevaluate_lang_performance\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfr\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mF1-score of [de] model on [fr] dataset: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mf1_scores[\u001b[33m'\u001b[39m\u001b[33mde\u001b[39m\u001b[33m'\u001b[39m][\u001b[33m'\u001b[39m\u001b[33mfr\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[211]\u001b[39m\u001b[32m, line 3\u001b[39m, in \u001b[36mevaluate_lang_performance\u001b[39m\u001b[34m(lang, trainer)\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mevaluate_lang_performance\u001b[39m(lang, trainer):\n\u001b[32m      2\u001b[39m     panx_ds = encode_panx_dataset(panx_ch[lang])\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mget_f1_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpanx_ds\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtest\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[207]\u001b[39m\u001b[32m, line 2\u001b[39m, in \u001b[36mget_f1_score\u001b[39m\u001b[34m(trainer, dataset)\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget_f1_score\u001b[39m(trainer, dataset):\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m)\u001b[49m.metrics[\u001b[33m\"\u001b[39m\u001b[33mtest_f1\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/vscode_projects/NLP/.venv/lib/python3.13/site-packages/transformers/trainer.py:4567\u001b[39m, in \u001b[36mTrainer.predict\u001b[39m\u001b[34m(self, test_dataset, ignore_keys, metric_key_prefix)\u001b[39m\n\u001b[32m   4564\u001b[39m start_time = time.time()\n\u001b[32m   4566\u001b[39m eval_loop = \u001b[38;5;28mself\u001b[39m.prediction_loop \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.args.use_legacy_prediction_loop \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m.evaluation_loop\n\u001b[32m-> \u001b[39m\u001b[32m4567\u001b[39m output = \u001b[43meval_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   4568\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtest_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdescription\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mPrediction\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_keys\u001b[49m\u001b[43m=\u001b[49m\u001b[43mignore_keys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetric_key_prefix\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmetric_key_prefix\u001b[49m\n\u001b[32m   4569\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4570\u001b[39m total_batch_size = \u001b[38;5;28mself\u001b[39m.args.eval_batch_size * \u001b[38;5;28mself\u001b[39m.args.world_size\n\u001b[32m   4571\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmetric_key_prefix\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m_jit_compilation_time\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m output.metrics:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/vscode_projects/NLP/.venv/lib/python3.13/site-packages/transformers/trainer.py:4685\u001b[39m, in \u001b[36mTrainer.evaluation_loop\u001b[39m\u001b[34m(self, dataloader, description, prediction_loss_only, ignore_keys, metric_key_prefix)\u001b[39m\n\u001b[32m   4682\u001b[39m         batch_size = observed_batch_size\n\u001b[32m   4684\u001b[39m \u001b[38;5;66;03m# Prediction step\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m4685\u001b[39m losses, logits, labels = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mprediction_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprediction_loss_only\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_keys\u001b[49m\u001b[43m=\u001b[49m\u001b[43mignore_keys\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4686\u001b[39m main_input_name = \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m.model, \u001b[33m\"\u001b[39m\u001b[33mmain_input_name\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33minput_ids\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   4687\u001b[39m inputs_decode = (\n\u001b[32m   4688\u001b[39m     \u001b[38;5;28mself\u001b[39m._prepare_input(inputs[main_input_name]) \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33minputs\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m args.include_for_metrics \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   4689\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/vscode_projects/NLP/.venv/lib/python3.13/site-packages/transformers/trainer.py:4902\u001b[39m, in \u001b[36mTrainer.prediction_step\u001b[39m\u001b[34m(self, model, inputs, prediction_loss_only, ignore_keys)\u001b[39m\n\u001b[32m   4900\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m.compute_loss_context_manager():\n\u001b[32m   4901\u001b[39m     num_items_in_batch = \u001b[38;5;28mself\u001b[39m._get_num_items_in_batch([inputs], \u001b[38;5;28mself\u001b[39m.args.device)\n\u001b[32m-> \u001b[39m\u001b[32m4902\u001b[39m     loss, outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcompute_loss\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   4903\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_outputs\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_items_in_batch\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_items_in_batch\u001b[49m\n\u001b[32m   4904\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4905\u001b[39m loss = loss.detach().mean()\n\u001b[32m   4907\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(outputs, \u001b[38;5;28mdict\u001b[39m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/vscode_projects/NLP/.venv/lib/python3.13/site-packages/transformers/trainer.py:4110\u001b[39m, in \u001b[36mTrainer.compute_loss\u001b[39m\u001b[34m(self, model, inputs, return_outputs, num_items_in_batch)\u001b[39m\n\u001b[32m   4108\u001b[39m         kwargs[\u001b[33m\"\u001b[39m\u001b[33mnum_items_in_batch\u001b[39m\u001b[33m\"\u001b[39m] = num_items_in_batch\n\u001b[32m   4109\u001b[39m     inputs = {**inputs, **kwargs}\n\u001b[32m-> \u001b[39m\u001b[32m4110\u001b[39m outputs = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4111\u001b[39m \u001b[38;5;66;03m# Save past state if it exists\u001b[39;00m\n\u001b[32m   4112\u001b[39m \u001b[38;5;66;03m# TODO: this needs to be fixed and made cleaner later.\u001b[39;00m\n\u001b[32m   4113\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.args.past_index >= \u001b[32m0\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/vscode_projects/NLP/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/vscode_projects/NLP/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/vscode_projects/NLP/.venv/lib/python3.13/site-packages/transformers/models/xlm_roberta/modeling_xlm_roberta.py:1387\u001b[39m, in \u001b[36mXLMRobertaForTokenClassification.forward\u001b[39m\u001b[34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[39m\n\u001b[32m   1372\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1373\u001b[39m \u001b[33;03mtoken_type_ids (`torch.LongTensor` of shape `(batch_size, sequence_length)`, *optional*):\u001b[39;00m\n\u001b[32m   1374\u001b[39m \u001b[33;03m    Segment token indices to indicate first and second portions of the inputs. Indices are selected in `[0,1]`:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1383\u001b[39m \u001b[33;03m    Labels for computing the token classification loss. Indices should be in `[0, ..., config.num_labels - 1]`.\u001b[39;00m\n\u001b[32m   1384\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1385\u001b[39m return_dict = return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m.config.use_return_dict\n\u001b[32m-> \u001b[39m\u001b[32m1387\u001b[39m outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mroberta\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1388\u001b[39m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1389\u001b[39m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1390\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1391\u001b[39m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1392\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1393\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1394\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1395\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1396\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1397\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1399\u001b[39m sequence_output = outputs[\u001b[32m0\u001b[39m]\n\u001b[32m   1401\u001b[39m sequence_output = \u001b[38;5;28mself\u001b[39m.dropout(sequence_output)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/vscode_projects/NLP/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/vscode_projects/NLP/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/vscode_projects/NLP/.venv/lib/python3.13/site-packages/transformers/models/xlm_roberta/modeling_xlm_roberta.py:789\u001b[39m, in \u001b[36mXLMRobertaModel.forward\u001b[39m\u001b[34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001b[39m\n\u001b[32m    786\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    787\u001b[39m         token_type_ids = torch.zeros(input_shape, dtype=torch.long, device=device)\n\u001b[32m--> \u001b[39m\u001b[32m789\u001b[39m embedding_output = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43membeddings\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    790\u001b[39m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    791\u001b[39m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    792\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    793\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    794\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpast_key_values_length\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpast_key_values_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    795\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    797\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m attention_mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    798\u001b[39m     attention_mask = torch.ones((batch_size, seq_length + past_key_values_length), device=device)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/vscode_projects/NLP/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/vscode_projects/NLP/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/vscode_projects/NLP/.venv/lib/python3.13/site-packages/transformers/models/xlm_roberta/modeling_xlm_roberta.py:111\u001b[39m, in \u001b[36mXLMRobertaEmbeddings.forward\u001b[39m\u001b[34m(self, input_ids, token_type_ids, position_ids, inputs_embeds, past_key_values_length)\u001b[39m\n\u001b[32m    108\u001b[39m         token_type_ids = torch.zeros(input_shape, dtype=torch.long, device=\u001b[38;5;28mself\u001b[39m.position_ids.device)\n\u001b[32m    110\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m inputs_embeds \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m111\u001b[39m     inputs_embeds = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mword_embeddings\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    112\u001b[39m token_type_embeddings = \u001b[38;5;28mself\u001b[39m.token_type_embeddings(token_type_ids)\n\u001b[32m    114\u001b[39m embeddings = inputs_embeds + token_type_embeddings\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/vscode_projects/NLP/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/vscode_projects/NLP/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/vscode_projects/NLP/.venv/lib/python3.13/site-packages/torch/nn/modules/sparse.py:192\u001b[39m, in \u001b[36mEmbedding.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    191\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) -> Tensor:\n\u001b[32m--> \u001b[39m\u001b[32m192\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    193\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    194\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    195\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    196\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmax_norm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    197\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mnorm_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    198\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    199\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    200\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/vscode_projects/NLP/.venv/lib/python3.13/site-packages/torch/nn/functional.py:2542\u001b[39m, in \u001b[36membedding\u001b[39m\u001b[34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[39m\n\u001b[32m   2536\u001b[39m     \u001b[38;5;66;03m# Note [embedding_renorm set_grad_enabled]\u001b[39;00m\n\u001b[32m   2537\u001b[39m     \u001b[38;5;66;03m# XXX: equivalent to\u001b[39;00m\n\u001b[32m   2538\u001b[39m     \u001b[38;5;66;03m# with torch.no_grad():\u001b[39;00m\n\u001b[32m   2539\u001b[39m     \u001b[38;5;66;03m#   torch.embedding_renorm_\u001b[39;00m\n\u001b[32m   2540\u001b[39m     \u001b[38;5;66;03m# remove once script supports set_grad_enabled\u001b[39;00m\n\u001b[32m   2541\u001b[39m     _no_grad_embedding_renorm_(weight, \u001b[38;5;28minput\u001b[39m, max_norm, norm_type)\n\u001b[32m-> \u001b[39m\u001b[32m2542\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msparse\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mRuntimeError\u001b[39m: Placeholder storage has not been allocated on MPS device!"
     ]
    }
   ],
   "source": [
    "def evaluate_lang_performance(lang, trainer):\n",
    "    panx_ds = encode_panx_dataset(panx_ch[lang])\n",
    "    return get_f1_score(trainer, panx_ds[\"test\"])\n",
    "     \n",
    "f1_scores[\"de\"][\"fr\"] = evaluate_lang_performance(\"fr\", trainer)\n",
    "print(f\"F1-score of [de] model on [fr] dataset: {f1_scores['de']['fr']:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "a1b03ffb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20d7945c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_on_subset(dataset, num_samples):\n",
    "    train_ds = dataset[\"train\"].shuffle(seed=42).select(range(num_samples))\n",
    "    valid_ds = dataset[\"validation\"]\n",
    "    test_ds = dataset[\"test\"]\n",
    "    training_args.logging_steps = len(train_ds) // batch_size\n",
    "    \n",
    "    trainer = Trainer(model_init=model_init, args=training_args,\n",
    "        data_collator=data_collator, compute_metrics=compute_metrics,\n",
    "        train_dataset=train_ds, eval_dataset=valid_ds, processing_class=xlmr_tokenizer)\n",
    "    trainer.train()\n",
    "    \n",
    "    # Get best validation F1 score from training history\n",
    "    \n",
    "    f1 = get_f1_score(trainer, test_ds)\n",
    "    \n",
    "    if training_args.push_to_hub:\n",
    "        trainer.push_to_hub(commit_message=\"Training completed!\")\n",
    "    \n",
    "    return pd.DataFrame.from_dict(\n",
    "        {\"num_samples\": [len(train_ds)], \"f1_score\": [f1]})\n",
    "     \n",
    "\n",
    "# hide_output\n",
    "panx_fr_encoded = encode_panx_dataset(panx_ch[\"fr\"])\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "78324701",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 4580\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 2290\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 2290\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "panx_fr_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "502ba8b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nurma/vscode_projects/NLP/.venv/lib/python3.13/site-packages/torch/utils/data/dataloader.py:692: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='32' max='32' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [32/32 00:27, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.116800</td>\n",
       "      <td>0.454532</td>\n",
       "      <td>0.790721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.065100</td>\n",
       "      <td>0.486820</td>\n",
       "      <td>0.790806</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nurma/vscode_projects/NLP/.venv/lib/python3.13/site-packages/torch/utils/data/dataloader.py:692: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_samples</th>\n",
       "      <th>f1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>250</td>\n",
       "      <td>0.790806</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   num_samples  f1_score\n",
       "0          250  0.790806"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_args.push_to_hub = False\n",
    "metrics_df = train_on_subset(panx_fr_encoded, 250)\n",
    "metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "112ed910",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'append'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[32m/var/folders/nw/yjct11rn2lq_yqyn7t95tx0w0000gn/T/ipykernel_1161/2897586078.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m num_samples \u001b[38;5;28;01min\u001b[39;00m [\u001b[32m500\u001b[39m, \u001b[32m1000\u001b[39m, \u001b[32m2000\u001b[39m, \u001b[32m4000\u001b[39m]:\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m     metrics_df = metrics_df.append(\n\u001b[32m      3\u001b[39m         train_on_subset(panx_fr_encoded, num_samples), ignore_index=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[32m~/vscode_projects/NLP/.venv/lib/python3.13/site-packages/pandas/core/generic.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, name)\u001b[39m\n\u001b[32m   6317\u001b[39m             \u001b[38;5;28;01mand\u001b[39;00m name \u001b[38;5;28;01mnot\u001b[39;00m \u001b[38;5;28;01min\u001b[39;00m self._accessors\n\u001b[32m   6318\u001b[39m             \u001b[38;5;28;01mand\u001b[39;00m self._info_axis._can_hold_identifiers_and_holds_name(name)\n\u001b[32m   6319\u001b[39m         ):\n\u001b[32m   6320\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m self[name]\n\u001b[32m-> \u001b[39m\u001b[32m6321\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m object.__getattribute__(self, name)\n",
      "\u001b[31mAttributeError\u001b[39m: 'DataFrame' object has no attribute 'append'"
     ]
    }
   ],
   "source": [
    "for num_samples in [500, 1000, 2000, 4000]:\n",
    "    metrics_df = metrics_df.append(\n",
    "        train_on_subset(panx_fr_encoded, num_samples), ignore_index=True)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e65c386",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NLP_for_transformers (3.13.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "30fe2f02",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nurma/vscode_projects/NLP/.venv/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(183,\n",
       " ['MLQA.ar.ar',\n",
       "  'MLQA.ar.de',\n",
       "  'MLQA.ar.en',\n",
       "  'MLQA.ar.es',\n",
       "  'MLQA.ar.hi',\n",
       "  'MLQA.ar.vi',\n",
       "  'MLQA.ar.zh',\n",
       "  'MLQA.de.ar',\n",
       "  'MLQA.de.de',\n",
       "  'MLQA.de.en',\n",
       "  'MLQA.de.es',\n",
       "  'MLQA.de.hi',\n",
       "  'MLQA.de.vi',\n",
       "  'MLQA.de.zh',\n",
       "  'MLQA.en.ar',\n",
       "  'MLQA.en.de',\n",
       "  'MLQA.en.en',\n",
       "  'MLQA.en.es',\n",
       "  'MLQA.en.hi',\n",
       "  'MLQA.en.vi',\n",
       "  'MLQA.en.zh',\n",
       "  'MLQA.es.ar',\n",
       "  'MLQA.es.de',\n",
       "  'MLQA.es.en',\n",
       "  'MLQA.es.es',\n",
       "  'MLQA.es.hi',\n",
       "  'MLQA.es.vi',\n",
       "  'MLQA.es.zh',\n",
       "  'MLQA.hi.ar',\n",
       "  'MLQA.hi.de',\n",
       "  'MLQA.hi.en',\n",
       "  'MLQA.hi.es',\n",
       "  'MLQA.hi.hi',\n",
       "  'MLQA.hi.vi',\n",
       "  'MLQA.hi.zh',\n",
       "  'MLQA.vi.ar',\n",
       "  'MLQA.vi.de',\n",
       "  'MLQA.vi.en',\n",
       "  'MLQA.vi.es',\n",
       "  'MLQA.vi.hi',\n",
       "  'MLQA.vi.vi',\n",
       "  'MLQA.vi.zh',\n",
       "  'MLQA.zh.ar',\n",
       "  'MLQA.zh.de',\n",
       "  'MLQA.zh.en',\n",
       "  'MLQA.zh.es',\n",
       "  'MLQA.zh.hi',\n",
       "  'MLQA.zh.vi',\n",
       "  'MLQA.zh.zh',\n",
       "  'PAN-X.af',\n",
       "  'PAN-X.ar',\n",
       "  'PAN-X.bg',\n",
       "  'PAN-X.bn',\n",
       "  'PAN-X.de',\n",
       "  'PAN-X.el',\n",
       "  'PAN-X.en',\n",
       "  'PAN-X.es',\n",
       "  'PAN-X.et',\n",
       "  'PAN-X.eu',\n",
       "  'PAN-X.fa',\n",
       "  'PAN-X.fi',\n",
       "  'PAN-X.fr',\n",
       "  'PAN-X.he',\n",
       "  'PAN-X.hi',\n",
       "  'PAN-X.hu',\n",
       "  'PAN-X.id',\n",
       "  'PAN-X.it',\n",
       "  'PAN-X.ja',\n",
       "  'PAN-X.jv',\n",
       "  'PAN-X.ka',\n",
       "  'PAN-X.kk',\n",
       "  'PAN-X.ko',\n",
       "  'PAN-X.ml',\n",
       "  'PAN-X.mr',\n",
       "  'PAN-X.ms',\n",
       "  'PAN-X.my',\n",
       "  'PAN-X.nl',\n",
       "  'PAN-X.pt',\n",
       "  'PAN-X.ru',\n",
       "  'PAN-X.sw',\n",
       "  'PAN-X.ta',\n",
       "  'PAN-X.te',\n",
       "  'PAN-X.th',\n",
       "  'PAN-X.tl',\n",
       "  'PAN-X.tr',\n",
       "  'PAN-X.ur',\n",
       "  'PAN-X.vi',\n",
       "  'PAN-X.yo',\n",
       "  'PAN-X.zh',\n",
       "  'PAWS-X.de',\n",
       "  'PAWS-X.en',\n",
       "  'PAWS-X.es',\n",
       "  'PAWS-X.fr',\n",
       "  'PAWS-X.ja',\n",
       "  'PAWS-X.ko',\n",
       "  'PAWS-X.zh',\n",
       "  'SQuAD',\n",
       "  'XNLI',\n",
       "  'XQuAD.ar',\n",
       "  'XQuAD.de',\n",
       "  'XQuAD.el',\n",
       "  'XQuAD.en',\n",
       "  'XQuAD.es',\n",
       "  'XQuAD.hi',\n",
       "  'XQuAD.ru',\n",
       "  'XQuAD.th',\n",
       "  'XQuAD.tr',\n",
       "  'XQuAD.vi',\n",
       "  'XQuAD.zh',\n",
       "  'bucc18.de',\n",
       "  'bucc18.fr',\n",
       "  'bucc18.ru',\n",
       "  'bucc18.zh',\n",
       "  'tatoeba.afr',\n",
       "  'tatoeba.ara',\n",
       "  'tatoeba.ben',\n",
       "  'tatoeba.bul',\n",
       "  'tatoeba.cmn',\n",
       "  'tatoeba.deu',\n",
       "  'tatoeba.ell',\n",
       "  'tatoeba.est',\n",
       "  'tatoeba.eus',\n",
       "  'tatoeba.fin',\n",
       "  'tatoeba.fra',\n",
       "  'tatoeba.heb',\n",
       "  'tatoeba.hin',\n",
       "  'tatoeba.hun',\n",
       "  'tatoeba.ind',\n",
       "  'tatoeba.ita',\n",
       "  'tatoeba.jav',\n",
       "  'tatoeba.jpn',\n",
       "  'tatoeba.kat',\n",
       "  'tatoeba.kaz',\n",
       "  'tatoeba.kor',\n",
       "  'tatoeba.mal',\n",
       "  'tatoeba.mar',\n",
       "  'tatoeba.nld',\n",
       "  'tatoeba.pes',\n",
       "  'tatoeba.por',\n",
       "  'tatoeba.rus',\n",
       "  'tatoeba.spa',\n",
       "  'tatoeba.swh',\n",
       "  'tatoeba.tam',\n",
       "  'tatoeba.tel',\n",
       "  'tatoeba.tgl',\n",
       "  'tatoeba.tha',\n",
       "  'tatoeba.tur',\n",
       "  'tatoeba.urd',\n",
       "  'tatoeba.vie',\n",
       "  'tydiqa',\n",
       "  'udpos.Afrikaans',\n",
       "  'udpos.Arabic',\n",
       "  'udpos.Basque',\n",
       "  'udpos.Bulgarian',\n",
       "  'udpos.Chinese',\n",
       "  'udpos.Dutch',\n",
       "  'udpos.English',\n",
       "  'udpos.Estonian',\n",
       "  'udpos.Finnish',\n",
       "  'udpos.French',\n",
       "  'udpos.German',\n",
       "  'udpos.Greek',\n",
       "  'udpos.Hebrew',\n",
       "  'udpos.Hindi',\n",
       "  'udpos.Hungarian',\n",
       "  'udpos.Indonesian',\n",
       "  'udpos.Italian',\n",
       "  'udpos.Japanese',\n",
       "  'udpos.Kazakh',\n",
       "  'udpos.Korean',\n",
       "  'udpos.Marathi',\n",
       "  'udpos.Persian',\n",
       "  'udpos.Portuguese',\n",
       "  'udpos.Russian',\n",
       "  'udpos.Spanish',\n",
       "  'udpos.Tagalog',\n",
       "  'udpos.Tamil',\n",
       "  'udpos.Telugu',\n",
       "  'udpos.Thai',\n",
       "  'udpos.Turkish',\n",
       "  'udpos.Urdu',\n",
       "  'udpos.Vietnamese',\n",
       "  'udpos.Yoruba'])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import get_dataset_config_names\n",
    "\n",
    "xtreme_subsets = get_dataset_config_names(\"xtreme\")\n",
    "len(xtreme_subsets), xtreme_subsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "627389d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['PAN-X.af',\n",
       " 'PAN-X.ar',\n",
       " 'PAN-X.bg',\n",
       " 'PAN-X.bn',\n",
       " 'PAN-X.de',\n",
       " 'PAN-X.el',\n",
       " 'PAN-X.en',\n",
       " 'PAN-X.es',\n",
       " 'PAN-X.et',\n",
       " 'PAN-X.eu',\n",
       " 'PAN-X.fa',\n",
       " 'PAN-X.fi',\n",
       " 'PAN-X.fr',\n",
       " 'PAN-X.he',\n",
       " 'PAN-X.hi',\n",
       " 'PAN-X.hu',\n",
       " 'PAN-X.id',\n",
       " 'PAN-X.it',\n",
       " 'PAN-X.ja',\n",
       " 'PAN-X.jv',\n",
       " 'PAN-X.ka',\n",
       " 'PAN-X.kk',\n",
       " 'PAN-X.ko',\n",
       " 'PAN-X.ml',\n",
       " 'PAN-X.mr',\n",
       " 'PAN-X.ms',\n",
       " 'PAN-X.my',\n",
       " 'PAN-X.nl',\n",
       " 'PAN-X.pt',\n",
       " 'PAN-X.ru',\n",
       " 'PAN-X.sw',\n",
       " 'PAN-X.ta',\n",
       " 'PAN-X.te',\n",
       " 'PAN-X.th',\n",
       " 'PAN-X.tl',\n",
       " 'PAN-X.tr',\n",
       " 'PAN-X.ur',\n",
       " 'PAN-X.vi',\n",
       " 'PAN-X.yo',\n",
       " 'PAN-X.zh']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "panx_subsets = [i for i in xtreme_subsets if i.startswith(\"PAN\") ]\n",
    "panx_subsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb80d8a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['PAN-X.kk']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[pan for pan in panx_subsets if pan[-2:] == \"kk\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "94a101e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['tokens', 'ner_tags', 'langs'],\n",
       "        num_rows: 1000\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['tokens', 'ner_tags', 'langs'],\n",
       "        num_rows: 1000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['tokens', 'ner_tags', 'langs'],\n",
       "        num_rows: 1000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "panx_kk = load_dataset(\"xtreme\", name=\"PAN-X.kk\")\n",
    "panx_kk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "be45ca13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tokens': [['АЙДАУ', 'Ауыр', 'атлетикадан', 'әлем', 'чемпионаты', '2013'],\n",
       "  ['``', 'Қазақфильм', \"''\", 'киностудиясы', 'шығарған', '.'],\n",
       "  ['ҚР', 'Сыртқы', 'істер', 'министрлігі'],\n",
       "  [\"'\", \"''\", 'Ербаш', \"''\", \"'\", '—', 'Ресейдегі', 'өзен', '.'],\n",
       "  ['Даг', 'Хаммаршельд', '(', 'посмертно', ')']],\n",
       " 'ner_tags': [[0, 3, 4, 4, 4, 4],\n",
       "  [0, 3, 0, 0, 0, 0],\n",
       "  [3, 4, 4, 4],\n",
       "  [0, 0, 0, 0, 0, 0, 5, 0, 0],\n",
       "  [1, 2, 0, 0, 0]],\n",
       " 'langs': [['kk', 'kk', 'kk', 'kk', 'kk', 'kk'],\n",
       "  ['kk', 'kk', 'kk', 'kk', 'kk', 'kk'],\n",
       "  ['kk', 'kk', 'kk', 'kk'],\n",
       "  ['kk', 'kk', 'kk', 'kk', 'kk', 'kk', 'kk', 'kk', 'kk'],\n",
       "  ['kk', 'kk', 'kk', 'kk', 'kk']]}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "panx_kk[\"train\"][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "382e015d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tokens': [['Илизаров', ',', 'Гавриил', 'Абрамович'],\n",
       "  [\"'\", \"''\", 'Рыбницкий', 'район', \"''\", \"'\"],\n",
       "  ['За',\n",
       "   'образцовое',\n",
       "   'выполнение',\n",
       "   'заданий',\n",
       "   'командования',\n",
       "   'в',\n",
       "   'боях',\n",
       "   'с',\n",
       "   'немецкими',\n",
       "   'захватчиками',\n",
       "   ',',\n",
       "   'за',\n",
       "   'овладение',\n",
       "   'городом',\n",
       "   'Демблин',\n",
       "   'и',\n",
       "   'проявленные',\n",
       "   'при',\n",
       "   'этом',\n",
       "   'доблесть',\n",
       "   'и',\n",
       "   'мужество',\n",
       "   '.'],\n",
       "  ['Стадион', 'имени', 'С.', 'Дарюса', 'и', 'С.', 'Гиренаса'],\n",
       "  ['Майкл', 'Томас', '(', '1987—1991', ')']],\n",
       " 'ner_tags': [[1, 2, 2, 2],\n",
       "  [0, 0, 5, 6, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [5, 6, 6, 6, 6, 6, 6],\n",
       "  [1, 2, 0, 0, 0]],\n",
       " 'langs': [['ru', 'ru', 'ru', 'ru'],\n",
       "  ['ru', 'ru', 'ru', 'ru', 'ru', 'ru'],\n",
       "  ['ru',\n",
       "   'ru',\n",
       "   'ru',\n",
       "   'ru',\n",
       "   'ru',\n",
       "   'ru',\n",
       "   'ru',\n",
       "   'ru',\n",
       "   'ru',\n",
       "   'ru',\n",
       "   'ru',\n",
       "   'ru',\n",
       "   'ru',\n",
       "   'ru',\n",
       "   'ru',\n",
       "   'ru',\n",
       "   'ru',\n",
       "   'ru',\n",
       "   'ru',\n",
       "   'ru',\n",
       "   'ru',\n",
       "   'ru',\n",
       "   'ru'],\n",
       "  ['ru', 'ru', 'ru', 'ru', 'ru', 'ru', 'ru'],\n",
       "  ['ru', 'ru', 'ru', 'ru', 'ru']]}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "panx_ru = load_dataset(\"xtreme\", name=\"PAN-X.ru\")\n",
    "panx_ru[\"train\"][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "064a7193",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tokens': ['Жак', 'Дерриданың', 'деконструкция', 'ілімі', ';'],\n",
       " 'ner_tags': [1, 2, 0, 0, 0],\n",
       " 'langs': ['kk', 'kk', 'kk', 'kk', 'kk']}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "panx_kk[\"train\"][12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "791af4f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from datasets import DatasetDict\n",
    "\n",
    "langs = [\"de\", \"fr\", \"it\", \"en\"]\n",
    "fracs = [0.629, 0.229, 0.084, 0.059]\n",
    "# Return a DatasetDict if a key doesn't exist\n",
    "panx_ch = defaultdict(DatasetDict)\n",
    "\n",
    "for lang, frac in zip(langs, fracs):\n",
    "    # Load monolingual corpus\n",
    "    ds = load_dataset(\"xtreme\", name=f\"PAN-X.{lang}\")\n",
    "    # Shuffle and downsample each split according to spoken proportion\n",
    "    for split in ds:\n",
    "        panx_ch[lang][split] = (\n",
    "            ds[split]\n",
    "            .shuffle(seed=0)\n",
    "            .select(range(int(frac * ds[split].num_rows))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2d6e34e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "validation\n",
      "test\n"
     ]
    }
   ],
   "source": [
    "for i in panx_kk:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3af2fb52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['de', 'fr', 'it', 'en']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "langs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5ff13801",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>de</th>\n",
       "      <th>fr</th>\n",
       "      <th>it</th>\n",
       "      <th>en</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Number of training examples</th>\n",
       "      <td>12580</td>\n",
       "      <td>4580</td>\n",
       "      <td>1680</td>\n",
       "      <td>1180</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                de    fr    it    en\n",
       "Number of training examples  12580  4580  1680  1180"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.DataFrame({lang: [panx_ch[lang][\"train\"].num_rows] for lang in langs}, index=[\"Number of training examples\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a91c0f0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['tokens', 'ner_tags', 'langs'],\n",
       "        num_rows: 1180\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['tokens', 'ner_tags', 'langs'],\n",
       "        num_rows: 590\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['tokens', 'ner_tags', 'langs'],\n",
       "        num_rows: 590\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "panx_ch[\"en\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "00816a41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokens: ['2.000', 'Einwohnern', 'an', 'der', 'Danziger', 'Bucht', 'in', 'der', 'polnischen', 'Woiwodschaft', 'Pommern', '.']\n",
      "ner_tags: [0, 0, 0, 0, 5, 6, 0, 0, 5, 5, 6, 0]\n",
      "langs: ['de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "element = panx_ch[\"de\"][\"train\"][0]\n",
    "for key, value in element.items():\n",
    "    print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d0e3b61d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokens: List(Value('string'))\n",
      "ner_tags: List(ClassLabel(names=['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC']))\n",
      "langs: List(Value('string'))\n"
     ]
    }
   ],
   "source": [
    "for key, value in panx_ch[\"de\"][\"train\"].features.items():\n",
    "    print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d0df4c49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ClassLabel(names=['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC'])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "tags = panx_ch[\"de\"][\"train\"].features[\"ner_tags\"].feature\n",
    "print(tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9acc3d31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['tokens', 'ner_tags', 'langs', 'ner_tags_str'],\n",
       "        num_rows: 12580\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['tokens', 'ner_tags', 'langs', 'ner_tags_str'],\n",
       "        num_rows: 6290\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['tokens', 'ner_tags', 'langs', 'ner_tags_str'],\n",
       "        num_rows: 6290\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def create_tag_names(batch):\n",
    "    return {\"ner_tags_str\": [tags.int2str(idx) for idx in batch[\"ner_tags\"]]}\n",
    "\n",
    "panx_de = panx_ch[\"de\"].map(create_tag_names)\n",
    "panx_de"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d5c98f40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokens: ['2.000', 'Einwohnern', 'an', 'der', 'Danziger', 'Bucht', 'in', 'der', 'polnischen', 'Woiwodschaft', 'Pommern', '.']\n",
      "ner_tags: [0, 0, 0, 0, 5, 6, 0, 0, 5, 5, 6, 0]\n",
      "langs: ['de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de']\n",
      "ner_tags_str: ['O', 'O', 'O', 'O', 'B-LOC', 'I-LOC', 'O', 'O', 'B-LOC', 'B-LOC', 'I-LOC', 'O']\n"
     ]
    }
   ],
   "source": [
    "for key, value in panx_de[\"train\"][0].items():\n",
    "    print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "24507432",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 0, 5, 6, 0, 0, 5, 5, 6, 0]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "panx_de[\"train\"][0][\"ner_tags\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "23cfea35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ClassLabel(names=['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC'])\n"
     ]
    }
   ],
   "source": [
    "tags_en = panx_ch[\"en\"][\"train\"].features[\"ner_tags\"].feature\n",
    "print(tags_en)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8f98ee9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['tokens', 'ner_tags', 'langs', 'ner_tags_str'],\n",
       "        num_rows: 1180\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['tokens', 'ner_tags', 'langs', 'ner_tags_str'],\n",
       "        num_rows: 590\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['tokens', 'ner_tags', 'langs', 'ner_tags_str'],\n",
       "        num_rows: 590\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def create_tag_names(batch):\n",
    "    return {\"ner_tags_str\": [tags_en.int2str(idx) for idx in batch[\"ner_tags\"]]}\n",
    "\n",
    "panx_en = panx_ch[\"en\"].map(create_tag_names)\n",
    "panx_en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "74d892a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokens: ['Vaivara', 'concentration', 'camp', ',', 'Vaivara', '(', \"''1943–1944\", ',', 'during', 'German', 'occupation', \"''\", ')']\n",
      "ner_tags: [5, 6, 6, 0, 5, 0, 0, 0, 0, 3, 4, 0, 0]\n",
      "langs: ['en', 'en', 'en', 'en', 'en', 'en', 'en', 'en', 'en', 'en', 'en', 'en', 'en']\n",
      "ner_tags_str: ['B-LOC', 'I-LOC', 'I-LOC', 'O', 'B-LOC', 'O', 'O', 'O', 'O', 'B-ORG', 'I-ORG', 'O', 'O']\n"
     ]
    }
   ],
   "source": [
    "for key, value in panx_en[\"train\"][2].items():\n",
    "    print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "62044014",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Tokens</th>\n",
       "      <td>2.000</td>\n",
       "      <td>Einwohnern</td>\n",
       "      <td>an</td>\n",
       "      <td>der</td>\n",
       "      <td>Danziger</td>\n",
       "      <td>Bucht</td>\n",
       "      <td>in</td>\n",
       "      <td>der</td>\n",
       "      <td>polnischen</td>\n",
       "      <td>Woiwodschaft</td>\n",
       "      <td>Pommern</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tags</th>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>B-LOC</td>\n",
       "      <td>I-LOC</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>B-LOC</td>\n",
       "      <td>B-LOC</td>\n",
       "      <td>I-LOC</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           0           1   2    3         4      5   6    7           8   \\\n",
       "Tokens  2.000  Einwohnern  an  der  Danziger  Bucht  in  der  polnischen   \n",
       "Tags        O           O   O    O     B-LOC  I-LOC   O    O       B-LOC   \n",
       "\n",
       "                  9        10 11  \n",
       "Tokens  Woiwodschaft  Pommern  .  \n",
       "Tags           B-LOC    I-LOC  O  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "de_example = panx_de[\"train\"][0]\n",
    "pd.DataFrame([de_example[\"tokens\"], de_example[\"ner_tags_str\"]],\n",
    "['Tokens', 'Tags'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "687faeba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LOC</th>\n",
       "      <th>ORG</th>\n",
       "      <th>PER</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>train</th>\n",
       "      <td>6186</td>\n",
       "      <td>5366</td>\n",
       "      <td>5810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>validation</th>\n",
       "      <td>3172</td>\n",
       "      <td>2683</td>\n",
       "      <td>2893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test</th>\n",
       "      <td>3180</td>\n",
       "      <td>2573</td>\n",
       "      <td>3071</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             LOC   ORG   PER\n",
       "train       6186  5366  5810\n",
       "validation  3172  2683  2893\n",
       "test        3180  2573  3071"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from collections import Counter\n",
    "\n",
    "split2freqs = defaultdict(Counter)\n",
    "for split, dataset in panx_de.items():\n",
    "    for row in dataset[\"ner_tags_str\"]:\n",
    "        for tag in row:\n",
    "            if tag.startswith(\"B\"):\n",
    "                tag_type = tag.split(\"-\")[1]\n",
    "                split2freqs[split][tag_type] += 1\n",
    "pd.DataFrame.from_dict(split2freqs, orient=\"index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bab70f6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(collections.Counter,\n",
       "            {'train': Counter({'LOC': 6186, 'PER': 5810, 'ORG': 5366}),\n",
       "             'validation': Counter({'LOC': 3172, 'PER': 2893, 'ORG': 2683}),\n",
       "             'test': Counter({'LOC': 3180, 'PER': 3071, 'ORG': 2573})})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split2freqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8a1fb596",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "bert_model_name = \"bert-base-cased\"\n",
    "xlmr_model_name = \"xlm-roberta-base\"\n",
    "bert_tokenizer = AutoTokenizer.from_pretrained(bert_model_name)\n",
    "xlmr_tokenizer = AutoTokenizer.from_pretrained(xlmr_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8cbfe8cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XLMRobertaTokenizerFast(name_or_path='xlm-roberta-base', vocab_size=250002, model_max_length=512, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<s>', 'eos_token': '</s>', 'unk_token': '<unk>', 'sep_token': '</s>', 'pad_token': '<pad>', 'cls_token': '<s>', 'mask_token': '<mask>'}, clean_up_tokenization_spaces=False, added_tokens_decoder={\n",
       "\t0: AddedToken(\"<s>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t1: AddedToken(\"<pad>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t2: AddedToken(\"</s>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t3: AddedToken(\"<unk>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t250001: AddedToken(\"<mask>\", rstrip=False, lstrip=True, single_word=False, normalized=False, special=True),\n",
       "}\n",
       ")"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xlmr_tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2e8d431a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'unk_token': '[UNK]',\n",
       " 'sep_token': '[SEP]',\n",
       " 'pad_token': '[PAD]',\n",
       " 'cls_token': '[CLS]',\n",
       " 'mask_token': '[MASK]'}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_tokenizer.special_tokens_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f4bb0602",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bos_token': '<s>',\n",
       " 'eos_token': '</s>',\n",
       " 'unk_token': '<unk>',\n",
       " 'sep_token': '</s>',\n",
       " 'pad_token': '<pad>',\n",
       " 'cls_token': '<s>',\n",
       " 'mask_token': '<mask>'}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xlmr_tokenizer.special_tokens_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "665c4a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Jack Sparrow loves New York!\"\n",
    "bert_tokens = bert_tokenizer(text).tokens()\n",
    "xlmr_tokens = xlmr_tokenizer(text).tokens()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "eda1979a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[CLS]', 'Jack', 'Spa', '##rrow', 'loves', 'New', 'York', '!', '[SEP]']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "01f0fe94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<s>', '▁Jack', '▁Spar', 'row', '▁love', 's', '▁New', '▁York', '!', '</s>']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xlmr_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "337bda00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<s>▁Jack▁Sparrow▁loves▁New▁York!</s>'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\".join(xlmr_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "47cda699",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<s> Jack Sparrow loves New York!</s>'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\".join(xlmr_tokens).replace(u\"\\u2581\", \" \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "09643af0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[CLS]JackSpa##rrowlovesNewYork![SEP]'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\".join(bert_tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1047557a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from transformers import XLMRobertaConfig\n",
    "from transformers.modeling_outputs import TokenClassifierOutput\n",
    "from transformers.models.roberta.modeling_roberta import RobertaModel\n",
    "from transformers.models.roberta.modeling_roberta import RobertaPreTrainedModel\n",
    "\n",
    "class XLMRobertaForTokenClassification(RobertaPreTrainedModel):\n",
    "    config_class = XLMRobertaConfig\n",
    "\n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "        self.num_labels = config.num_labels\n",
    "        # Load model body\n",
    "        self.roberta = RobertaModel(config, add_pooling_layer=False)\n",
    "        # Set up token classification head\n",
    "        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
    "        self.classifier = nn.Linear(config.hidden_size, config.num_labels)\n",
    "        # Load and initialize weights\n",
    "        self.init_weights()\n",
    "\n",
    "    def forward(self, input_ids=None, attention_mask=None, token_type_ids=None, \n",
    "                labels=None, **kwargs):\n",
    "        # Use model body to get encoder representations\n",
    "        outputs = self.roberta(input_ids, attention_mask=attention_mask,\n",
    "                               token_type_ids=token_type_ids, **kwargs)\n",
    "        # Apply classifier to encoder representation\n",
    "        sequence_output = self.dropout(outputs[0])\n",
    "        logits = self.classifier(sequence_output)\n",
    "        # Calculate losses\n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "            loss_fct = nn.CrossEntropyLoss()\n",
    "            loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1))\n",
    "        # Return model output object\n",
    "        return TokenClassifierOutput(loss=loss, logits=logits, \n",
    "                                     hidden_states=outputs.hidden_states, \n",
    "                                     attentions=outputs.attentions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "374e4cc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ClassLabel(names=['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC'])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "bd410340",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags.num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "650af991",
   "metadata": {},
   "outputs": [],
   "source": [
    "index2tag = {idx: tag for idx, tag in enumerate(tags.names)}\n",
    "tag2index = {tag: idx for idx, tag in enumerate(tags.names)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ed55aa0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XLMRobertaConfig {\n",
       "  \"architectures\": [\n",
       "    \"XLMRobertaForMaskedLM\"\n",
       "  ],\n",
       "  \"attention_probs_dropout_prob\": 0.1,\n",
       "  \"bos_token_id\": 0,\n",
       "  \"classifier_dropout\": null,\n",
       "  \"eos_token_id\": 2,\n",
       "  \"hidden_act\": \"gelu\",\n",
       "  \"hidden_dropout_prob\": 0.1,\n",
       "  \"hidden_size\": 768,\n",
       "  \"id2label\": {\n",
       "    \"0\": \"O\",\n",
       "    \"1\": \"B-PER\",\n",
       "    \"2\": \"I-PER\",\n",
       "    \"3\": \"B-ORG\",\n",
       "    \"4\": \"I-ORG\",\n",
       "    \"5\": \"B-LOC\",\n",
       "    \"6\": \"I-LOC\"\n",
       "  },\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"intermediate_size\": 3072,\n",
       "  \"label2id\": {\n",
       "    \"B-LOC\": 5,\n",
       "    \"B-ORG\": 3,\n",
       "    \"B-PER\": 1,\n",
       "    \"I-LOC\": 6,\n",
       "    \"I-ORG\": 4,\n",
       "    \"I-PER\": 2,\n",
       "    \"O\": 0\n",
       "  },\n",
       "  \"layer_norm_eps\": 1e-05,\n",
       "  \"max_position_embeddings\": 514,\n",
       "  \"model_type\": \"xlm-roberta\",\n",
       "  \"num_attention_heads\": 12,\n",
       "  \"num_hidden_layers\": 12,\n",
       "  \"output_past\": true,\n",
       "  \"pad_token_id\": 1,\n",
       "  \"position_embedding_type\": \"absolute\",\n",
       "  \"transformers_version\": \"4.57.3\",\n",
       "  \"type_vocab_size\": 1,\n",
       "  \"use_cache\": true,\n",
       "  \"vocab_size\": 250002\n",
       "}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoConfig\n",
    "\n",
    "xlmr_config = AutoConfig.from_pretrained(xlmr_model_name,\n",
    "                                         num_labels=tags.num_classes,\n",
    "                                         id2label=index2tag,\n",
    "                                         label2id=tag2index)\n",
    "xlmr_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "5013c201",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "xlmr_model1 = XLMRobertaForTokenClassification.from_pretrained(xlmr_model_name ,config=xlmr_config).to(device)\n",
    "xlmr_model2 = XLMRobertaForTokenClassification(config=xlmr_config).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c9514357",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Tokens</th>\n",
       "      <td>&lt;s&gt;</td>\n",
       "      <td>▁Jack</td>\n",
       "      <td>▁Spar</td>\n",
       "      <td>row</td>\n",
       "      <td>▁love</td>\n",
       "      <td>s</td>\n",
       "      <td>▁New</td>\n",
       "      <td>▁York</td>\n",
       "      <td>!</td>\n",
       "      <td>&lt;/s&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Input IDs</th>\n",
       "      <td>0</td>\n",
       "      <td>33600</td>\n",
       "      <td>31</td>\n",
       "      <td>759</td>\n",
       "      <td>9351</td>\n",
       "      <td>83</td>\n",
       "      <td>10772</td>\n",
       "      <td>6614</td>\n",
       "      <td>2</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             0      1      2    3      4   5      6      7  8     9\n",
       "Tokens     <s>  ▁Jack  ▁Spar  row  ▁love   s   ▁New  ▁York  !  </s>\n",
       "Input IDs    0  33600     31  759   9351  83  10772   6614  2  None"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids = xlmr_tokenizer.encode(text, return_tensors=\"pt\")\n",
    "\n",
    "pd.DataFrame([xlmr_tokens, input_ids[0].numpy()], index=[\"Tokens\", \"Input IDs\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "bfb78d6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[    0, 33600,    31,   759,  9351,    83, 10772,  6614,     2]])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "c41bc8c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<s>', '▁hell', 'o', '▁my', '▁name', '▁is', '▁Nur', 'eke', '</s>']"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xlmr_tokenizer(text).tokens()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "f9f0dbe2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.1466,  0.4846,  0.1115,  0.3251, -0.5045, -0.4904,  0.3245],\n",
       "         [ 0.5245,  0.4037,  0.1426,  0.0698, -0.4307, -0.6167,  0.4906],\n",
       "         [ 0.3921,  0.2743,  0.1126,  0.0619, -0.4907, -0.5963,  0.5037],\n",
       "         [ 0.4164,  0.3172, -0.0015,  0.0689, -0.4784, -0.7190,  0.5588],\n",
       "         [ 0.6306,  0.2780,  0.0258, -0.1220, -0.5544, -0.7714,  0.5167],\n",
       "         [ 0.5327,  0.3673,  0.1324,  0.0812, -0.4019, -0.6561,  0.5613],\n",
       "         [ 0.4875,  0.5378,  0.0384,  0.0053, -0.5715, -0.6755,  0.5913],\n",
       "         [ 0.4636,  0.4627,  0.0776,  0.0422, -0.5724, -0.5671,  0.5677],\n",
       "         [ 0.1226,  0.4804,  0.1285,  0.3237, -0.5565, -0.4965,  0.3136]]],\n",
       "       grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs = xlmr_model1(input_ids).logits\n",
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "b758278d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 0, 6, 6, 0, 6, 6, 6, 1]])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = outputs.argmax(-1)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "96a66f2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tokens in sequence: 10\n",
      "Shape of outputs: torch.Size([1, 9, 7])\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of tokens in sequence: {len(xlmr_tokens)}\")\n",
    "print(f\"Shape of outputs: {outputs.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "ed06fa45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC']"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags.names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "eee86078",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['B-PER', 'O', 'I-LOC', 'I-LOC', 'O', 'I-LOC', 'I-LOC', 'I-LOC', 'B-PER']"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = [tags.names[p] for p in predictions[0].cpu().numpy()]\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "fdb79006",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Tokens</th>\n",
       "      <td>&lt;s&gt;</td>\n",
       "      <td>▁Jack</td>\n",
       "      <td>▁Spar</td>\n",
       "      <td>row</td>\n",
       "      <td>▁love</td>\n",
       "      <td>s</td>\n",
       "      <td>▁New</td>\n",
       "      <td>▁York</td>\n",
       "      <td>!</td>\n",
       "      <td>&lt;/s&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tags</th>\n",
       "      <td>B-PER</td>\n",
       "      <td>O</td>\n",
       "      <td>I-LOC</td>\n",
       "      <td>I-LOC</td>\n",
       "      <td>O</td>\n",
       "      <td>I-LOC</td>\n",
       "      <td>I-LOC</td>\n",
       "      <td>I-LOC</td>\n",
       "      <td>B-PER</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            0      1      2      3      4      5      6      7      8     9\n",
       "Tokens    <s>  ▁Jack  ▁Spar    row  ▁love      s   ▁New  ▁York      !  </s>\n",
       "Tags    B-PER      O  I-LOC  I-LOC      O  I-LOC  I-LOC  I-LOC  B-PER  None"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame([xlmr_tokens, preds], index=[\"Tokens\", \"Tags\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "61983d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tag_text(text, tags, model,tokenizer):\n",
    "    tokens = tokenizer(text).tokens()\n",
    "    input_ids = xlmr_tokenizer(text, return_tensors=\"pt\").input_ids.to(device)\n",
    "    outputs = model(input_ids)[0]\n",
    "    predictions = outputs.argmax(-1)\n",
    "    preds = [tags.names[p] for p in predictions[0].cpu().numpy()]\n",
    "    return pd.DataFrame([xlmr_tokens, preds], index=[\"Tokens\", \"Tags\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "a51788e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokens: ['2.000', 'Einwohnern', 'an', 'der', 'Danziger', 'Bucht', 'in', 'der', 'polnischen', 'Woiwodschaft', 'Pommern', '.']\n",
      "ner_tags: [0, 0, 0, 0, 5, 6, 0, 0, 5, 5, 6, 0]\n",
      "langs: ['de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de']\n",
      "ner_tags_str: ['O', 'O', 'O', 'O', 'B-LOC', 'I-LOC', 'O', 'O', 'B-LOC', 'B-LOC', 'I-LOC', 'O']\n"
     ]
    }
   ],
   "source": [
    "for key, value in de_example.items():\n",
    "    print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "00e7077f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['2.000',\n",
       "  'Einwohnern',\n",
       "  'an',\n",
       "  'der',\n",
       "  'Danziger',\n",
       "  'Bucht',\n",
       "  'in',\n",
       "  'der',\n",
       "  'polnischen',\n",
       "  'Woiwodschaft',\n",
       "  'Pommern',\n",
       "  '.'],\n",
       " [0, 0, 0, 0, 5, 6, 0, 0, 5, 5, 6, 0])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = de_example[\"tokens\"]\n",
    "labels = de_example[\"ner_tags\"]\n",
    "words, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ad73b4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [0, 70101, 176581, 19, 142, 122, 2290, 708, 1505, 18363, 18, 23, 122, 127474, 15439, 13787, 14, 15263, 18917, 663, 6947, 19, 6, 5, 2], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_input = xlmr_tokenizer(words, is_split_into_words=True)\n",
    "tokenized_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "383121f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Tokens</th>\n",
       "      <td>&lt;s&gt;</td>\n",
       "      <td>▁2.000</td>\n",
       "      <td>▁Einwohner</td>\n",
       "      <td>n</td>\n",
       "      <td>▁an</td>\n",
       "      <td>▁der</td>\n",
       "      <td>▁Dan</td>\n",
       "      <td>zi</td>\n",
       "      <td>ger</td>\n",
       "      <td>▁Buch</td>\n",
       "      <td>...</td>\n",
       "      <td>▁Wo</td>\n",
       "      <td>i</td>\n",
       "      <td>wod</td>\n",
       "      <td>schaft</td>\n",
       "      <td>▁Po</td>\n",
       "      <td>mmer</td>\n",
       "      <td>n</td>\n",
       "      <td>▁</td>\n",
       "      <td>.</td>\n",
       "      <td>&lt;/s&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0       1           2  3    4     5     6   7    8      9   ...   15  \\\n",
       "Tokens  <s>  ▁2.000  ▁Einwohner  n  ▁an  ▁der  ▁Dan  zi  ger  ▁Buch  ...  ▁Wo   \n",
       "\n",
       "       16   17      18   19    20 21 22 23    24  \n",
       "Tokens  i  wod  schaft  ▁Po  mmer  n  ▁  .  </s>  \n",
       "\n",
       "[1 rows x 25 columns]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = xlmr_tokenizer.convert_ids_to_tokens(tokenized_input[\"input_ids\"])\n",
    "pd.DataFrame([tokens],index=[\"Tokens\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "aefd15e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "transformers.tokenization_utils_base.BatchEncoding"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(tokenized_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "fbdc1f46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Tokens</th>\n",
       "      <td>&lt;s&gt;</td>\n",
       "      <td>▁2.000</td>\n",
       "      <td>▁Einwohner</td>\n",
       "      <td>n</td>\n",
       "      <td>▁an</td>\n",
       "      <td>▁der</td>\n",
       "      <td>▁Dan</td>\n",
       "      <td>zi</td>\n",
       "      <td>ger</td>\n",
       "      <td>▁Buch</td>\n",
       "      <td>...</td>\n",
       "      <td>▁Wo</td>\n",
       "      <td>i</td>\n",
       "      <td>wod</td>\n",
       "      <td>schaft</td>\n",
       "      <td>▁Po</td>\n",
       "      <td>mmer</td>\n",
       "      <td>n</td>\n",
       "      <td>▁</td>\n",
       "      <td>.</td>\n",
       "      <td>&lt;/s&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Word ids</th>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0       1           2  3    4     5     6   7    8      9   ...  \\\n",
       "Tokens     <s>  ▁2.000  ▁Einwohner  n  ▁an  ▁der  ▁Dan  zi  ger  ▁Buch  ...   \n",
       "Word ids  None       0           1  1    2     3     4   4    4      5  ...   \n",
       "\n",
       "           15 16   17      18   19    20  21  22  23    24  \n",
       "Tokens    ▁Wo  i  wod  schaft  ▁Po  mmer   n   ▁   .  </s>  \n",
       "Word ids    9  9    9       9   10    10  10  11  11  None  \n",
       "\n",
       "[2 rows x 25 columns]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "pd.DataFrame([tokens,tokenized_input.word_ids()],index=[\"Tokens\",\"Word ids\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "f52dfe64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 0, 5, 6, 0, 0, 5, 5, 6, 0]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "3dbc5285",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-100,\n",
       " 0,\n",
       " 0,\n",
       " -100,\n",
       " 0,\n",
       " 0,\n",
       " 5,\n",
       " -100,\n",
       " -100,\n",
       " 6,\n",
       " -100,\n",
       " 0,\n",
       " 0,\n",
       " 5,\n",
       " -100,\n",
       " 5,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " 6,\n",
       " -100,\n",
       " -100,\n",
       " 0,\n",
       " -100,\n",
       " -100]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "previous_word_idx = None\n",
    "label_ids = []\n",
    "\n",
    "for word_idx in tokenized_input.word_ids():\n",
    "    if word_idx is None or word_idx == previous_word_idx:\n",
    "        label_ids.append(-100)\n",
    "    elif word_idx != previous_word_idx:\n",
    "        label_ids.append(labels[word_idx])\n",
    "    previous_word_idx = word_idx\n",
    "\n",
    "label_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "d92f73d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['IGN',\n",
       " 'O',\n",
       " 'O',\n",
       " 'IGN',\n",
       " 'O',\n",
       " 'O',\n",
       " 'B-LOC',\n",
       " 'IGN',\n",
       " 'IGN',\n",
       " 'I-LOC',\n",
       " 'IGN',\n",
       " 'O',\n",
       " 'O',\n",
       " 'B-LOC',\n",
       " 'IGN',\n",
       " 'B-LOC',\n",
       " 'IGN',\n",
       " 'IGN',\n",
       " 'IGN',\n",
       " 'I-LOC',\n",
       " 'IGN',\n",
       " 'IGN',\n",
       " 'O',\n",
       " 'IGN',\n",
       " 'IGN']"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = [index2tag[l] if l != -100 else \"IGN\" for l in label_ids]\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "41f819fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Tokens</th>\n",
       "      <td>&lt;s&gt;</td>\n",
       "      <td>▁2.000</td>\n",
       "      <td>▁Einwohner</td>\n",
       "      <td>n</td>\n",
       "      <td>▁an</td>\n",
       "      <td>▁der</td>\n",
       "      <td>▁Dan</td>\n",
       "      <td>zi</td>\n",
       "      <td>ger</td>\n",
       "      <td>▁Buch</td>\n",
       "      <td>...</td>\n",
       "      <td>▁Wo</td>\n",
       "      <td>i</td>\n",
       "      <td>wod</td>\n",
       "      <td>schaft</td>\n",
       "      <td>▁Po</td>\n",
       "      <td>mmer</td>\n",
       "      <td>n</td>\n",
       "      <td>▁</td>\n",
       "      <td>.</td>\n",
       "      <td>&lt;/s&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Word IDs</th>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Label IDs</th>\n",
       "      <td>-100</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-100</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>6</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>0</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Labels</th>\n",
       "      <td>IGN</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>IGN</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>B-LOC</td>\n",
       "      <td>IGN</td>\n",
       "      <td>IGN</td>\n",
       "      <td>I-LOC</td>\n",
       "      <td>...</td>\n",
       "      <td>B-LOC</td>\n",
       "      <td>IGN</td>\n",
       "      <td>IGN</td>\n",
       "      <td>IGN</td>\n",
       "      <td>I-LOC</td>\n",
       "      <td>IGN</td>\n",
       "      <td>IGN</td>\n",
       "      <td>O</td>\n",
       "      <td>IGN</td>\n",
       "      <td>IGN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0       1           2     3    4     5      6     7     8   \\\n",
       "Tokens      <s>  ▁2.000  ▁Einwohner     n  ▁an  ▁der   ▁Dan    zi   ger   \n",
       "Word IDs   None       0           1     1    2     3      4     4     4   \n",
       "Label IDs  -100       0           0  -100    0     0      5  -100  -100   \n",
       "Labels      IGN       O           O   IGN    O     O  B-LOC   IGN   IGN   \n",
       "\n",
       "              9   ...     15    16    17      18     19    20    21  22    23  \\\n",
       "Tokens     ▁Buch  ...    ▁Wo     i   wod  schaft    ▁Po  mmer     n   ▁     .   \n",
       "Word IDs       5  ...      9     9     9       9     10    10    10  11    11   \n",
       "Label IDs      6  ...      5  -100  -100    -100      6  -100  -100   0  -100   \n",
       "Labels     I-LOC  ...  B-LOC   IGN   IGN     IGN  I-LOC   IGN   IGN   O   IGN   \n",
       "\n",
       "             24  \n",
       "Tokens     </s>  \n",
       "Word IDs   None  \n",
       "Label IDs  -100  \n",
       "Labels      IGN  \n",
       "\n",
       "[4 rows x 25 columns]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index = [\"Tokens\", \"Word IDs\", \"Label IDs\", \"Labels\"]\n",
    "\n",
    "word_ids = tokenized_input.word_ids()\n",
    "\n",
    "pd.DataFrame([tokens, word_ids, label_ids, labels], index=index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "d53ce79f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets.arrow_dataset import Dataset\n",
    "\n",
    "def tokenize_and_align_labels(examples: Dataset):\n",
    "    tokenized_input = xlmr_tokenizer(examples[\"tokens\"], is_split_into_words=True, truncation=True)\n",
    "    labels = []\n",
    "    for idx, label_row in enumerate(examples[\"ner_tags\"]):\n",
    "        word_ids = tokenized_input.word_ids(batch_index=idx)\n",
    "\n",
    "        previous_word_idx = None\n",
    "        label_ids = []\n",
    "\n",
    "        for word_idx in word_ids:\n",
    "            if word_idx is None or word_idx == previous_word_idx:\n",
    "                label_ids.append(-100)\n",
    "            elif word_idx != previous_word_idx:\n",
    "                label_ids.append(label_row[word_idx])\n",
    "            previous_word_idx = word_idx\n",
    "        labels.append(label_ids)\n",
    "    tokenized_input[\"labels\"] = labels\n",
    "    return tokenized_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "a43795ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 1180\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 590\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 590\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def encode_panx_dataset(corpus):\n",
    "    return corpus.map(tokenize_and_align_labels, batched=True, \n",
    "                      remove_columns=['langs', 'ner_tags', 'tokens'])\n",
    "     \n",
    "panx_en_encoded = encode_panx_dataset(panx_ch[\"en\"])\n",
    "panx_en_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "693d569e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [0, 242, 5106, 90915, 54012, 425, 5106, 242, 2],\n",
       " 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       " 'labels': [-100, 0, 0, 3, 4, -100, 0, 0, -100]}"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "panx_en_encoded[\"train\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "f3f549d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['tokens', 'ner_tags', 'langs', 'ner_tags_str'],\n",
       "        num_rows: 1180\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['tokens', 'ner_tags', 'langs', 'ner_tags_str'],\n",
       "        num_rows: 590\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['tokens', 'ner_tags', 'langs', 'ner_tags_str'],\n",
       "        num_rows: 590\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "panx_en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "22f21156",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Column([[0, 0, 0, 0, 5, 6, 0, 0, 5, 5, 6, 0], [0, 0, 0, 3, 0, 0, 0, 3, 4, 0, 0], [0, 0, 0, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 0], [0, 0, 3, 4, 0, 0], [0, 1, 2, 2, 2]])"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "panx_ch[\"de\"][\"train\"][\"ner_tags\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "3a0872d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datasets.arrow_dataset.Dataset"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(panx_ch[\"de\"][\"train\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "e83838ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [0, 70101, 176581, 19, 142, 122, 2290, 708, 1505, 18363, 18, 23, 122, 127474, 15439, 13787, 14, 15263, 18917, 663, 6947, 19, 6, 5, 2], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_input = xlmr_tokenizer(panx_de[\"train\"][\"tokens\"][0], is_split_into_words=True)\n",
    "tokenized_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "5530283e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'O',\n",
       " 1: 'B-PER',\n",
       " 2: 'I-PER',\n",
       " 3: 'B-ORG',\n",
       " 4: 'I-ORG',\n",
       " 5: 'B-LOC',\n",
       " 6: 'I-LOC'}"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index2tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "cbd276ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<s>',\n",
       " '▁2.000',\n",
       " '▁Einwohner',\n",
       " 'n',\n",
       " '▁an',\n",
       " '▁der',\n",
       " '▁Dan',\n",
       " 'zi',\n",
       " 'ger',\n",
       " '▁Buch',\n",
       " 't',\n",
       " '▁in',\n",
       " '▁der',\n",
       " '▁polni',\n",
       " 'schen',\n",
       " '▁Wo',\n",
       " 'i',\n",
       " 'wod',\n",
       " 'schaft',\n",
       " '▁Po',\n",
       " 'mmer',\n",
       " 'n',\n",
       " '▁',\n",
       " '.',\n",
       " '</s>']"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xlmr_tokenizer.convert_ids_to_tokens(tokenized_input[\"input_ids\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "273c9c2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 70101,\n",
       " 176581,\n",
       " 19,\n",
       " 142,\n",
       " 122,\n",
       " 2290,\n",
       " 708,\n",
       " 1505,\n",
       " 18363,\n",
       " 18,\n",
       " 23,\n",
       " 122,\n",
       " 127474,\n",
       " 15439,\n",
       " 13787,\n",
       " 14,\n",
       " 15263,\n",
       " 18917,\n",
       " 663,\n",
       " 6947,\n",
       " 19,\n",
       " 6,\n",
       " 5,\n",
       " 2]"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_input[\"input_ids\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "be0f0272",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Column([['2.000', 'Einwohnern', 'an', 'der', 'Danziger', 'Bucht', 'in', 'der', 'polnischen', 'Woiwodschaft', 'Pommern', '.'], ['Sie', 'geht', 'hinter', 'Walluf', 'nahtlos', 'in', 'die', 'Bundesautobahn', '66', 'über', '.'], ['Dirigenten', 'von', 'Weltruf', 'wie', 'Wilhelm', 'Furtwängler', ',', 'Erich', 'Kleiber', ',', 'Wolfgang', 'Sawallisch', ',', 'Karl', 'Böhm', ',', 'Herbert', 'von', 'Karajan', ',', 'Rafael', 'Kubelík', ',', 'Erich', 'Kleiber', ',', 'Bernard', 'Haitink', ',', 'Josef', 'Krips', ',', 'Zubin', 'Mehta', ',', 'Dimitri', 'Mitropoulos', ',', 'Antal', 'Doráti', ',', 'Sergiu', 'Celibidache', 'und', 'andere', 'haben', 'seine', 'Werke', 'dirigiert', ',', 'zuletzt', 'besonders', 'Horst', 'Stein', '.'], [\"'\", \"''\", 'Stade', 'Reims', \"''\", \"'\"], ['2011', 'David', 'J.', 'P.', 'Barker']])"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "panx_de[\"train\"][\"tokens\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "f1e76afb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2.000',\n",
       " 'Einwohnern',\n",
       " 'an',\n",
       " 'der',\n",
       " 'Danziger',\n",
       " 'Bucht',\n",
       " 'in',\n",
       " 'der',\n",
       " 'polnischen',\n",
       " 'Woiwodschaft',\n",
       " 'Pommern',\n",
       " '.']"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "panx_ch[\"de\"][\"train\"][\"tokens\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f44113b3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp (3.13.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
